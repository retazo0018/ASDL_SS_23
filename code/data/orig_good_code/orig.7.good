dir_dict = { <NEWLINE> <INDENT> <STRING> : os . path . join ( base_dir , prep_dir , <STRING> ) , <NEWLINE> <STRING> : os . path . join ( base_dir , prep_dir , <STRING> ) , <NEWLINE> <STRING> : os . path . join ( base_dir , prep_dir , <STRING> ) , <NEWLINE> <STRING> : os . path . join ( base_dir , prep_dir , <STRING> ) , <NEWLINE> <STRING> : os . path . join ( base_dir , prep_dir , <STRING> ) , <NEWLINE> <STRING> : os . path . join ( base_dir , resize_dir , <STRING> ) , <NEWLINE> <STRING> : os . path . join ( base_dir , prep_dir , <STRING> ) , <NEWLINE> <DEDENT>
if downsample : <NEWLINE> <INDENT> fixed_shrunk = trans . resize_image ( fixed_image , fixed_image . GetSpacing ( ) [ 0 ] , downsample_target ) <NEWLINE> rotated_shrunk = trans . resize_image ( rotated_image , fixed_image . GetSpacing ( ) [ 0 ] , downsample_target ) <NEWLINE> spacing = fixed_shrunk . GetSpacing ( ) <NEWLINE> <DEDENT>
if roi_size is None : <NEWLINE> <INDENT> with open ( output_path , <STRING> , newline = <STRING> ) as csvfile : <NEWLINE> <INDENT> print ( <STRING> . format ( <NEWLINE> <INDENT> ret_image_path . name , tile_size [ 0 ] ) ) <NEWLINE> <DEDENT> writer = csv . writer ( csvfile ) <NEWLINE> writer . writerow ( [ <STRING> , <STRING> , <STRING> , <STRING> , <NEWLINE> <INDENT> <STRING> , <STRING> , <STRING> ] ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT>
iecsize = hdd . diskSize ( ) <NEWLINE> <COMMENT> <NL> <INDENT> if iecsize > 1000000 : <NEWLINE> <INDENT> iecsize = ( iecsize + 50000 ) // float ( 100000 ) / 10 <NEWLINE> <COMMENT> <NL> if ( iecsize % 1 > 0 ) : <NEWLINE> <INDENT> iecsize = <STRING> % iecsize <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> iecsize = <STRING> % iecsize <NEWLINE> <COMMENT> <NL> <DEDENT> <DEDENT> elif iecsize > 300000 : <NEWLINE> <INDENT> iecsize = <STRING> % ( ( iecsize + 5000 ) // 10000 * 10 ) <NEWLINE> <COMMENT> <NL> <DEDENT> elif iecsize > 1000 : <NEWLINE> <INDENT> iecsize = <STRING> % ( ( iecsize + 500 ) // 1000 ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> iecsize = <STRING> % iecsize <NEWLINE> <DEDENT> <DEDENT>
if querytype == QUERYTYPE_LOOKUP__ID : <NEWLINE> <INDENT> arglist = ( service_reference , querytype , begin ) <NEWLINE> else : <NEWLINE> arglist = ( service_reference , querytype , begin , minutes ) <NEWLINE> <DEDENT>
@ classmethod <NEWLINE> <INDENT> def isinstance ( cls , instance ) : <NEWLINE> <INDENT> if isinstance ( instance , cls ) : <NEWLINE> <INDENT> return instance <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> raise TypeError ( <STRING> % ( instance , cls . __name__ ) ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT>
rows = husoftm . connection . get_connection ( ) . query ( [ <STRING> ] , condition = <STRING> % ( int ( iln ) , ) ) <NEWLINE> <INDENT> if rows : <NEWLINE> <COMMENT> <NL> <INDENT> return get_kunde ( rows [ 0 ] [ <STRING> ] ) <NEWLINE> <DEDENT> else : <NEWLINE> <COMMENT> <NL> <INDENT> rows = husoftm . connection . get_connection ( ) . query ( [ <STRING> ] , condition = <STRING> % ( int ( iln ) , ) ) <NEWLINE> if rows : <NEWLINE> <INDENT> rows2 = husoftm . connection . get_connection ( ) . query ( [ <STRING> ] , <NEWLINE> <INDENT> condition = <STRING> % ( int ( rows [ 0 ] [ <STRING> ] ) , ) ) <NEWLINE> <DEDENT> if rows2 : <NEWLINE> <INDENT> kunde = Kunde ( ) . fill_from_softm ( rows2 [ 0 ] ) <NEWLINE> kunde . kundennr = kunde . kundennr + ( <STRING> % int ( rows [ 0 ] [ <STRING> ] ) ) <NEWLINE> return kunde <NEWLINE> <DEDENT> <DEDENT> <DEDENT> raise ValueError ( <STRING> % iln ) <NEWLINE> <DEDENT>
<COMMENT> <NL> <INDENT> assert svc in self . services <NEWLINE> <DEDENT>
<COMMENT> <NL> <INDENT> config . update ( new_properties ) <NEWLINE> <DEDENT>
def _add_memory_since_blocked ( self , position ) : <NEWLINE> <INDENT> memory_since_blocked = self . get_memory_since_blocked ( ) <NEWLINE> memory_since_blocked . append ( position ) <NEWLINE> self . _set_memory_since_blocked ( memory_since_blocked ) <NEWLINE> <DEDENT>
def normalized ( self ) : <NEWLINE> <INDENT> return self . __class__ ( self . _quantity * self . _units . _scale , self . _units . base_units ( ) ) <NEWLINE> <DEDENT>
config [ <STRING> ] = form or parse_kwarg ( config , <STRING> , context . get ( <STRING> ) ) <NEWLINE> <INDENT> config [ <STRING> ] = config . get ( <STRING> ) <NEWLINE> config [ <STRING> ] = config . get ( <STRING> ) <NEWLINE> config [ <STRING> ] = config . get ( <STRING> ) <NEWLINE> config [ <STRING> ] = config . get ( <STRING> , label ) <NEWLINE> config [ <STRING> ] = config . get ( <STRING> ) <NEWLINE> config [ <STRING> ] = config . get ( <STRING> ) <NEWLINE> config [ <STRING> ] = config . get ( <STRING> ) <NEWLINE> config [ <STRING> ] = config . get ( <STRING> ) <NEWLINE> config [ <STRING> ] = config . get ( <STRING> ) <NEWLINE> config [ <STRING> ] = config . get ( <STRING> ) <NEWLINE> config [ <STRING> ] = config . get ( <STRING> ) <NEWLINE> config [ <STRING> ] = config . get ( <STRING> , <STRING> ) <NEWLINE> config [ <STRING> ] = parse_kwarg ( config , <STRING> , [ ] ) <COMMENT> <NEWLINE> config [ <STRING> ] = config . get ( <STRING> , <STRING> ) <NEWLINE> config [ <STRING> ] = config . get ( <STRING> , <STRING> ) <NEWLINE> config [ <STRING> ] = config . get ( <STRING> , settings . RH_HELP_TEXT_POSITION ) <NEWLINE> <DEDENT>
<COMMENT> <NL> <INDENT> model = dct . pop ( <STRING> ) <NEWLINE> dct [ <STRING> ] , dct [ <STRING> ] = set ( ) , set ( ) <NEWLINE> for rel in dct . pop ( <STRING> ) : <NEWLINE> <INDENT> if isinstance ( rel , tuple ) : <NEWLINE> <COMMENT> <NL> <INDENT> other , field , lkey , rkey = rel <NEWLINE> <DEDENT> else : <NEWLINE> <COMMENT> <NL> <INDENT> other = rel <NEWLINE> field , lkey , rkey = other . lower ( ) , <STRING> , <STRING> % model . lower ( ) <NEWLINE> <DEDENT> dct [ field ] = HasOneDescriptor ( other , lkey , rkey ) <NEWLINE> dct [ <STRING> ] . add ( field ) <NEWLINE> index_registry . register ( other , rkey ) <NEWLINE> <DEDENT> for rel in dct . pop ( <STRING> ) : <NEWLINE> <INDENT> if isinstance ( rel , tuple ) : <NEWLINE> <INDENT> other , field , lkey , rkey = rel <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> other = rel <NEWLINE> field , lkey , rkey = other . lower ( ) , <STRING> % other . lower ( ) , <STRING> <NEWLINE> <DEDENT> dct [ field ] = BelongsToDescriptor ( other , lkey , rkey ) <NEWLINE> dct [ <STRING> ] . add ( field ) <NEWLINE> dct [ <STRING> ] . add ( lkey ) <NEWLINE> index_registry . register ( model , lkey ) <NEWLINE> <DEDENT> for rel in dct . pop ( <STRING> ) : <NEWLINE> <INDENT> if isinstance ( rel , tuple ) : <NEWLINE> <INDENT> other , field , lkey , rkey = rel <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> other = rel <NEWLINE> field , lkey , rkey = tableize ( other ) , <STRING> , <STRING> % model . lower ( ) <NEWLINE> <DEDENT> dct [ field ] = HasManyDescriptor ( other , lkey , rkey ) <NEWLINE> dct [ <STRING> ] . add ( field ) <NEWLINE> index_registry . register ( other , rkey ) <NEWLINE> <DEDENT> for rel in dct . pop ( <STRING> ) : <NEWLINE> <INDENT> if isinstance ( rel , tuple ) : <NEWLINE> <INDENT> other , field , lkey , rkey = rel <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> other = rel <NEWLINE> field , lkey , rkey = tableize ( other ) , <STRING> , <STRING> <NEWLINE> <DEDENT> join_model = <STRING> + <STRING> . join ( sorted ( [ model , other ] ) ) <NEWLINE> try : <NEWLINE> <INDENT> remodel . models . ModelBase ( join_model , ( remodel . models . Model , ) , { } ) <NEWLINE> <DEDENT> except AlreadyRegisteredError : <NEWLINE> <COMMENT> <NL> <COMMENT> <NL> <INDENT> pass <NEWLINE> <DEDENT> mlkey , mrkey = <STRING> % model . lower ( ) , <STRING> % other . lower ( ) <NEWLINE> dct [ field ] = HasAndBelongsToManyDescriptor ( other , lkey , rkey , join_model , mlkey , mrkey ) <NEWLINE> dct [ <STRING> ] . add ( field ) <NEWLINE> index_registry . register ( join_model , mlkey ) <NEWLINE> index_registry . register ( join_model , mrkey ) <NEWLINE> <DEDENT> <DEDENT>
if num_items == 2 : <NEWLINE> <INDENT> if implied_state < 0 : <NEWLINE> <INDENT> raise ValueError ( <STRING> ) <NEWLINE> <DEDENT> in_label , dest = arc_def <NEWLINE> arc_simple = implied_state , in_label , in_label , dest , - 1 <NEWLINE> elif num_items == 3 : <NEWLINE> if implied_state < 0 : <NEWLINE> <INDENT> raise ValueError ( <STRING> ) <NEWLINE> <COMMENT> <NL> <DEDENT> in_label , out_label , dest = arc_def <NEWLINE> arc_simple = implied_state , in_label , out_label , dest , - 1 <NEWLINE> elif num_items == 4 : <NEWLINE> <COMMENT> <NL> src , in_label , dest , is_final = arc_def <NEWLINE> if is_final == 1 : <NEWLINE> <INDENT> assert in_label == - 1 and dest == - 1 <NEWLINE> <DEDENT> arc_simple = src , in_label , in_label , dest , is_final <NEWLINE> elif num_items == 5 : <NEWLINE> arc_simple = arc_def <COMMENT> <NEWLINE> <DEDENT>
<COMMENT> <NL> <INDENT> self . mygene_df = self . my_gene_info ( ) <NEWLINE> self . mygene_df . to_csv ( self . mygene_path , self . mygene_df ) <NEWLINE> <COMMENT> <NL> if self . __post_blast : <NEWLINE> <INDENT> self . missing_dict = self . get_miss_acc ( ) <NEWLINE> self . missing_genes = self . missing_dict [ <STRING> ] <NEWLINE> self . missing_gene_count = self . missing_genes [ <STRING> ] <NEWLINE> del self . missing_genes [ <STRING> ] <NEWLINE> self . missing_organsims = self . missing_dict [ <STRING> ] <NEWLINE> self . missing_organsims_count = self . missing_organsims [ <STRING> ] <NEWLINE> del self . missing_organsims [ <STRING> ] <NEWLINE> <DEDENT> <DEDENT>
args = parser . parse_args ( argv ) <NEWLINE>
xlim1 = ax1 . get_xlim ( ) <NEWLINE> <INDENT> ylim1 = ax1 . get_ylim ( ) <NEWLINE> <DEDENT>
<COMMENT> <NL> <INDENT> try : <NEWLINE> <INDENT> if self . _project_lock_file is not None : <NEWLINE> <INDENT> try : <NEWLINE> <INDENT> if os . path . exists ( self . _project_lock_file ) : <NEWLINE> <INDENT> file = open ( self . _project_lock_file , <STRING> ) <NEWLINE> data = file . readlines ( ) <NEWLINE> file . close ( ) <NEWLINE> for index in range ( len ( data ) ) : <NEWLINE> <INDENT> data [ index ] = data [ index ] . strip ( ) <NEWLINE> <DEDENT> if data == self . _project_lock_signature : <NEWLINE> <INDENT> os . remove ( self . _project_lock_file ) <NEWLINE> print ( <STRING> % self . _project_lock_file ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> printWarrningMSG = False <NEWLINE> try : <NEWLINE> <INDENT> if data [ 0 ] != self . _project_lock_signature [ 0 ] : <NEWLINE> <INDENT> printWarrningMSG = True <NEWLINE> <DEDENT> <DEDENT> except : <NEWLINE> <INDENT> printWarrningMSG = True <NEWLINE> <DEDENT> if printWarrningMSG : <NEWLINE> <INDENT> print ( <STRING> ) <NEWLINE> print ( <STRING> ) <NEWLINE> print ( self . _project_lock_signature ) <NEWLINE> print ( <STRING> ) <NEWLINE> print ( data ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT> return True <NEWLINE> <DEDENT> except : <NEWLINE> <INDENT> print ( <STRING> % self . _project_lock_file ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT> <DEDENT>
def drawColorBox ( self , qp , colorlist , xC , yC , xSize , ySize , DrawBorder ) : <NEWLINE> <INDENT> if xSize > 0 and ySize > 0 : <NEWLINE> <INDENT> numberofColors = len ( colorlist ) <NEWLINE> if numberofColors >= xSize : <NEWLINE> <INDENT> yP = int ( yC + ySize ) <NEWLINE> for i in range ( xSize ) : <NEWLINE> <INDENT> color = colorlist [ i ] <NEWLINE> qp . setBrush ( color ) <NEWLINE> qp . setPen ( color ) <NEWLINE> xE = int ( i + xC ) <NEWLINE> qp . drawLine ( xE , yP , xE , yP ) <NEWLINE> <DEDENT> <DEDENT> else : <NEWLINE> <INDENT> rightP = int ( xC ) <NEWLINE> scaleFactor = float ( xSize ) / float ( numberofColors ) <NEWLINE> rightPos = rightP + xSize - 1 <NEWLINE> for i in range ( numberofColors ) : <NEWLINE> <INDENT> leftP = rightP <NEWLINE> rightP = int ( xC + scaleFactor * float ( i + 1 ) ) <NEWLINE> color = colorlist [ i ] <NEWLINE> qp . setBrush ( color ) <NEWLINE> qp . setPen ( color ) <NEWLINE> if ( leftP < rightPos ) : <NEWLINE> <INDENT> qp . drawRect ( leftP , yC , max ( rightP - leftP , 1 ) , ySize - 1 ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT> if DrawBorder : <NEWLINE> <INDENT> qp . setPen ( QtGui . QColor ( 0 , 0 , 0 ) ) <NEWLINE> qp . setBrush ( QtGui . QColor ( 0 , 0 , 0 , 0 ) ) <NEWLINE> qp . drawRect ( xC , yC , xSize - 1 , ySize - 1 ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT>
if longFileNameWritePath is None : <NEWLINE> <INDENT> CreateWriteDirPathFromShortFilePath = True <NEWLINE> else : <NEWLINE> writepathdir , _ = os . path . split ( longFileNameWritePath ) <NEWLINE> if platform . system ( ) == <STRING> : <NEWLINE> <INDENT> if len ( writepathdir ) > 200 : <NEWLINE> <INDENT> writepathdir , _ = os . path . split ( writepath ) <NEWLINE> <DEDENT> <DEDENT> FileUtil . createPath ( writepathdir , False ) <NEWLINE> CreateWriteDirPathFromShortFilePath = not os . path . isdir ( writepathdir ) <NEWLINE> if CreateWriteDirPathFromShortFilePath : <NEWLINE> writepathdir , _ = os . path . split ( writepath ) <NEWLINE> FileUtil . createPath ( writepathdir , False ) <NEWLINE> <DEDENT>
def _childNodeROIIndicatorChanged ( self , val , AquireFileLock = True ) : <NEWLINE> <INDENT> if not self . _childNodeROIIndicatorChanged_called : <NEWLINE> <INDENT> try : <NEWLINE> <INDENT> self . _childNodeROIIndicatorChanged_called = True <NEWLINE> if self . isDelayedCacheLoadingSet ( ) : <NEWLINE> <INDENT> if not val : <NEWLINE> <INDENT> return <NEWLINE> <DEDENT> elif self . _ROIDatasetIndicatorCache != True : <NEWLINE> <INDENT> self . _ROIDatasetIndicatorCache = val <NEWLINE> tree = self . _tree <NEWLINE> if ( tree is not None ) : <NEWLINE> <INDENT> tree . _ProjectDataset . getProjectFileInterface ( ) . setProjectDatasetCache ( self . getTreePath ( ) , val , Key = <STRING> ) <NEWLINE> <DEDENT> self . callChildNodeROIIndicatorChanged ( val , AquireFileLock = AquireFileLock ) <NEWLINE> self . fireTreeNodeChangedEvent ( ) <NEWLINE> return <NEWLINE> <DEDENT> <DEDENT> currentValue = self . getROIDatasetIndicator ( ) <NEWLINE> if val is not None and val : <NEWLINE> <INDENT> if val != currentValue : <NEWLINE> <INDENT> self . setROIDatasetIndicator ( val ) <NEWLINE> <DEDENT> <DEDENT> elif val != currentValue : <NEWLINE> <INDENT> found = False <NEWLINE> lst = self . getChildernLst ( ) <NEWLINE> if len ( lst ) > 0 : <NEWLINE> <INDENT> for child in lst : <NEWLINE> <INDENT> if ( child . getROIDatasetIndicator ( ) ) : <NEWLINE> <INDENT> found = True <NEWLINE> break <NEWLINE> <DEDENT> <DEDENT> if found != currentValue or val is not None : <NEWLINE> <INDENT> self . setROIDatasetIndicator ( found ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT> <DEDENT> finally : <NEWLINE> <INDENT> self . _childNodeROIIndicatorChanged_called = False <NEWLINE> <DEDENT> <DEDENT> <DEDENT>
def removeAllInternalTags ( self , SafeNameSet = None ) : <NEWLINE> <INDENT> if SafeNameSet is not None : <NEWLINE> <INDENT> if not isinstance ( SafeNameSet , set ) : <NEWLINE> <INDENT> SafeNameSet = set ( SafeNameSet ) <NEWLINE> <DEDENT> <DEDENT> else : <NEWLINE> <INDENT> SafeNameSet = set ( ) <NEWLINE> <DEDENT> self . _clearTagCache ( ) <NEWLINE> datasetLength = len ( self . _dataSetTags ) <NEWLINE> for index in range ( datasetLength - 1 , - 1 , - 1 ) : <NEWLINE> <INDENT> tag = self . _dataSetTags [ index ] <NEWLINE> if tag . isInternalTag ( ) : <NEWLINE> <INDENT> if tag . getName ( ) not in SafeNameSet : <NEWLINE> <INDENT> self . _recycleID ( tag . getID ( ) ) <NEWLINE> del self . _dataSetTags [ index ] <NEWLINE> del tag <NEWLINE> <DEDENT> <DEDENT> <DEDENT> if datasetLength != len ( self . _dataSetTags ) : <NEWLINE> <INDENT> self . callParameterChangeListener ( ) <NEWLINE> <DEDENT> <DEDENT>
if ( rebuildList ) : <NEWLINE> <INDENT> lst . clear ( ) <NEWLINE> for name in namelist : <NEWLINE> <INDENT> item = QListWidgetItem ( ) <NEWLINE> item . setText ( name ) <NEWLINE> if ( name == <STRING> ) : <NEWLINE> <INDENT> color = QtGui . QColor ( 0 , 0 , 0 ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> color = roiDefs . getROIColor ( name ) <NEWLINE> <DEDENT> item . setForeground ( color ) <NEWLINE> if ROIDictionary is not None and ROIDictionary . isROIDefined ( name ) : <NEWLINE> <INDENT> item . setBackground ( QtGui . QColor ( 255 , 211 , 82 ) ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> item . setBackground ( QtGui . QColor ( 255 , 255 , 255 ) ) <NEWLINE> <DEDENT> item . setSelected ( name in selectedNameList ) <NEWLINE> lst . addItem ( item ) <NEWLINE> <COMMENT> <NL> <COMMENT> <NL> if ( listSelectionChangeListenerConnected ) : <NEWLINE> <DEDENT> self . ui . ROI_List . selectionModel ( ) . selectionChanged . connect ( self . ROIListSelectionChanged ) <NEWLINE> <DEDENT>
kModel = Custom_Objects [ <STRING> ] ( origionalModelPath , LoadLinearModel = True ) <NEWLINE>
def get_ready_buffers ( self ) : <NEWLINE> <INDENT> ready = { } <NEWLINE> current_time = time ( ) <NEWLINE> with self . lock : <NEWLINE> <INDENT> for ts , delayed_to in list ( self . delays . items ( ) ) : <NEWLINE> <INDENT> if delayed_to < current_time : <NEWLINE> <INDENT> del self . delays [ ts ] <NEWLINE> ready [ ts ] = self . buffers . pop ( ts ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT> return ready <NEWLINE> <DEDENT>
assert result not in tree <NEWLINE> <INDENT> assert is_left_subtree_less_than_right_subtree ( tree ) <NEWLINE> <DEDENT>
assert len ( tree ) > 0 <NEWLINE> <INDENT> assert to_height ( tree ) >= 0 <NEWLINE> assert is_left_subtree_less_than_right_subtree ( tree ) <NEWLINE> <DEDENT>
counter . subtract ( { tok : counter [ tok ] for tok in [ <STRING> ] + specials } ) <NEWLINE> <INDENT> max_size = None if max_size is None else max_size + len ( self . itos ) <NEWLINE> <DEDENT>
def set_vectors ( self , stoi , vectors , dim , unk_init = torch . Tensor . zero_ ) : <NEWLINE> <INDENT> self . vectors = torch . Tensor ( len ( self ) , dim ) <NEWLINE> for i , token in enumerate ( self . itos ) : <NEWLINE> <INDENT> wv_index = stoi . get ( token , None ) <NEWLINE> if wv_index is not None : <NEWLINE> <INDENT> self . vectors [ i ] = vectors [ wv_index ] <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> self . vectors [ i ] = unk_init ( self . vectors [ i ] ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT>
for partition in self . _client . get_partition_ids_for_topic ( topic ) : <NEWLINE> <INDENT> self . _consume_topic_partition ( topic , partition ) <NEWLINE> <DEDENT>
def get_nat_type ( s , source_ip , source_port , stun_host = None , stun_port = 3478 ) : <NEWLINE> <INDENT> _initialize ( ) <NEWLINE> port = stun_port <NEWLINE> log . debug ( <STRING> ) <NEWLINE> resp = False <NEWLINE> if stun_host : <NEWLINE> <INDENT> ret = stun_test ( s , stun_host , port , source_ip , source_port ) <NEWLINE> resp = ret [ <STRING> ] <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> for stun_host in stun_servers_list : <NEWLINE> <INDENT> log . debug ( <STRING> , stun_host ) <NEWLINE> ret = stun_test ( s , stun_host , port , source_ip , source_port ) <NEWLINE> resp = ret [ <STRING> ] <NEWLINE> if resp : <NEWLINE> <INDENT> break <NEWLINE> <DEDENT> <DEDENT> <DEDENT> if not resp : <NEWLINE> <INDENT> return Blocked , ret <NEWLINE> <DEDENT> log . debug ( <STRING> , ret ) <NEWLINE> exIP = ret [ <STRING> ] <NEWLINE> exPort = ret [ <STRING> ] <NEWLINE> changedIP = ret [ <STRING> ] <NEWLINE> changedPort = ret [ <STRING> ] <NEWLINE> if ret [ <STRING> ] == source_ip : <NEWLINE> <INDENT> changeRequest = <STRING> . join ( [ ChangeRequest , <STRING> , <STRING> ] ) <NEWLINE> ret = stun_test ( s , stun_host , port , source_ip , source_port , <NEWLINE> <INDENT> changeRequest ) <NEWLINE> <DEDENT> if ret [ <STRING> ] : <NEWLINE> <INDENT> typ = OpenInternet <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> typ = SymmetricUDPFirewall <NEWLINE> <DEDENT> <DEDENT> else : <NEWLINE> <INDENT> changeRequest = <STRING> . join ( [ ChangeRequest , <STRING> , <STRING> ] ) <NEWLINE> log . debug ( <STRING> ) <NEWLINE> ret = stun_test ( s , stun_host , port , source_ip , source_port , <NEWLINE> <INDENT> changeRequest ) <NEWLINE> <DEDENT> log . debug ( <STRING> , ret ) <NEWLINE> if ret [ <STRING> ] : <NEWLINE> <INDENT> typ = FullCone <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> log . debug ( <STRING> ) <NEWLINE> ret = stun_test ( s , changedIP , changedPort , source_ip , source_port ) <NEWLINE> log . debug ( <STRING> , ret ) <NEWLINE> if not ret [ <STRING> ] : <NEWLINE> <INDENT> typ = ChangedAddressError <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> if exIP == ret [ <STRING> ] and exPort == ret [ <STRING> ] : <NEWLINE> <INDENT> changePortRequest = <STRING> . join ( [ ChangeRequest , <STRING> , <NEWLINE> <INDENT> <STRING> ] ) <NEWLINE> <DEDENT> log . debug ( <STRING> ) <NEWLINE> ret = stun_test ( s , changedIP , changedPort , source_ip , source_port , <NEWLINE> <INDENT> changePortRequest ) <NEWLINE> <DEDENT> log . debug ( <STRING> , ret ) <NEWLINE> if ret [ <STRING> ] : <NEWLINE> <INDENT> typ = RestricNAT <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> typ = RestricPortNAT <NEWLINE> <DEDENT> <DEDENT> else : <NEWLINE> <INDENT> typ = SymmetricNAT <NEWLINE> <DEDENT> <DEDENT> <DEDENT> <DEDENT> return typ , ret <NEWLINE> <DEDENT>
if __name__ == <STRING> : <NEWLINE> <INDENT> if QtCore . QCoreApplication . instance ( ) is None : <NEWLINE> <INDENT> app = QtGui . QApplication ( [ ] ) <NEWLINE> <DEDENT> test_all ( ) <NEWLINE> <COMMENT> <NL> <COMMENT> <NL> <DEDENT>
class Frame ( Environment ) : <NEWLINE> <INDENT> def __init__ ( self , title , subtitle = <STRING> , ncols = 0 ) : <NEWLINE> <INDENT> super ( ) . __init__ ( ) <NEWLINE> self . content_separator = <STRING> <NEWLINE> self . append ( <NEWLINE> <INDENT> pl . NoEscape ( <STRING> ) + <NEWLINE> pl . escape_latex ( title ) + <NEWLINE> pl . NoEscape ( <STRING> ) <NEWLINE> <DEDENT> ) <NEWLINE> if subtitle : <NEWLINE> <INDENT> self . append ( <NEWLINE> <INDENT> pl . NoEscape ( <STRING> ) + <NEWLINE> pl . escape_latex ( subtitle ) + <NEWLINE> pl . NoEscape ( <STRING> ) <NEWLINE> <DEDENT> ) <NEWLINE> <DEDENT> if ncols : <NEWLINE> <INDENT> self . add_columns ( ncols = ncols ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT>
def get_running_plants ( self , plants ) : <NEWLINE> <INDENT> for plant in plants : <NEWLINE> <INDENT> if plant . construction_year <= 1990 and plant . name != <STRING> : <NEWLINE> <COMMENT> <NL> <INDENT> plant . construction_year = randint ( self . year_number - 15 , self . year_number ) <NEWLINE> yield plant <NEWLINE> <DEDENT> elif plant . construction_year + plant . operating_period + plant . construction_period + plant . pre_dev_period >= self . year_number : <NEWLINE> <INDENT> yield plant <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> logger . info ( <STRING> . format ( plant . name , <NEWLINE> <INDENT> plant . construction_year ) ) <NEWLINE> <DEDENT> continue <NEWLINE> <DEDENT> <DEDENT> <DEDENT>
def invest ( self ) : <NEWLINE> <INDENT> lowest_upfront_cost = 0 <NEWLINE> total_upfront_cost = 0 <NEWLINE> counter = 0 <NEWLINE> total_capacity = 0 <NEWLINE> while self . money > lowest_upfront_cost or total_capacity < 1500 : <NEWLINE> <INDENT> counter += 1 <NEWLINE> <COMMENT> <NL> <COMMENT> <NL> <COMMENT> <NL> potential_plant_data = get_most_profitable_plants_by_npv ( self . model , self . difference_in_discount_rate , <NEWLINE> <INDENT> self . look_back_period ) <NEWLINE> <DEDENT> if counter == 1 : <NEWLINE> <INDENT> potential_plant_list = [ ] <NEWLINE> for plant_data in potential_plant_data : <NEWLINE> <INDENT> if not potential_plant_data : <NEWLINE> <INDENT> break <NEWLINE> <DEDENT> power_plant_trial = create_power_plant ( <STRING> , self . model . year_number , plant_data [ 1 ] , plant_data [ 0 ] ) <NEWLINE> potential_plant_list . append ( power_plant_trial ) <NEWLINE> if potential_plant_list : <NEWLINE> <INDENT> lowest_upfront_cost = min ( plant . get_upfront_costs ( ) * upfront_investment_costs for plant in potential_plant_list ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> break <NEWLINE> <DEDENT> <DEDENT> <DEDENT> for plant_data in potential_plant_data : <NEWLINE> <COMMENT> <NL> <INDENT> if not potential_plant_data : <NEWLINE> <INDENT> break <NEWLINE> <DEDENT> power_plant_trial = create_power_plant ( <STRING> , self . model . year_number , plant_data [ 1 ] , plant_data [ 0 ] ) <NEWLINE> total_upfront_cost = power_plant_trial . get_upfront_costs ( ) * upfront_investment_costs <NEWLINE> <COMMENT> <NL> if self . money > total_upfront_cost : <NEWLINE> <INDENT> logger . info ( <STRING> . format ( power_plant_trial . plant_type , self . money , total_upfront_cost ) ) <NEWLINE> self . plants . append ( power_plant_trial ) <NEWLINE> self . money -= total_upfront_cost <NEWLINE> total_capacity += power_plant_trial . capacity_mw <NEWLINE> break <NEWLINE> <DEDENT> <DEDENT> <DEDENT> <DEDENT>
try : <NEWLINE> <INDENT> kp . verify ( sig , input ) <NEWLINE> return True <NEWLINE> except ed25519 . BadSignatureError : <NEWLINE> raise ErrInvalidSignature ( ) <NEWLINE> <DEDENT>
user = nkeys . from_seed ( seed ) <NEWLINE> <INDENT> if user . verify ( data , signed_data ) : <NEWLINE> <INDENT> print ( <STRING> ) <NEWLINE> sys . exit ( 0 ) <NEWLINE> <DEDENT> <DEDENT>
@ classmethod <NEWLINE> <INDENT> def auto ( cls , syslog = None , stderr = None , level = None , extended = None ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> level = norm_level ( level ) <NEWLINE> if syslog is None and stderr is None : <NEWLINE> <INDENT> if sys . stderr . isatty ( ) or syslog_path ( ) is None : <NEWLINE> <INDENT> log . info ( <STRING> ) <NEWLINE> syslog , stderr = None , ( level or logging . INFO ) <NEWLINE> if extended is None : <NEWLINE> <INDENT> extended = ( stderr or 0 ) <= logging . DEBUG <NEWLINE> <DEDENT> <DEDENT> else : <NEWLINE> <INDENT> log . info ( <STRING> ) <NEWLINE> syslog , stderr = ( level or logging . WARNING ) , None <NEWLINE> <DEDENT> <DEDENT> return cls ( syslog = syslog , stderr = stderr , extended = extended ) <NEWLINE> <DEDENT> <DEDENT>
tifffile . imsave ( full_fname , output_data [ 0 , : , : , : ] , compress = 1 ) <NEWLINE>
if tag == VERSION : <NEWLINE> <INDENT> info = <STRING> . format ( <NEWLINE> <INDENT> tag , VERSION <NEWLINE> <DEDENT> ) <NEWLINE> sys . exit ( info ) <NEWLINE> <DEDENT>
sm = site . getSiteManager ( ) <NEWLINE> <INDENT> if not sm . queryUtility ( interfaces . ICalendarSupport ) : <NEWLINE> <INDENT> sm . registerUtility ( content . CalendarSupport ( <STRING> ) , <NEWLINE> <INDENT> interfaces . ICalendarSupport ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT>
sm = site . getSiteManager ( ) <NEWLINE> <INDENT> if not sm . queryUtility ( interfaces . ICalendarSupport ) : <NEWLINE> <INDENT> sm . registerUtility ( content . CalendarSupport ( <STRING> ) , <NEWLINE> <INDENT> interfaces . ICalendarSupport ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT>
for each in recurrence . getOccurrenceDays ( ) : <NEWLINE> <INDENT> if start is not None and each < startdate : <NEWLINE> <INDENT> continue <NEWLINE> <DEDENT> if stop is not None and each >= stopdate : <NEWLINE> <INDENT> break <NEWLINE> <DEDENT> dt = datetime . date . fromordinal ( each ) <NEWLINE> res . append ( BrainEvent ( self . context , dt ) ) <NEWLINE> <DEDENT>
available_operations = { <NEWLINE> <INDENT> <STRING> : ( 1 , lambda x , y : x + y ) , <NEWLINE> <STRING> : ( 1 , lambda x , y : x - y ) , <NEWLINE> <STRING> : ( 2 , lambda x , y : x * y ) , <NEWLINE> <STRING> : ( 2 , lambda x , y : x // y ) , <NEWLINE> <STRING> : ( 3 , lambda x , y : x ** y ) , <NEWLINE> <STRING> : ( 2 , lambda x , y : x % y ) , <NEWLINE> <STRING> : ( 3 , lambda x , y : x ** y ) , <NEWLINE> <STRING> : ( 0 , lambda x , y : x < y ) , <NEWLINE> <STRING> : ( 0 , lambda x , y : x > y ) , <NEWLINE> <STRING> : ( 0 , lambda x , y : x <= y ) , <NEWLINE> <STRING> : ( 0 , lambda x , y : x >= y ) , <NEWLINE> <STRING> : ( 0 , lambda x , y : x >= y ) , <NEWLINE> <STRING> : ( 0 , lambda x , y : x != y ) , <NEWLINE> <STRING> : ( 2 , lambda x , y : x / y ) , <NEWLINE> } <NEWLINE> <DEDENT>
if expr . operator . type_ == TokenTypes . MINUS : <NEWLINE> <INDENT> self . check_number_operands ( expr . operator , left , right ) <NEWLINE> return float ( left ) - float ( right ) <NEWLINE> elif expr . operator . type_ == TokenTypes . SLASH : <NEWLINE> self . check_number_operands ( expr . operator , left , right ) <NEWLINE> return float ( left ) / float ( right ) <NEWLINE> elif expr . operator . type_ == TokenTypes . STAR : <NEWLINE> self . check_number_operands ( expr . operator , left , right ) <NEWLINE> return float ( left ) * float ( right ) <NEWLINE> elif expr . operator . type_ == TokenTypes . PLUS : <NEWLINE> self . check_number_operands ( expr . operator , left , right ) <NEWLINE> return left + right <NEWLINE> elif expr . operator . type_ == TokenTypes . CAP or expr . operator . type_ == TokenTypes . STAR_STAR : <NEWLINE> self . check_number_operands ( expr . operator , left , right ) <NEWLINE> return left ** right <NEWLINE> elif expr . operator . type_ == TokenTypes . SLASH_SLASH : <NEWLINE> self . check_number_operands ( expr . operator , left , right ) <NEWLINE> return left // right <NEWLINE> elif expr . operator . type_ == TokenTypes . PERCENTS : <NEWLINE> self . check_number_operands ( expr . operator , left , right ) <NEWLINE> return left % right <NEWLINE> elif expr . operator . type_ == TokenTypes . GREATER : <NEWLINE> self . check_number_operands ( expr . operator , left , right ) <NEWLINE> return left > right <NEWLINE> elif expr . operator . type_ == TokenTypes . GREATER_EQUAL : <NEWLINE> self . check_number_operands ( expr . operator , left , right ) <NEWLINE> return left >= right <NEWLINE> elif expr . operator . type_ == TokenTypes . LESS : <NEWLINE> self . check_number_operands ( expr . operator , left , right ) <NEWLINE> return left < right <NEWLINE> elif expr . operator . type_ == TokenTypes . LESS_EQUAL : <NEWLINE> self . check_number_operands ( expr . operator , left , right ) <NEWLINE> return left <= right <NEWLINE> elif expr . operator . type_ == TokenTypes . BANG_EQUAL : <NEWLINE> self . check_number_operands ( expr . operator , left , right ) <NEWLINE> return not self . is_equal ( left , right ) <NEWLINE> elif expr . operator . type_ == TokenTypes . EQUAL_EQUAL : <NEWLINE> self . check_number_operands ( expr . operator , left , right ) <NEWLINE> return self . is_equal ( left , right ) <NEWLINE> <DEDENT>
elif data . message_type == GCMMessageType . RECEIPT : <NEWLINE> <INDENT> logging . debug ( <STRING> % data . message_id ) <NEWLINE> self . event ( XMPPEvent . RECEIPT , data ) <NEWLINE> <DEDENT>
self . groupRemoved . emit ( uuid , curgroup ) <NEWLINE>
tfi . saved_model . export ( <STRING> , m ) <NEWLINE> <COMMENT> <NL> <COMMENT> <NL>
def test_dictrecursion ( self ) : <NEWLINE> <INDENT> x = { } <NEWLINE> x [ <STRING> ] = x <NEWLINE> try : <NEWLINE> <INDENT> json . dumps ( x ) <NEWLINE> <DEDENT> except ValueError : <NEWLINE> <INDENT> pass <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> self . fail ( <STRING> ) <NEWLINE> <DEDENT> x = { } <NEWLINE> y = { <STRING> : x , <STRING> : x } <NEWLINE> <COMMENT> <NL> json . dumps ( y ) <NEWLINE> <DEDENT>
def __call__ ( self , text ) : <NEWLINE> <INDENT> atoms = self . toatoms ( text ) <NEWLINE> j = 0 <NEWLINE> while j < len ( atoms ) : <NEWLINE> <INDENT> i = j <NEWLINE> chunksize = 0 <NEWLINE> while j < len ( atoms ) and chunksize + len ( atoms [ j ] ) <= self . buffersize : <NEWLINE> <INDENT> chunksize += len ( atoms [ j ] ) <NEWLINE> j += 1 <NEWLINE> <DEDENT> self . _juststuff ( <STRING> . join ( atoms [ i : j ] ) ) <NEWLINE> <DEDENT> <DEDENT>
def test_http_304_res ( self ) : <NEWLINE> <INDENT> res = self . testapp . get ( <STRING> ) <NEWLINE> self . assertEqual ( <STRING> , res . status ) <NEWLINE> etag = res . headers [ <STRING> ] <NEWLINE> res2 = self . testapp . get ( <STRING> , headers = { <STRING> : etag } ) <NEWLINE> self . assertEqual ( <STRING> , res2 . status ) <NEWLINE> <DEDENT>
<COMMENT> <NL> <INDENT> pList = Q2Dict ( protoMeta , pRows ) <NEWLINE> <DEDENT>
Qtmp = getQbeStmt ( fieldName , sCondicion , sType ) <NEWLINE> <INDENT> if bAndConector : <NEWLINE> <INDENT> QResult = QResult & Qtmp <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> QResult = QResult | Qtmp <NEWLINE> <DEDENT> <DEDENT>
@ need_permissions ( <STRING> ) <NEWLINE> <INDENT> @ pass_record <NEWLINE> def post ( self , pid , record , ** kwargs ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> days_ago = circulation_overdue_loan_days ( record ) <NEWLINE> is_overdue = days_ago > 0 <NEWLINE> if not is_overdue : <NEWLINE> <INDENT> raise OverdueLoansMailError ( description = <STRING> ) <NEWLINE> <DEDENT> send_loan_overdue_reminder_mail ( record , days_ago ) <NEWLINE> return self . make_response ( <NEWLINE> <INDENT> pid , record , 202 , links_factory = self . links_factory <NEWLINE> <DEDENT> ) <NEWLINE> <DEDENT> <DEDENT>
def activate ( self , leaf ) : <NEWLINE> <INDENT> url = to_correios_url ( leaf ) <NEWLINE> with request . urlopen ( url ) as curreio : <NEWLINE> <INDENT> content = curreio . read ( ) <NEWLINE> info = get_tracking_info ( content . decode ( <STRING> ) ) <NEWLINE> if info : <NEWLINE> <INDENT> txt = <STRING> . join ( reversed ( info [ 0 ] ) ) <NEWLINE> return TextLeaf ( leaf . object , txt ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT>
with logger : <NEWLINE> <INDENT> for file , timers in timers_info : <NEWLINE> <INDENT> logger . debug ( <STRING> , file , timers ) <NEWLINE> <DEDENT> logger . info ( <STRING> , timers_total , len ( files ) ) <NEWLINE> <DEDENT>
for key , value in list ( data . items ( ) ) : <NEWLINE> <INDENT> if not isinstance ( value , str ) : <NEWLINE> <INDENT> data [ key ] = value . encode ( <STRING> ) <NEWLINE> <DEDENT> <DEDENT>
if commit_only : <NEWLINE> <INDENT> include += [ <STRING> + f for f in git . staged ( ) if f . endswith ( <STRING> ) ] <NEWLINE> exclude += git . ignore ( ) <NEWLINE> <DEDENT>
common . git_checkout ( master ) <NEWLINE>
for time in t_indexes : <NEWLINE> <INDENT> if time >= size_t : <NEWLINE> <INDENT> log ( <STRING> <NEWLINE> <INDENT> <STRING> % ( time + 1 , size_t ) ) <NEWLINE> <DEDENT> <DEDENT> else : <NEWLINE> <INDENT> if pro_start != pro_end : <NEWLINE> <INDENT> rendered_img = re . renderProjectedCompressed ( <NEWLINE> <INDENT> algorithm , time , stepping , pro_start , pro_end ) <NEWLINE> <DEDENT> <DEDENT> else : <NEWLINE> <INDENT> plane_def = omero . romio . PlaneDef ( ) <NEWLINE> plane_def . z = pro_start <NEWLINE> plane_def . t = time <NEWLINE> rendered_img = re . renderCompressed ( plane_def ) <NEWLINE> <COMMENT> <NL> <DEDENT> image = Image . open ( io . BytesIO ( rendered_img ) ) <NEWLINE> resized_image = imgUtil . resizeImage ( image , width , height ) <NEWLINE> rendered_images . append ( resized_image ) <NEWLINE> <DEDENT> <DEDENT>
def test_adapter_04 ( tmp_path ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> <COMMENT> <NL> assert not any ( SimpleAdapter . scan_path ( str ( tmp_path ) ) ) <NEWLINE> <COMMENT> <NL> assert not any ( SimpleAdapter . scan_path ( str ( tmp_path / <STRING> ) ) ) <NEWLINE> <COMMENT> <NL> file1 = ( tmp_path / <STRING> ) <NEWLINE> file1 . touch ( ) <NEWLINE> found = tuple ( SimpleAdapter . scan_path ( str ( file1 ) ) ) <NEWLINE> assert len ( found ) == 1 <NEWLINE> assert str ( file1 ) in found <NEWLINE> <COMMENT> <NL> assert len ( tuple ( SimpleAdapter . scan_path ( str ( tmp_path ) ) ) ) == 1 <NEWLINE> <COMMENT> <NL> ( tmp_path / <STRING> ) . touch ( ) <NEWLINE> nested = ( tmp_path / <STRING> ) <NEWLINE> nested . mkdir ( ) <NEWLINE> file2 = ( nested / <STRING> ) <NEWLINE> file2 . touch ( ) <NEWLINE> assert len ( tuple ( SimpleAdapter . scan_path ( str ( tmp_path ) ) ) ) == 1 <NEWLINE> <COMMENT> <NL> found = tuple ( SimpleAdapter . scan_path ( str ( tmp_path ) , recursive = True ) ) <NEWLINE> assert len ( found ) == 2 <NEWLINE> assert str ( file1 ) in found <NEWLINE> assert str ( file2 ) in found <NEWLINE> <DEDENT>
<COMMENT> <NL> <INDENT> return ct , existing_artifact <NEWLINE> <DEDENT>
changes . extend ( chs ) <NEWLINE> <INDENT> files . extend ( fs ) <NEWLINE> <DEDENT>
def percentiles ( self , start , percentiles = [ 10 , 25 , 75 , 90 ] ) : <NEWLINE> <INDENT> end = start + timedelta ( days = 7 ) <NEWLINE> ts_start , ts_end = utils . timestamp_from_datetime ( [ start , end ] ) <NEWLINE> this_week_indices = where ( ( self . _data [ <STRING> ] < ts_end ) & ( self . _data [ <STRING> ] >= ts_start ) ) <NEWLINE> this_week = self . _data [ this_week_indices ] <NEWLINE> result = { } <NEWLINE> pred = self . baseline_model . prediction ( this_week ) <NEWLINE> for p in percentiles : <NEWLINE> <INDENT> result [ p ] = pred + self . baseline_model . percentile_in_place ( this_week , p ) <NEWLINE> <DEDENT> return result <NEWLINE> <DEDENT>
for ref in range ( 1 , self . numberOfRef + 1 ) : <NEWLINE> <INDENT> refVol = self . _getFileName ( <STRING> , iter = iter , ref = ref ) <COMMENT> <NEWLINE> iterVol = self . _getFileName ( <STRING> , iter = iter , ref = ref ) <COMMENT> <NEWLINE> if iter == 1 : <NEWLINE> <INDENT> copyFile ( volFn , iterVol ) <COMMENT> <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> self . _splitParFile ( iter , ref , cpusRef [ ref - 1 ] ) <NEWLINE> prevIterVol = self . _getFileName ( <STRING> , iter = prevIter , ref = ref ) <COMMENT> <NEWLINE> copyFile ( prevIterVol , refVol ) <COMMENT> <NEWLINE> <DEDENT> copyFile ( refVol , iterVol ) <COMMENT> <NEWLINE> <DEDENT>
self . _defineSourceRelation ( self . inputClasses , vol ) <NEWLINE>
def _processMovie ( self , movieId , movieName , movieFolder ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> <COMMENT> <NL> <COMMENT> <NL> inMovieName = os . path . join ( movieFolder , movieName ) <NEWLINE> if movieName . endswith ( <STRING> ) : <NEWLINE> <INDENT> movieNameAux = movieName <NEWLINE> <DEDENT> elif movieName . endswith ( <STRING> ) : <NEWLINE> <INDENT> movieNameAux = pwutils . replaceExt ( inMovieName , <STRING> ) <NEWLINE> createLink ( inMovieName , movieNameAux ) <NEWLINE> movieNameAux = pwutils . replaceExt ( movieName , <STRING> ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> micFnMrc = pwutils . replaceExt ( inMovieName , <STRING> ) <NEWLINE> ImageHandler ( ) . convert ( inMovieName , micFnMrc , DT_FLOAT ) <NEWLINE> movieNameAux = pwutils . replaceExt ( movieName , <STRING> ) <NEWLINE> <DEDENT> <DEDENT>
if _showVol is not None : <NEWLINE> <COMMENT> <NL> <INDENT> showVolFileName = os . path . abspath ( <NEWLINE> <INDENT> ImageHandler . removeFileType ( _showVol . getFileName ( ) ) ) <NEWLINE> <DEDENT> f . write ( <STRING> % showVolFileName ) <NEWLINE> if _showVol . hasOrigin ( ) : <NEWLINE> <INDENT> x , y , z = _showVol . getOrigin ( ) . getShifts ( ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> x , y , z = _showVol . getOrigin ( force = True ) . getShifts ( ) <NEWLINE> <DEDENT> <DEDENT>
label_seq_id = str ( resseq ) <NEWLINE>
@ classmethod <NEWLINE> <INDENT> def createEmptyImage ( cls , fnOut , xDim = 1 , yDim = 1 , zDim = 1 , nDim = 1 , <NEWLINE> <INDENT> dataType = None ) : <NEWLINE> dt = dataType or cls . DT_FLOAT <NEWLINE> xmippLib . createEmptyFile ( fnOut , xDim , yDim , zDim , nDim , dt ) <NEWLINE> <DEDENT> <DEDENT>
<COMMENT> <NL> <INDENT> int_all_ranks_filt = stats . filter_min_observed ( intensity_all_ranks , threshold , samp_grps ) <NEWLINE> int_all_ranks_filt [ <STRING> ] = int_all_ranks_filt . index <NEWLINE> <DEDENT>
if url is None and not fail_silently : <NEWLINE> <INDENT> raise KeyDoesNotExist ( <STRING> % key ) <NEWLINE> <DEDENT>
if sort_by is not None : <NEWLINE> <INDENT> params [ <STRING> ] = <STRING> . format ( sort_by , sort_order ) <NEWLINE> <DEDENT>
number_dict = { <NEWLINE> <INDENT> <STRING> : True , <NEWLINE> <STRING> : True <NEWLINE> } <NEWLINE> phone_number = event [ <STRING> ] [ <STRING> ] <NEWLINE> if phone_number is None : <NEWLINE> phone_number = <STRING> <NEWLINE> else : <NEWLINE> phone_number = str ( phone_number ) <NEWLINE> <DEDENT>
iHTML = self . _Output [ <STRING> ] . to_html ( formatters = [ _QS_formatPandasPercentage ] * 5 ) <NEWLINE>
iDataLen = DataLenMax . iloc [ i ] <NEWLINE>
histogram = target . reduceRegion ( ee . Reducer . histogram ( 255 , 2 ) . combine ( <STRING> , None , True ) . combine ( <STRING> , None , True ) , sampleRegion , reductionScale , bestEffort = True ) <NEWLINE>
x_coord_range = torch . linspace ( - r , r , steps = self . width ) <NEWLINE> <INDENT> y_coord_range = torch . linspace ( - r , r , steps = self . height ) <NEWLINE> x , y = torch . meshgrid ( y_coord_range , x_coord_range ) <NEWLINE> <DEDENT>
<COMMENT> <NL> <INDENT> gdal . UseExceptions ( ) <NEWLINE> gdal . AllRegister ( ) <NEWLINE> np . seterr ( divide = <STRING> , invalid = <STRING> ) <NEWLINE> SWIR1_path = gdal . Open ( os . path . join ( landsat_dir , swir1 [ 0 ] ) ) <NEWLINE> swir1_band = SWIR1_path . GetRasterBand ( 1 ) . ReadAsArray ( ) . astype ( np . float32 ) <NEWLINE> TIR_path = gdal . Open ( os . path . join ( landsat_dir , tir [ 0 ] ) ) <NEWLINE> tir_band = TIR_path . GetRasterBand ( 1 ) . ReadAsArray ( ) . astype ( np . float32 ) <NEWLINE> snap = gdal . Open ( os . path . join ( landsat_dir , tir [ 0 ] ) ) <NEWLINE> <DEDENT>
num_arcs = auggraph . num_arcs ( ) <NEWLINE> <INDENT> changed = True <NEWLINE> d = 1 <NEWLINE> print ( <STRING> , end = <STRING> , flush = True ) <NEWLINE> while changed and d < project . radius : <NEWLINE> <INDENT> if d in augs : <NEWLINE> <INDENT> print ( <STRING> . format ( d ) , end = <STRING> , flush = True ) <NEWLINE> with open ( augname . format ( d ) , <STRING> ) as f : <NEWLINE> <INDENT> auggraph . add_arcs ( EdgeSet . from_ext ( f , self . id_map ) , d + 1 ) <NEWLINE> <DEDENT> <DEDENT> else : <NEWLINE> <INDENT> print ( d , end = <STRING> , flush = True ) <NEWLINE> dtf_step ( auggraph , d + 1 ) <NEWLINE> with open ( augname . format ( d ) , <STRING> ) as f : <NEWLINE> <INDENT> EdgeSet ( auggraph . arcs ( weight = d + 1 ) ) . write_ext ( f , self . id_map ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT> <DEDENT>
query_mh = query_sig . minhash <NEWLINE> <INDENT> query_mh = query_mh . downsample_max_hash ( frontier_mh ) <NEWLINE> frontier_mh = frontier_mh . downsample_max_hash ( query_mh ) <NEWLINE> <DEDENT>
if mh > 1 : <NEWLINE> <INDENT> n_merged += 1 <NEWLINE> merge_mh . merge ( mh ) <NEWLINE> <DEDENT>
if 1 : <NEWLINE> <INDENT> terminal = set ( ) <NEWLINE> for subnode in dag [ top_node_id ] : <NEWLINE> <INDENT> mh = load_minhash ( subnode , minhash_db ) <NEWLINE> if mh : <NEWLINE> <INDENT> terminal . update ( find_terminal_nodes ( subnode , args . maxsize ) ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT>
<COMMENT> <NL> <INDENT> d = defaultdict ( list ) <NEWLINE> for style , rules in iterate ( s1 ) : <NEWLINE> <INDENT> another_rules = s2 . get ( style ) <NEWLINE> if another_rules is None : <NEWLINE> <INDENT> d [ style ] . extend ( addall ( rules ) ) <NEWLINE> continue <NEWLINE> <DEDENT> for name , value in iterate ( rules ) : <NEWLINE> <INDENT> another_value = another_rules . get ( name ) <NEWLINE> if another_value is None : <NEWLINE> <INDENT> d [ style ] . append ( add ( name , value ) ) <NEWLINE> <DEDENT> elif value != another_value : <NEWLINE> <INDENT> d [ style ] . append ( change ( name , another_value , value ) ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT> return d <NEWLINE> <DEDENT>
class Collection ( WrenCollection ) : <NEWLINE> <INDENT> def handle_error ( self , response ) : <NEWLINE> <INDENT> import requests <NEWLINE> if response . status_code == requests . codes . not_found and response . json ( ) == { <STRING> : <STRING> } : <NEWLINE> <INDENT> raise NotFound ( response . text ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> super ( Collection , self ) . handle_error ( response ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT>
self . spawn_timer = Timer ( self . _spawn_heartbeat , 20 , <NEWLINE> <INDENT> single_shot = False ) <NEWLINE> self . spawn_timer . start ( ) <NEWLINE> <DEDENT>
def setup_order_workers ( self ) : <NEWLINE> <INDENT> self . _cxt . orders = FieldSet ( ) <NEWLINE> venue_names = self . _cfg . get ( <STRING> , { } ) . keys ( ) <NEWLINE> instr_names = self . _cfg . get ( <STRING> , { } ) <NEWLINE> self . logger . info ( <STRING> ) <NEWLINE> venue_instruments = 0 <NEWLINE> for k in venue_names : <NEWLINE> <INDENT> self . _cxt . orders [ k ] = { } <NEWLINE> venue = self . _venues [ k ] <NEWLINE> instr_defs = venue . get_instrument_defs ( instr_names ) <NEWLINE> for instr in instr_names : <NEWLINE> <INDENT> if not ( instr in instr_defs ) : continue <NEWLINE> self . logger . info ( <STRING> ) <NEWLINE> instrument = CosineInstrument . load ( self . instr_cache , ** instr_defs [ instr ] ) <NEWLINE> self . _cxt . instruments [ instrument . name ] = instrument <NEWLINE> order_worker = CosineOrderWorker ( self . _cfg . orders . ActiveDepth , instrument , venue , logger = self . logger ) <NEWLINE> self . _cxt . orders [ k ] [ instrument . symbol ] = order_worker <NEWLINE> venue_instruments += 1 <NEWLINE> <DEDENT> <DEDENT> if venue_instruments == 0 : <NEWLINE> <INDENT> raise LookupError ( <STRING> ) <NEWLINE> <DEDENT> <DEDENT>
def CTSget ( source , targets , identifiers , top_only = True , timeout = 60 , server = <STRING> ) : <NEWLINE> <INDENT> result = { } <NEWLINE> if type ( targets ) is str : <NEWLINE> <INDENT> result [ targets ] = CTS_translate_multi ( source , targets , identifiers , top_only , timeout , server ) <NEWLINE> <DEDENT> elif type ( targets ) is list : <NEWLINE> <INDENT> for i in range ( len ( targets ) ) : <NEWLINE> <INDENT> target = targets [ i ] <NEWLINE> print ( <STRING> + source + <STRING> + target ) <NEWLINE> result [ target ] = CTS_translate_multi ( source , target , identifiers , top_only , timeout , server ) <NEWLINE> <DEDENT> <DEDENT> else : <NEWLINE> <INDENT> raise IOError ( <STRING> ) <NEWLINE> <DEDENT> return result <NEWLINE> <DEDENT>
self . model = model <NEWLINE> <INDENT> self . nb_actions = nb_actions <NEWLINE> self . policy = policy <NEWLINE> self . test_policy = test_policy <NEWLINE> self . gamma = gamma <NEWLINE> self . nb_steps_warmup = nb_steps_warmup <NEWLINE> self . train_interval = train_interval <NEWLINE> <DEDENT>
def _type_variants ( self ) : <NEWLINE> <INDENT> self . out_json [ self . sample ] [ <STRING> ] = { } <NEWLINE> gt = VariantTyper ( <NEWLINE> <INDENT> expected_depths = self . expected_depths , <NEWLINE> error_rate = self . expected_error_rate , <NEWLINE> contamination_depths = self . contamination_depths , <NEWLINE> ignore_filtered = self . ignore_filtered , <NEWLINE> minor_freq = self . minor_freq , <NEWLINE> confidence_threshold = self . variant_confidence_threshold ) <NEWLINE> <DEDENT> genotypes = [ ] <NEWLINE> filters = [ ] <NEWLINE> for probe_name , probe_coverages in self . variant_covgs . items ( ) : <NEWLINE> <INDENT> probe_id = self . _name_to_id ( probe_name ) <NEWLINE> variant = None <NEWLINE> call = gt . type ( probe_coverages , variant = probe_name ) <NEWLINE> genotypes . append ( sum ( call [ <STRING> ] ) ) <NEWLINE> filters . append ( int ( call [ <STRING> ] [ <STRING> ] == <STRING> ) ) <NEWLINE> if sum ( call [ <STRING> ] ) > 0 or not call [ <NEWLINE> <INDENT> <STRING> ] or self . report_all_calls : <NEWLINE> self . variant_calls [ probe_name ] = call <NEWLINE> self . variant_calls_dict [ <NEWLINE> probe_id ] = call <NEWLINE> <DEDENT> <DEDENT> self . out_json [ self . sample ] [ <STRING> ] = genotypes <NEWLINE> self . out_json [ self . sample ] [ <STRING> ] = filters <NEWLINE> self . out_json [ self . sample ] [ <STRING> ] = self . variant_calls_dict <NEWLINE> <DEDENT>
def run ( self ) : <NEWLINE> <INDENT> self . create_folder ( ) <COMMENT> <NEWLINE> <COMMENT> <NL> answers = prompt ( questions , style = style ) <NEWLINE> self . answer = answers <NEWLINE> self . create_virtualenv ( ) <NEWLINE> self . main_structure ( ) <NEWLINE> self . write_file ( self . app , <STRING> , app_init ) <NEWLINE> self . write_file ( self . utils_path , <STRING> , utils_init ) <NEWLINE> self . write_file ( self . utils_path , <STRING> , logger ) <NEWLINE> self . write_file ( self . utils_path , <STRING> , response ) <NEWLINE> self . write_file ( self . instance , <STRING> , config ) <NEWLINE> self . make_env ( ) <NEWLINE> self . write_file ( self . folder_name , <STRING> , requirement_list ) <NEWLINE> self . write_file ( self . folder_name , <STRING> , docker_compose ) <NEWLINE> self . write_file ( self . folder_name , <STRING> , Dockerfile ) <NEWLINE> self . write_file ( self . folder_name , <STRING> , readme ) <NEWLINE> if answers . get ( <STRING> ) == <STRING> or not answers : <NEWLINE> <INDENT> self . write_file ( self . api_path , <STRING> , producer_restful ) <NEWLINE> self . write_file ( self . folder_name , <STRING> , run_restful ) <NEWLINE> <DEDENT> elif answers . get ( <STRING> ) == <STRING> : <NEWLINE> <INDENT> ask_redis = prompt ( redis_questions , style = style ) <NEWLINE> self . write_file ( self . api_path , <STRING> , producer_redis ) <NEWLINE> self . write_file ( self . folder_name , <STRING> , run_redis_pubsub ) <NEWLINE> self . write_file ( self . folder_name , <STRING> , redis_client ) <NEWLINE> self . add_env ( redis_credentials . format ( ask_redis . get ( <STRING> , <STRING> ) ) ) <NEWLINE> self . update_file ( self . folder_name , <STRING> , redis_required ) <NEWLINE> <COMMENT> <NL> os . makedirs ( self . development ) <NEWLINE> self . write_file ( self . development , <STRING> , <NEWLINE> <INDENT> redis_dockerfile . format ( ask_redis . get ( <STRING> , <STRING> ) ) ) <NEWLINE> <DEDENT> self . write_file ( self . development , <STRING> , redis_docker_compose ) <NEWLINE> <DEDENT> elif answers . get ( <STRING> ) == <STRING> : <NEWLINE> <INDENT> self . write_file ( self . api_path , <STRING> , producer_rabbitmq ) <NEWLINE> self . write_file ( self . folder_name , <STRING> , run_rabbitmq ) <NEWLINE> self . write_file ( self . folder_name , <STRING> , rabbit_client ) <NEWLINE> self . add_env ( rabbitmq_credentials ) <NEWLINE> self . update_file ( self . folder_name , <STRING> , rabbit_required ) <NEWLINE> <COMMENT> <NL> os . makedirs ( self . development ) <NEWLINE> self . write_file ( self . development , <STRING> , rabbit_enable_plugins ) <NEWLINE> self . write_file ( self . development , <STRING> , rabbit_docker_compose ) <NEWLINE> <DEDENT> <DEDENT>
try : <NEWLINE> <INDENT> new_node = etree . parse ( new_file ) . getroot ( ) <NEWLINE> except XMLSyntaxError as e : <NEWLINE> errorstore . add_error ( InvalidXML ( new_file , e . args [ 0 ] ) ) <NEWLINE> return <NEWLINE> else : <NEWLINE> traverse_course ( edxobj , new_node , new_file , errorstore , pointer = True ) <NEWLINE> return <NEWLINE> <DEDENT>
def show_list ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> self . _init_repo ( ) <NEWLINE> for filename in glob ( self . app . get_home_path ( ) + <STRING> ) : <NEWLINE> <INDENT> endpoint = Endpoint ( self . app , filename ) <NEWLINE> if endpoint . is_visible ( ) : <NEWLINE> <INDENT> print ( endpoint . path ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT>
def container_style ( request ) : <NEWLINE> <INDENT> classname = <STRING> <NEWLINE> if getattr ( settings , <STRING> , False ) : <NEWLINE> <INDENT> classname += <STRING> <NEWLINE> <DEDENT> return { <STRING> : classname } <NEWLINE> <DEDENT>
<COMMENT> <NL> <INDENT> os . chdir ( path_out ) <NEWLINE> nii_files = glob . glob ( <STRING> ) <NEWLINE> for nii_file in nii_files : <NEWLINE> <COMMENT> <NL> <INDENT> for contrast in list ( contrast_dict . keys ( ) ) : <NEWLINE> <COMMENT> <NL> <INDENT> if contrast in nii_file : <NEWLINE> <INDENT> print ( <STRING> + nii_file + <STRING> + contrast ) <NEWLINE> <COMMENT> <NL> nii_file_all_exts = glob . glob ( nii_file . strip ( <STRING> ) + <STRING> ) <NEWLINE> for nii_file_all_ext in nii_file_all_exts : <NEWLINE> <COMMENT> <NL> <INDENT> fname_out = os . path . join ( subject , contrast_dict [ contrast ] [ 1 ] , <NEWLINE> <INDENT> subject + <STRING> + contrast_dict [ contrast ] [ 0 ] + <STRING> <NEWLINE> + nii_file_all_ext . split ( os . extsep , 1 ) [ 1 ] ) <NEWLINE> <DEDENT> os . makedirs ( os . path . abspath ( os . path . dirname ( fname_out ) ) , exist_ok = True ) <NEWLINE> <COMMENT> <NL> shutil . move ( nii_file_all_ext , fname_out ) <NEWLINE> <DEDENT> break <NEWLINE> <DEDENT> <DEDENT> <DEDENT> <DEDENT>
def isstatic ( arguments ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> if len ( arguments ) == 0 : <NEWLINE> <INDENT> return True <NEWLINE> <DEDENT> elif not isinstance ( arguments [ 0 ] , var . SymbolObject ) : <NEWLINE> <INDENT> return True <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> return <STRING> != arguments [ 0 ] . name != <STRING> <NEWLINE> <DEDENT> <DEDENT>
if settings . DEBUG and getattr ( response_type , <STRING> , False ) : <NEWLINE>
def write_sorted_file ( fpath , outdir = None , cfg = None ) : <NEWLINE> <INDENT> if outdir is not None : <NEWLINE> <INDENT> fbasename = os . path . splitext ( os . path . basename ( fpath ) ) [ 0 ] <NEWLINE> sorted_fpath = os . path . join ( outdir , <STRING> . format ( fbasename ) ) <NEWLINE> tmp = unicode_writer ( open ( sorted_fpath , <STRING> ) ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> tmp = unicode_writer ( NamedTemporaryFile ( <STRING> ) ) <NEWLINE> <DEDENT> <DEDENT>
def get_tracking_delta ( self ) : <NEWLINE> <INDENT> if len ( self . track_value_list ) == self . track_average_epoc_count : <NEWLINE> <INDENT> return sum ( <NEWLINE> <INDENT> [ self . track_value_list [ idx + 1 ] - <NEWLINE> <INDENT> self . track_value_list [ idx ] <NEWLINE> for idx in range ( len ( self . track_value_list ) - 1 ) ] ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT> else : <NEWLINE> <INDENT> return 0 <NEWLINE> <DEDENT> <DEDENT>
for jrid , jrdef in sorted ( list ( runs ) ) : <NEWLINE> <INDENT> yield jrid <NEWLINE> <DEDENT>
if len ( intensive_variables ) > 0 : <NEWLINE> <INDENT> profile = pd . DataFrame ( interpolation [ 1 ] , columns = intensive_variables ) <NEWLINE> profiles . append ( profile ) <NEWLINE> <DEDENT>
__implicit_features [ v ] = feature <NEWLINE>
<COMMENT> <NL> <COMMENT> <NL> <INDENT> for r in requirements : <NEWLINE> <COMMENT> <NL> <INDENT> if not r . condition ( ) : <NEWLINE> <INDENT> required [ r . feature ( ) ] = r <NEWLINE> <DEDENT> <DEDENT> <DEDENT>
__module_flags . setdefault ( module , [ ] ) . append ( f ) <NEWLINE> <INDENT> __flags . setdefault ( rule_or_module , [ ] ) . append ( f ) <NEWLINE> <DEDENT>
@ numba . njit ( cache = True ) <NEWLINE> <INDENT> def _get_edges ( clustering1 : np . array , clustering2 : np . array ) : <NEWLINE> <INDENT> edges = [ ] <NEWLINE> offset1 = clustering1 . min ( ) <NEWLINE> offset2 = clustering2 . min ( ) <NEWLINE> <COMMENT> <NL> <COMMENT> <NL> offset_clusts1 = clustering1 - offset1 <NEWLINE> offset_clusts2 = clustering2 - offset2 <NEWLINE> <COMMENT> <NL> nclusts1 = offset_clusts1 . max ( ) + 1 <NEWLINE> nclusts2 = offset_clusts2 . max ( ) + 1 <NEWLINE> coincidence = np . zeros ( ( nclusts1 , nclusts2 ) ) <NEWLINE> <COMMENT> <NL> ncells1 = np . zeros ( nclusts1 ) <NEWLINE> ncells2 = np . zeros ( nclusts2 ) <NEWLINE> <COMMENT> <NL> for cell in range ( len ( clustering1 ) ) : <NEWLINE> <INDENT> c1 = offset_clusts1 [ cell ] <NEWLINE> c2 = offset_clusts2 [ cell ] <NEWLINE> coincidence [ c1 , c2 ] += 1 <NEWLINE> ncells1 [ c1 ] += 1 <NEWLINE> ncells2 [ c2 ] += 1 <NEWLINE> <DEDENT> for cidx1 , cidx2 in np . ndindex ( coincidence . shape ) : <NEWLINE> <INDENT> isize = coincidence [ cidx1 , cidx2 ] <NEWLINE> if isize < 1 : <NEWLINE> <INDENT> continue <NEWLINE> <DEDENT> jaccard_sim = isize / ( ncells1 [ cidx1 ] + ncells2 [ cidx2 ] - isize ) <NEWLINE> edge = ( cidx1 + offset1 , cidx2 + offset2 , jaccard_sim ) <NEWLINE> edges . append ( edge ) <NEWLINE> <DEDENT> return edges <NEWLINE> <DEDENT> <DEDENT>
def _request ( self , resource , method , args = None , data = None , headers = None ) : <NEWLINE> <INDENT> response_data = None <NEWLINE> request_body = self . _serialize ( data ) <NEWLINE> response_headers , response_content = self . _connection . request ( resource , method , args = args , body = request_body , headers = headers , content_type = self . content_type ) <NEWLINE> if response_headers . get ( <STRING> ) == HTTP_STATUS_OK : <NEWLINE> <INDENT> response_data = self . _deserialize ( response_content ) <NEWLINE> <DEDENT> return Response ( response_headers , response_content , response_data ) <NEWLINE> <DEDENT>
def main ( ) : <NEWLINE> <INDENT> parser = argparse . ArgumentParser ( prog = <STRING> . format ( __package__ ) , <NEWLINE> <INDENT> description = <STRING> ) <NEWLINE> <COMMENT> <NL> <DEDENT> parser . add_argument ( <STRING> , nargs = <STRING> , metavar = <STRING> , <NEWLINE> <INDENT> help = <STRING> ) <NEWLINE> <DEDENT> parser . add_argument ( <STRING> , action = <STRING> , <NEWLINE> <INDENT> help = <STRING> ) <NEWLINE> <DEDENT> parser . add_argument ( <STRING> , <STRING> , action = <STRING> , <NEWLINE> <INDENT> help = <STRING> ) <NEWLINE> <DEDENT> parser . add_argument ( <STRING> , action = <STRING> , <NEWLINE> <INDENT> help = <STRING> ) <NEWLINE> <DEDENT> args = parser . parse_args ( ) <NEWLINE> <DEDENT>
args [ <STRING> ] = request <NEWLINE> <INDENT> try : <NEWLINE> <INDENT> if cache . get ( cache_key ) : <NEWLINE> <INDENT> try : <NEWLINE> <INDENT> parsed = re . sub ( <STRING> + item + <STRING> , cache . get ( cache_key ) , parsed ) <NEWLINE> <DEDENT> except : <NEWLINE> <INDENT> pass <NEWLINE> <DEDENT> <DEDENT> else : <NEWLINE> <INDENT> module = import_parser ( <STRING> + name ) <NEWLINE> function = getattr ( module , <STRING> ) <NEWLINE> result = function ( args ) <NEWLINE> try : <NEWLINE> <INDENT> cache . set ( cache_key , result , 3600 ) <NEWLINE> parsed = re . sub ( <STRING> + re . escape ( item ) + <STRING> , result , parsed ) <NEWLINE> <DEDENT> except : <NEWLINE> <INDENT> pass <NEWLINE> <DEDENT> <DEDENT> <DEDENT> except ImportError : <NEWLINE> <INDENT> pass <NEWLINE> return parsed <NEWLINE> <DEDENT> <DEDENT>
async with self . _session . post ( <NEWLINE> <INDENT> self . url , <NEWLINE> params = { <STRING> : <STRING> , ** self . params } , <NEWLINE> data = query . encode ( ) , <NEWLINE> ) as response : <NEWLINE> if response . status != 200 : <NEWLINE> <INDENT> body = await response . read ( ) <NEWLINE> raise DBException . from_message ( <NEWLINE> <INDENT> query , body . decode ( errors = <STRING> ) , <NEWLINE> <DEDENT> ) <NEWLINE> <DEDENT> <DEDENT>
if default != NoValue : <NEWLINE> <INDENT> if auto_increment or primary : <NEWLINE> <INDENT> raise ValueError ( <STRING> <STRING> ) <NEWLINE> <DEDENT> scolumn += <STRING> <NEWLINE> values . append ( default ) <NEWLINE> <DEDENT>
return center <NEWLINE>
<COMMENT> <NL> <INDENT> failure_states = set ( ) <NEWLINE> for s in filter ( lambda x : x not in z_current , dfa . states ) : <NEWLINE> <INDENT> state2level [ s ] = level <NEWLINE> failure_states . add ( s ) <NEWLINE> <DEDENT> <DEDENT>
return SteaResult ( client . calculate ( request ) , stea_input ) <NEWLINE>
for j in range ( n_classes ) : <NEWLINE> <INDENT> print ( <STRING> . format ( conf_mat_v [ i ] [ j ] ) , end = <STRING> ) <NEWLINE> print ( <STRING> ) <NEWLINE> print ( <STRING> ) <NEWLINE> <DEDENT>
else : <NEWLINE> <INDENT> intcheck = ( numerics % 1 ) == 0 <NEWLINE> if np . sum ( intcheck ) / length > 0.9 : <NEWLINE> <INDENT> if <STRING> not in old_metadata [ <STRING> ] : <NEWLINE> <INDENT> old_metadata [ <STRING> ] += ( <STRING> , ) <NEWLINE> old_metadata [ <STRING> ] = type ( 10 ) <NEWLINE> inputs . iloc [ : , col ] = numerics <NEWLINE> <DEDENT> <DEDENT> else : <NEWLINE> <INDENT> if <STRING> not in old_metadata [ <STRING> ] : <NEWLINE> <INDENT> old_metadata [ <STRING> ] += ( <STRING> , ) <NEWLINE> old_metadata [ <STRING> ] = type ( 10.2 ) <NEWLINE> inputs . iloc [ : , col ] = numerics <NEWLINE> <DEDENT> <DEDENT> <DEDENT>
<COMMENT> <NL> <INDENT> if <STRING> in rule [ 1 ] : <NEWLINE> <COMMENT> <NL> <INDENT> for pattern in shlex . split ( rule [ 1 ] [ <STRING> ] ) : <NEWLINE> <INDENT> if rule [ 1 ] [ <STRING> ] == <STRING> : <NEWLINE> <INDENT> sql_tuple = FilterTree . text_similarity_filter ( rule [ 0 ] , pattern , True ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> sql_tuple = FilterTree . text_similarity_filter ( rule [ 0 ] , pattern , False ) <NEWLINE> <DEDENT> rule_specs . append ( sql_tuple ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT>
class Path ( AbstractPath ) : <NEWLINE> <INDENT> abs = abspath = property ( lambda self : pth ( ospath . abspath ( self ) ) ) <NEWLINE> exists = property ( lambda self : ospath . exists ( self ) ) <NEWLINE> lexists = property ( lambda self : ospath . lexists ( self ) ) <NEWLINE> expanduser = property ( lambda self : pth ( ospath . expanduser ( self ) ) ) <NEWLINE> expandvars = property ( lambda self : pth ( ospath . expandvars ( self ) ) ) <NEWLINE> atime = property ( lambda self : ospath . getatime ( self ) ) <NEWLINE> ctime = property ( lambda self : ospath . getctime ( self ) ) <NEWLINE> mtime = property ( lambda self : ospath . getmtime ( self ) ) <NEWLINE> size = property ( lambda self : ospath . getsize ( self ) ) <NEWLINE> isdir = property ( lambda self : ospath . isdir ( self ) ) <NEWLINE> isfile = property ( lambda self : ospath . isfile ( self ) ) <NEWLINE> islink = property ( lambda self : ospath . islink ( self ) ) <NEWLINE> ismount = property ( lambda self : ospath . ismount ( self ) ) <NEWLINE> joinpath = pathjoin = __div__ = __floordiv__ = __truediv__ = lambda self , * args : pth ( ospath . join ( self , * args ) ) <NEWLINE> normcase = property ( lambda self : pth ( ospath . normcase ( self ) ) ) <NEWLINE> normpath = property ( lambda self : pth ( ospath . normpath ( self ) ) ) <NEWLINE> norm = property ( lambda self : pth ( ospath . normcase ( ospath . normpath ( self ) ) ) ) <NEWLINE> real = realpath = property ( lambda self : pth ( ospath . realpath ( self ) ) ) <NEWLINE> rel = relpath = lambda self , start : pth ( ospath . relpath ( start , self ) ) <NEWLINE> same = samefile = lambda self , other : ospath . samefile ( self , other ) <NEWLINE> if hasattr ( os , <STRING> ) : <NEWLINE> <INDENT> if PY33 : <NEWLINE> <INDENT> link = lambda self , dest , follow_symlinks = True , ** kwargs : os . link ( self , dest , follow_symlinks = follow_symlinks , ** kwargs ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> link = lambda self , dest : os . link ( self , dest ) <NEWLINE> <DEDENT> <DEDENT> if PY33 : <NEWLINE> <INDENT> stat = property ( lambda self : LazyObjectProxy ( lambda ** kwargs : os . stat ( self , ** kwargs ) ) ) <NEWLINE> lstat = property ( lambda self : LazyObjectProxy ( lambda ** kwargs : os . lstat ( self , ** kwargs ) ) ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> stat = property ( lambda self : os . stat ( self ) ) <NEWLINE> lstat = property ( lambda self : os . lstat ( self ) ) <NEWLINE> <DEDENT> isreadable = property ( lambda self : LazyObjectProxy ( lambda ** kwargs : os . access ( self , os . R_OK , ** kwargs ) ) ) <NEWLINE> mkdir = lambda self : os . mkdir ( self ) <NEWLINE> makedirs = lambda self : os . makedirs ( self ) <NEWLINE> if hasattr ( os , <STRING> ) : <NEWLINE> <INDENT> pathconf = lambda self , name : os . pathconf ( self , name ) <NEWLINE> <DEDENT> if hasattr ( os , <STRING> ) : <NEWLINE> <INDENT> readlink = property ( lambda self : os . readlink ( self ) ) <NEWLINE> <DEDENT> if hasattr ( os , <STRING> ) : <NEWLINE> <INDENT> fsencode = fsencoded = property ( lambda self : os . fsencode ( self ) ) <NEWLINE> <DEDENT> access = lambda self , mode , ** kwargs : os . access ( self , mode , ** kwargs ) <NEWLINE> if PY33 : <NEWLINE> <INDENT> isreadable = property ( lambda self : LazyObjectProxy ( lambda ** kwargs : os . access ( self , os . R_OK , ** kwargs ) ) ) <NEWLINE> iswritable = property ( lambda self : LazyObjectProxy ( lambda ** kwargs : os . access ( self , os . W_OK , ** kwargs ) ) ) <NEWLINE> isexecutable = property ( lambda self : LazyObjectProxy ( lambda ** kwargs : os . access ( self , os . R_OK | os . X_OK , ** kwargs ) ) ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> isreadable = property ( lambda self : os . access ( self , os . R_OK ) ) <NEWLINE> iswritable = property ( lambda self : os . access ( self , os . W_OK ) ) <NEWLINE> isexecutable = property ( lambda self : os . access ( self , os . R_OK | os . X_OK ) ) <NEWLINE> <DEDENT> if hasattr ( os , <STRING> ) : <NEWLINE> <INDENT> chroot = lambda self : os . chroot ( self ) <NEWLINE> <DEDENT> if hasattr ( os , <STRING> ) : <NEWLINE> <INDENT> chflags = lambda self , flags , follow_symlinks = True : os . chflags ( self , flags ) if follow_symlinks else os . lchflags ( self , flags ) <NEWLINE> lchflags = lambda self , flags : os . lchflags ( self , flags ) <NEWLINE> <DEDENT> <DEDENT>
( mode , ino , dev , nlink , uid , gid , size , atime , mtime , ctime ) = _stat ( _fd ) <NEWLINE> <COMMENT> <NL> <COMMENT> <NL> <COMMENT> <NL> <COMMENT> <NL> <COMMENT> <NL> <INDENT> return time . strftime ( <NEWLINE> <INDENT> <STRING> , <NEWLINE> time . gmtime ( mtime ) <NEWLINE> <DEDENT> ) <NEWLINE> <DEDENT>
@ cli . command ( <STRING> , short_help = <STRING> ) <NEWLINE> <INDENT> @ click . option ( <STRING> , <STRING> , <NEWLINE> <INDENT> type = str , <NEWLINE> required = False , <NEWLINE> help = <STRING> ) <NEWLINE> <DEDENT> @ click . option ( <STRING> , <STRING> , <NEWLINE> <INDENT> type = int , <NEWLINE> required = False , <NEWLINE> help = <STRING> ) <NEWLINE> <DEDENT> @ pass_context <NEWLINE> def remove ( ctx , name = None , index = None ) : <NEWLINE> <INDENT> connectionsCsvLocation = resource_filename ( Requirement . parse ( <STRING> ) , <STRING> ) <NEWLINE> with open ( connectionsCsvLocation ) as connectionFile : <NEWLINE> <INDENT> connections = list ( csv . DictReader ( connectionFile , delimiter = <STRING> ) ) <NEWLINE> <DEDENT> print ( connectionsCsvLocation ) <NEWLINE> if ( name is None and index is None ) : <NEWLINE> <INDENT> cli_utils . print_result ( connections , ctx . logger , as_json = ctx . json , as_pickle = ctx . pickle , depth = ctx . depth , filter_tree = ctx . filter_tree ) <NEWLINE> <DEDENT> if ( name is None and index is not None ) : <NEWLINE> <INDENT> cli_utils . print_result ( connections [ int ( index ) ] , ctx . logger , as_json = ctx . json , as_pickle = ctx . pickle , depth = ctx . depth , filter_tree = ctx . filter_tree ) <NEWLINE> <DEDENT> if ( name is not None and index is None ) : <NEWLINE> <INDENT> connections = [ connection for connection in connections if connection [ <STRING> ] == name ] <NEWLINE> cli_utils . print_result ( connections , ctx . logger , as_json = ctx . json , as_pickle = ctx . pickle , depth = ctx . depth , filter_tree = ctx . filter_tree ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT>
def delay_job ( self , job , time_delta ) : <NEWLINE> <INDENT> amount = int ( time_delta . total_seconds ( ) ) <NEWLINE> self . connection . zincrby ( self . scheduler_jobs_key , amount , job . id ) <NEWLINE> <DEDENT>
for spouse_uid in spouse_uids : <NEWLINE> <INDENT> try : <NEWLINE> <INDENT> spouse = family . uid_to_person ( spouse_uid ) <NEWLINE> <DEDENT> except TypeError as e : <NEWLINE> <INDENT> print ( <STRING> ) <NEWLINE> print ( <STRING> ) <NEWLINE> continue <NEWLINE> <DEDENT> spouses = [ <NEWLINE> <INDENT> family . uid_to_person ( relation [ 1 ] ) <NEWLINE> for relation in big_dict [ <STRING> ] <NEWLINE> if relation [ 0 ] == spouse_uid <NEWLINE> <DEDENT> ] <NEWLINE> family . add_spouses ( spouse , spouses ) <NEWLINE> <DEDENT>
<COMMENT> <NL> <INDENT> if isinstance ( db , SQLAlchemy ) : <NEWLINE> <INDENT> role1 = db_adapter . find_first_object ( RoleClass , name = <STRING> ) <NEWLINE> db_adapter . delete_object ( role1 ) <NEWLINE> role2 = db_adapter . find_first_object ( RoleClass , name = <STRING> ) <NEWLINE> db_adapter . delete_object ( role2 ) <NEWLINE> <DEDENT> <DEDENT>
if ( outer_sort == outer_sort_next ) : <NEWLINE> <INDENT> if ( inner_sort < inner_sort_next ) : <NEWLINE> <INDENT> print ( <STRING> <NEWLINE> <INDENT> <STRING> <NEWLINE> . format ( halo_id , opt [ <STRING> ] , inner_sort , halo_id_next , <NEWLINE> inner_sort_next ) ) <NEWLINE> <DEDENT> print ( <STRING> <NEWLINE> <INDENT> <STRING> . format ( opt [ <STRING> ] ) ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT>
if ( outer_sort == outer_sort_next ) : <NEWLINE> <INDENT> if ( inner_sort > inner_sort_next ) : <NEWLINE> <INDENT> print ( <STRING> <NEWLINE> <INDENT> <STRING> <NEWLINE> . format ( halo_id , opt [ <STRING> ] , inner_sort , halo_id_next , <NEWLINE> inner_sort_next ) ) <NEWLINE> <DEDENT> print ( <STRING> <NEWLINE> <INDENT> <STRING> . format ( opt [ <STRING> ] ) ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT>
<COMMENT> <NL> <INDENT> features = int . from_bytes ( buf [ 166 ] + buf [ 167 ] , byteorder = <STRING> ) <NEWLINE> if features & 0x400 : <NEWLINE> <INDENT> self . lba48bit = True <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> self . lba48bit = False <NEWLINE> <DEDENT> <DEDENT>
<COMMENT> <NL> <INDENT> fig . text ( x = .5 , y = .99 , s = qpi_sim [ <STRING> ] , <NEWLINE> <INDENT> verticalalignment = <STRING> , <NEWLINE> horizontalalignment = <STRING> , <NEWLINE> fontsize = 14 ) <NEWLINE> <DEDENT> <DEDENT>
def validate_python ( self , values , state ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> email = values [ <STRING> ] <NEWLINE> if email : <COMMENT> <NEWLINE> <INDENT> user = AuthUser . get_by_email ( email ) <NEWLINE> <COMMENT> <NL> <COMMENT> <NL> if values . has_key ( <STRING> ) : <NEWLINE> <INDENT> user_id = values [ <STRING> ] <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> user_id = None <NEWLINE> <DEDENT> if user and ( user . user_id != user_id ) : <NEWLINE> <INDENT> errors = { <STRING> : self . message ( <STRING> , state ) } <NEWLINE> raise Invalid ( self . message ( <STRING> , state ) , <NEWLINE> <INDENT> values , state , error_dict = errors ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT> <DEDENT>
for value in [ command [ <STRING> ] , command [ <STRING> ] , command [ <STRING> ] , command [ <STRING> ] ] : <NEWLINE> <INDENT> if value != - 1 : <NEWLINE> <INDENT> if value < 0 or value > 1 : <NEWLINE> <INDENT> raise ValueError ( <STRING> ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT>
if process . returncode != 0 : <NEWLINE> <INDENT> msg = <STRING> <NEWLINE> logger . error ( msg ) <NEWLINE> raise SetupError ( msg ) <NEWLINE> else : <NEWLINE> logger . info ( <STRING> ) <NEWLINE> logger . info ( <STRING> ) <NEWLINE> <DEDENT>
<COMMENT> <NL> <INDENT> dimu_pt , dimu_phi , dimu_para , dimu_perp = create_metres ( <NEWLINE> <INDENT> event . METnoX , event . MuonSelection , <NEWLINE> <DEDENT> ) <NEWLINE> event . DiMuon_pt = dimu_pt <NEWLINE> event . DiMuon_phi = dimu_phi <NEWLINE> event . METnoX_diMuonParaProjPt = dimu_para <NEWLINE> event . METnoX_diMuonPerpProjPt = dimu_perp <NEWLINE> event . METnoX_diMuonParaProjPt_Minus_DiMuon_pt = dimu_para - dimu_pt <NEWLINE> event . METnoX_diMuonPerpProjPt_Plus_DiMuon_pt = dimu_perp + dimu_pt <NEWLINE> event . METnoX_diMuonParaProjPt_Div_DiMuon_pt = dimu_para / dimu_pt <NEWLINE> event . METnoX_diMuonPerpProjPt_Plus_DiMuon_pt_Div_DiMuon_pt = ( dimu_perp + dimu_pt ) / dimu_pt <NEWLINE> <DEDENT>
for name , obj in getattr ( mod , <STRING> , { } ) . iteritems ( ) : <NEWLINE> <INDENT> scope [ name ] = obj <NEWLINE> <DEDENT>
def _scheduler ( self , epoch ) : <NEWLINE> <INDENT> if epoch % self . decay_after_n_epoch == 0 and epoch != 0 : <NEWLINE> <INDENT> lr = K . get_value ( self . model . optimizer . lr ) <NEWLINE> K . set_value ( self . model . optimizer . lr , lr * self . decay_rate ) <NEWLINE> print ( <STRING> . format ( lr * self . decay_rate ) ) <NEWLINE> <DEDENT> return K . get_value ( self . model . optimizer . lr ) <NEWLINE> <DEDENT>
@ _run <NEWLINE> <INDENT> def update ( self , document , target , ** kargs ) : <NEWLINE> <INDENT> self . _db [ document ] . update ( target , kargs , callback = self . callback ) <NEWLINE> <DEDENT> <DEDENT>
structure_txt = generate_LAMMPS_structure ( structure ) <NEWLINE> <INDENT> input_txt = generate_LAMMPS_input ( potential_object , <NEWLINE> <INDENT> parameters_data , <NEWLINE> structure_file = self . _INPUT_STRUCTURE , <NEWLINE> optimize_path_file = self . _OUTPUT_TRAJECTORY_FILE_NAME ) <NEWLINE> <DEDENT> <DEDENT>
if max_stress < test_range [ 1 ] and min_stress > test_range [ 0 ] : <NEWLINE> <INDENT> if abs ( max_stress - test_range [ 1 ] ) < interval * 2 or abs ( test_range [ 0 ] - min_stress ) < interval * 2 : <NEWLINE> <INDENT> interval *= 0.5 <NEWLINE> <DEDENT> <DEDENT>
if isinstance ( radius , Variable ) : <NEWLINE> <INDENT> self . _radius = dcopy ( radius ) <NEWLINE> else : <NEWLINE> self . _radius = Variable ( <NEWLINE> <INDENT> <STRING> , <NEWLINE> radius , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> + str ( name ) + <STRING> , <NEWLINE> <DEDENT> ) <NEWLINE> if not self . _radius . scalar : <NEWLINE> raise ValueError ( <STRING> ) <NEWLINE> if self . radius < 0.0 : <NEWLINE> raise ValueError ( <STRING> ) <NEWLINE> <DEDENT>
observation = varlib . Observation ( name , obs , time , description ) <NEWLINE> <INDENT> except Exception : <NEWLINE> <INDENT> raise Exception ( <STRING> ) <NEWLINE> <DEDENT> return observation <NEWLINE> <DEDENT>
response = await venom . invoke ( method , request , context = AioHTTPRequestContext ( http_request ) ) <NEWLINE> <INDENT> return web . Response ( body = rpc_response . pack ( response ) , <NEWLINE> <INDENT> content_type = rpc_response . mime , <NEWLINE> status = http_status ) <NEWLINE> except Error as e : <NEWLINE> <DEDENT> return web . Response ( body = rpc_error_response . pack ( e . format ( ) ) , <NEWLINE> <INDENT> content_type = rpc_error_response . mime , <NEWLINE> status = e . http_status ) <NEWLINE> <DEDENT> <DEDENT>
<COMMENT> <NL> <INDENT> app_index_class = getattr ( app_config , <STRING> , None ) <NEWLINE> if app_index_class : <NEWLINE> <INDENT> template_name = getattr ( app_index_class , <STRING> , <STRING> ) <NEWLINE> app_index = app_index_class . as_view ( <NEWLINE> <INDENT> app_config = app_config , backend = self , template_name = template_name <NEWLINE> <DEDENT> ) <NEWLINE> urlpatterns [ None ] . append ( url ( <STRING> , app_index , name = <STRING> ) ) <NEWLINE> <DEDENT> <DEDENT>
@ classmethod <NEWLINE> <INDENT> def from_time ( cls , command , user , time ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> assert len ( time ) <= 5 <NEWLINE> padded_time = tuple ( time ) + ( <STRING> , ) * ( 5 - len ( time ) ) <NEWLINE> assert len ( padded_time ) == 5 <NEWLINE> return cls ( command , padded_time [ 0 ] , user , padded_time [ 1 ] , padded_time [ 2 ] , padded_time [ 3 ] , padded_time [ 4 ] ) <NEWLINE> <DEDENT> <DEDENT>
@ classmethod <NEWLINE> <INDENT> def from_time ( cls , command , user , time ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> if len ( time ) > 5 : <NEWLINE> <INDENT> raise RuntimeError ( <STRING> . format ( time ) ) <NEWLINE> <DEDENT> padded_time = tuple ( time ) + ( <STRING> , ) * ( 5 - len ( time ) ) <NEWLINE> if len ( padded_time ) != 5 : <NEWLINE> <INDENT> raise RuntimeError ( <STRING> . format ( padded_time ) ) <NEWLINE> <DEDENT> return cls ( command , padded_time [ 0 ] , user , padded_time [ 1 ] , padded_time [ 2 ] , padded_time [ 3 ] , padded_time [ 4 ] ) <NEWLINE> <DEDENT> <DEDENT>
def send_message ( self , frameid , blob ) : <NEWLINE> <INDENT> self . _sending = True <NEWLINE> d = self . merger . write_blob ( frameid , blob ) <NEWLINE> def done ( result ) : <NEWLINE> <INDENT> self . _sending = False <NEWLINE> return result <NEWLINE> <DEDENT> d . addBoth ( done ) <NEWLINE> <DEDENT>
if isinstance ( t , Workflow ) : <NEWLINE> <INDENT> wf_wdl , _ , wf_tools = t . wdl ( with_docker = with_docker , is_nested_tool = True ) <NEWLINE> wtools [ s . id ( ) ] = wf_wdl <NEWLINE> wtools . update ( wf_tools ) <NEWLINE> else : <NEWLINE> wtools [ t . id ( ) ] = t . wdl ( with_docker = with_docker ) <NEWLINE> <DEDENT>
z , edges = np . histogram ( data . ids , <NEWLINE> <INDENT> bins = np . arange ( - 0.5 , data . nx * data . ny + 0.5 ) ) <NEWLINE> z = z . reshape ( data . ny , data . nx ) <NEWLINE> if side_panels : <NEWLINE> z_sumx = np . sum ( z , axis = 1 ) <NEWLINE> z_sumy = np . sum ( z , axis = 0 ) <NEWLINE> <DEDENT>
t = np . linspace ( 0.0 , 7.2e4 , nbins + 1 ) <NEWLINE> <INDENT> z , xe , ye = np . histogram2d ( data . ids , data . tofs / 1.0e3 , <NEWLINE> <INDENT> bins = [ np . arange ( - 0.5 , data . nx * data . ny + 0.5 ) , <NEWLINE> <INDENT> t ] ) <NEWLINE> <DEDENT> <DEDENT> z = z . reshape ( data . ny , data . nx , nbins ) <NEWLINE> <COMMENT> <NL> if transpose : <NEWLINE> <INDENT> z = np . transpose ( z , axes = [ 1 , 0 , 2 ] ) <NEWLINE> <DEDENT> clab = <STRING> <NEWLINE> if log : <NEWLINE> <INDENT> with np . errstate ( divide = <STRING> , invalid = <STRING> ) : <NEWLINE> <INDENT> z = np . log10 ( z ) <NEWLINE> <DEDENT> clab = <STRING> . format ( clab ) <NEWLINE> <DEDENT> <DEDENT>
print ( <STRING> ) <NEWLINE> <INDENT> for s in stringers . values ( ) : <NEWLINE> <INDENT> s . elements = [ bdf . elements [ eid ] for eid in s . eids ] <NEWLINE> setelements = set ( s . elements ) <NEWLINE> <DEDENT> print ( <STRING> ) <NEWLINE> <DEDENT>
value = logical_value <NEWLINE> <INDENT> if reg == Register . HUE : <NEWLINE> <INDENT> if logical_value in ( 0.0 , 360.0 ) : <NEWLINE> <INDENT> value = 0.0 <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> value = ( logical_value % 360.0 ) / 360.0 * 65535.0 <NEWLINE> <DEDENT> <DEDENT> elif reg in ( Register . BRIGHTNESS , Register . SATURATION ) : <NEWLINE> <INDENT> if logical_value >= 100.0 : <NEWLINE> <INDENT> value = 65535.0 <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> value = logical_value / 100.0 * 65535.0 <NEWLINE> <DEDENT> <DEDENT> elif reg in ( Register . DURATION , Register . TIME ) : <NEWLINE> <INDENT> value = logical_value * 1000.0 <NEWLINE> <DEDENT> <DEDENT>
sepcon = ( Group ( Literal ( <STRING> ) + Literal ( <STRING> ) - <NEWLINE> <INDENT> contract_expression ( <STRING> ) - Literal ( <STRING> ) ) ) <NEWLINE> sepcon . setParseAction ( SeparateContext . parse_action ) <NEWLINE> sepcon . setName ( <STRING> ) <NEWLINE> add_contract ( sepcon ) <NEWLINE> <DEDENT>
<COMMENT> <NL> <INDENT> if gap_filling != None and ~ np . isnan ( np . nanmean ( Array_end ) ) : <NEWLINE> <INDENT> Array_end [ np . isnan ( Array_end ) ] = - 9999 <NEWLINE> Array_end = RC . gap_filling ( Array_end , - 9999 , gap_filling ) <NEWLINE> <DEDENT> Array_end = Array_end * MASK <NEWLINE> <DEDENT>
if not np . isnan ( np . nanmean ( Crop_S1_End . Data ) ) : <NEWLINE> <INDENT> for Date_Year in Dates_Years : <NEWLINE> <INDENT> year_diff = int ( Date_Year . year - Dates_Years [ 0 ] . year ) <NEWLINE> for dekad in range ( 0 , int ( np . nanmax ( Crop_S3_End . Data ) ) ) : <NEWLINE> <INDENT> Accumulated_NPP_Data_Start_S1 [ year_diff , Crop_S1_End . Data [ year_diff , : , : ] == dekad ] = NPPcum . Data [ np . minimum ( NPPcum . Size [ 0 ] - 1 , int ( year_diff * 36 + dekad - 1 ) ) , Crop_S1_End . Data [ year_diff , : , : ] == dekad ] <NEWLINE> Accumulated_NPP_Data_Start_S2 [ year_diff , Crop_S2_End . Data [ year_diff , : , : ] == dekad ] = NPPcum . Data [ np . minimum ( NPPcum . Size [ 0 ] - 1 , int ( year_diff * 36 + dekad - 1 ) ) , Crop_S2_End . Data [ year_diff , : , : ] == dekad ] <NEWLINE> Accumulated_NPP_Data_Start_S3 [ year_diff , Crop_S3_End . Data [ year_diff , : , : ] == dekad ] = NPPcum . Data [ np . minimum ( NPPcum . Size [ 0 ] - 1 , int ( year_diff * 36 + dekad - 1 ) ) , Crop_S3_End . Data [ year_diff , : , : ] == dekad ] <NEWLINE> <DEDENT> <DEDENT> <DEDENT>
def get_positive_stabilizer_groups ( n_qubits , n_states ) : <NEWLINE> <INDENT> if n_states == n_stabilizer_states ( n_qubits ) : <NEWLINE> <COMMENT> <NL> <COMMENT> <NL> <INDENT> target = n_states / pow ( 2 , n_qubits ) <NEWLINE> <DEDENT> else : <NEWLINE> <COMMENT> <NL> <INDENT> target = n_states <NEWLINE> <DEDENT> bitstrings = gen_bitstrings ( n_qubits ) <NEWLINE> subspaces = [ ] <NEWLINE> generators = [ ] <NEWLINE> for group in combinations ( bitstrings , n_qubits ) : <NEWLINE> <INDENT> if len ( group ) == 2 : <NEWLINE> <INDENT> if not test_commutivity ( n_qubits , group [ 0 ] , group [ 1 ] ) : <NEWLINE> <INDENT> continue <NEWLINE> <DEDENT> <DEDENT> if len ( group ) > 2 : <NEWLINE> <INDENT> if not all ( [ test_commutivity ( n_qubits , pair [ 0 ] , pair [ 1 ] ) <NEWLINE> <INDENT> for pair in combinations ( group , 2 ) ] ) : <NEWLINE> continue <NEWLINE> <DEDENT> <DEDENT> candidate = BinarySubspace ( * group ) <NEWLINE> if len ( candidate . generators ) < n_qubits : <NEWLINE> <INDENT> continue <NEWLINE> <DEDENT> if len ( candidate . _items ) < pow ( 2 , n_qubits ) : <NEWLINE> <INDENT> continue <NEWLINE> <DEDENT> res = tuple ( i for i in sorted ( candidate . _items , key = bool_to_int ) ) <NEWLINE> for space in subspaces : <NEWLINE> <INDENT> if np . all ( [ np . array_equal ( _el1 , _el2 ) for _el1 , _el2 in zip ( res , space ) ] ) : <NEWLINE> <INDENT> continue <NEWLINE> <DEDENT> <DEDENT> subspaces . append ( res ) <NEWLINE> generators . append ( tuple ( candidate . generators ) ) <NEWLINE> if len ( generators ) == target : <NEWLINE> <INDENT> break <NEWLINE> <DEDENT> <DEDENT> return generators <NEWLINE> <DEDENT>
def test_write_missing_value ( self ) : <NEWLINE> <INDENT> svc = Service ( <STRING> ) <NEWLINE> self . assertRaises ( MissingKeyException , lambda : svc [ <STRING> ] ) <NEWLINE> <DEDENT>
vel = ltu . dv_from_z ( ( mean / wv_line_vac ) - 1 , z ) . to ( units ) . value <NEWLINE>
def _config_parse ( config_file ) : <NEWLINE> <INDENT> if config_file is not None : <NEWLINE> <INDENT> try : <NEWLINE> <INDENT> configs = ConfigParse ( ) <NEWLINE> configs . read ( config_file ) <NEWLINE> dwh_schema = dict ( configs . items ( <STRING> ) ) <NEWLINE> <DEDENT> except FileNotFoundError : <NEWLINE> <INDENT> logger . error ( <STRING> ) <NEWLINE> sys . exit ( 1 ) <NEWLINE> <DEDENT> <DEDENT> else : <NEWLINE> <INDENT> dwh_config = { <NEWLINE> <INDENT> <STRING> : os . getenv ( <STRING> ) , <NEWLINE> <STRING> : os . getenv ( <STRING> ) , <NEWLINE> <STRING> : os . getenv ( <STRING> ) , <NEWLINE> <STRING> : os . getenv ( <STRING> ) , <NEWLINE> <STRING> : os . getenv ( <STRING> ) , <NEWLINE> <DEDENT> } <NEWLINE> <DEDENT> return dwh_config <NEWLINE> <DEDENT>
def perform_test ( self , command : [ str ] , input_file : str , expected_result_file : str ) : <NEWLINE> <INDENT> with open ( expected_result_file , <STRING> ) as fin : <NEWLINE> <INDENT> expected = fin . read ( ) <NEWLINE> <DEDENT> cmd , flags = self . interpreter . build_command ( command , input_file ) <NEWLINE> res = self . interpreter . execute_command ( cmd , flags , return_output = True ) <NEWLINE> self . assertEqual ( expected , res ) <NEWLINE> <DEDENT>
h , m , s = convert_elapsed_time ( training_time ) <NEWLINE> <INDENT> logger . info ( <STRING> <NEWLINE> <INDENT> . format ( h , m , s ) ) <NEWLINE> <DEDENT> logger . info ( <STRING> ) <NEWLINE> logger . info ( outputs_ ) <NEWLINE> logger . info ( <STRING> ) <NEWLINE> logger . info ( targets ) <NEWLINE> <DEDENT>
def mdata ( path , track_element ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> <COMMENT> <NL> tags = { <STRING> , <STRING> , <STRING> , <STRING> , <STRING> , <STRING> } <NEWLINE> <COMMENT> <NL> cmd = [ <STRING> , path . rstrip ( ) ] <NEWLINE> process = subprocess . Popen ( cmd , stdout = subprocess . PIPE , <NEWLINE> <INDENT> stderr = subprocess . STDOUT ) <NEWLINE> <COMMENT> <NL> <DEDENT> while True : <NEWLINE> <INDENT> out = process . stdout . readline ( ) <NEWLINE> decoded = out . decode ( <STRING> ) <NEWLINE> if out != <STRING> : <NEWLINE> <INDENT> linecheck = decoded . replace ( <STRING> , <STRING> ) <NEWLINE> for tag in tags : <NEWLINE> <INDENT> tagstring = tag + <STRING> <NEWLINE> if tagstring in linecheck : <NEWLINE> <INDENT> stringf = decoded . split ( <STRING> ) [ 1 ] <NEWLINE> ttag = tag <NEWLINE> if tag == <STRING> : <NEWLINE> <INDENT> ttag = <STRING> <NEWLINE> <DEDENT> if tag == <STRING> : <NEWLINE> <INDENT> ttag = <STRING> <NEWLINE> <DEDENT> ttag = SubElement ( track_element , tag ) <NEWLINE> ttag . text = stringf . rstrip ( ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT> else : <NEWLINE> <INDENT> break <NEWLINE> <DEDENT> <DEDENT> <DEDENT>
def mdata ( path , track_element ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> <COMMENT> <NL> tags = { <STRING> , <STRING> , <STRING> , <STRING> , <STRING> , <STRING> } <NEWLINE> <COMMENT> <NL> cmd = [ <STRING> , path . rstrip ( ) ] <NEWLINE> process = subprocess . Popen ( cmd , stdout = subprocess . PIPE , <NEWLINE> <INDENT> stderr = subprocess . STDOUT ) <NEWLINE> <COMMENT> <NL> <DEDENT> while True : <NEWLINE> <INDENT> out = process . stdout . readline ( ) <NEWLINE> decoded = out . decode ( <STRING> ) <NEWLINE> if out != <STRING> : <NEWLINE> <INDENT> linecheck = decoded . replace ( <STRING> , <STRING> ) <NEWLINE> for tag in tags : <NEWLINE> <INDENT> tagstring = tag + <STRING> <NEWLINE> if tagstring in linecheck : <NEWLINE> <INDENT> stringf = decoded . split ( <STRING> ) [ 1 ] <NEWLINE> ttag = tag <NEWLINE> if tag == <STRING> : <NEWLINE> <INDENT> ttag = <STRING> <NEWLINE> <DEDENT> if tag == <STRING> : <NEWLINE> <INDENT> ttag = <STRING> <NEWLINE> <DEDENT> ttag = SubElement ( track_element , ttag ) <NEWLINE> ttag . text = stringf . rstrip ( ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT> else : <NEWLINE> <INDENT> break <NEWLINE> <DEDENT> <DEDENT> <DEDENT>
class CLIN28JSON : <NEWLINE> <INDENT> def __init__ ( self , filename ) : <NEWLINE> <INDENT> if not os . path . exists ( filename ) : <NEWLINE> <INDENT> raise FileExistsError ( <STRING> + filename ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT>
def validate ( self ) : <NEWLINE> <INDENT> self . index = { } <NEWLINE> if <STRING> not in self . data : <NEWLINE> <INDENT> return ValidationError ( <STRING> ) <NEWLINE> <DEDENT> if <STRING> not in self . data : <NEWLINE> <INDENT> return ValidationError ( <STRING> ) <NEWLINE> <DEDENT> for key in self . data : <NEWLINE> <INDENT> if key not in ( <STRING> , <STRING> ) : <NEWLINE> <INDENT> print ( <STRING> + key + <STRING> , file = sys . stderr ) <NEWLINE> <DEDENT> <DEDENT> for word in self . words ( ) : <NEWLINE> <INDENT> if <STRING> not in word or not word [ <STRING> ] : <NEWLINE> <INDENT> raise ValidationError ( <STRING> + repr ( word ) ) <NEWLINE> <DEDENT> self . index [ word [ <STRING> ] ] = word <NEWLINE> if <STRING> not in word or not word [ <STRING> ] : <NEWLINE> <INDENT> raise ValidationError ( <STRING> + repr ( word ) ) <NEWLINE> <DEDENT> for key in word : <NEWLINE> <INDENT> if key not in ( <STRING> , <STRING> , <STRING> , <STRING> ) : <NEWLINE> <INDENT> print ( <STRING> + key + <STRING> + repr ( word ) + <STRING> , file = sys . stderr ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT> for correction in self . corrections ( ) : <NEWLINE> <INDENT> if <STRING> not in correction or not correction [ <STRING> ] : <NEWLINE> <INDENT> if <STRING> not in correction or not correction [ <STRING> ] : <NEWLINE> <INDENT> raise ValidationError ( <STRING> + repr ( correction ) ) <NEWLINE> <DEDENT> elif correction [ <STRING> ] not in self . index : <NEWLINE> <INDENT> raise ValidationError ( <STRING> + correction [ <STRING> ] + <STRING> + repr ( correction ) ) <NEWLINE> <DEDENT> <DEDENT> else : <NEWLINE> <INDENT> for wordid in correction [ <STRING> ] : <NEWLINE> <INDENT> if wordid not in self . index : <NEWLINE> <INDENT> raise ValidationError ( <STRING> + wordid + <STRING> + repr ( correction ) ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT> for key in correction : <NEWLINE> <INDENT> if key not in ( <STRING> , <STRING> , <STRING> , <STRING> , <STRING> ) : <NEWLINE> <INDENT> print ( <STRING> + key + <STRING> + repr ( correction ) + <STRING> , file = sys . stderr ) <NEWLINE> <DEDENT> if key == <STRING> : <NEWLINE> <INDENT> try : <NEWLINE> <INDENT> correction [ <STRING> ] = float ( correction [ <STRING> ] ) <NEWLINE> <DEDENT> except : <NEWLINE> <INDENT> raise ValidationError ( <STRING> + str ( correction [ <STRING> ] ) + <STRING> + repr ( correction ) ) <NEWLINE> <DEDENT> if correction [ <STRING> ] < 0 or correction [ <STRING> ] > 1 : <NEWLINE> <INDENT> raise ValidationError ( <STRING> + str ( correction [ <STRING> ] ) + <STRING> + repr ( correction ) ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT> <DEDENT> <DEDENT>
@ patch ( <STRING> , <STRING> ) <NEWLINE> <INDENT> @ patch ( <STRING> , _fake_urlopen ) <NEWLINE> def test_send_request ( self ) : <NEWLINE> <INDENT> sender = SmsSender ( ) <NEWLINE> response = sender . send_request ( { } , <STRING> ) <NEWLINE> self . assertIn ( SMSMessage . STATUS_ACCEPTED , response ) <NEWLINE> <DEDENT> <DEDENT>
def send_sms ( to , text , signature_id = None , date = None , link = <STRING> ) : <NEWLINE> <INDENT> signature = sender . get_signature ( signature_id ) <NEWLINE> params = { <NEWLINE> <INDENT> <STRING> : to , <NEWLINE> <STRING> : quote_plus ( text ) , <NEWLINE> <STRING> : signature . name , <NEWLINE> <STRING> : date or <STRING> , <NEWLINE> <DEDENT> } <NEWLINE> response = sender . send_request ( params , link ) <NEWLINE> sms_id , status = sender . parse_response ( response ) <NEWLINE> <DEDENT>
<COMMENT> <NL> <INDENT> if step > 0 : <NEWLINE> <INDENT> if ( start > a_length ) or ( stop < - a_length ) : <NEWLINE> <INDENT> start = stop = 0 <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> if start < - a_length : <NEWLINE> <INDENT> start = 0 <NEWLINE> <DEDENT> if stop > a_length : <NEWLINE> <INDENT> stop = a_length <NEWLINE> <DEDENT> <DEDENT> <DEDENT> elif step < 0 : <NEWLINE> <INDENT> if ( start < - a_length ) or ( stop_i and stop >= ( a_length - 1 ) ) : <NEWLINE> <INDENT> start = stop = 0 <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> if start >= a_length : <NEWLINE> <INDENT> start = a_length - 1 <NEWLINE> <DEDENT> if stop_i and stop < - a_length : <NEWLINE> <INDENT> stop = None <NEWLINE> stop_i = False <NEWLINE> <DEDENT> <DEDENT> <DEDENT> <DEDENT>
new_slice = a_slice <NEWLINE> <INDENT> if new_slice is Ellipsis : <NEWLINE> <INDENT> new_slice = slice ( None ) <NEWLINE> <DEDENT> elif not isinstance ( a_slice , slice ) : <NEWLINE> <INDENT> raise ValueError ( <NEWLINE> <INDENT> <STRING> % str ( new_slice ) <NEWLINE> <DEDENT> ) <NEWLINE> <DEDENT> <DEDENT>
new_slice = a_slice <NEWLINE> <INDENT> if new_slice is Ellipsis : <NEWLINE> <INDENT> new_slice = slice ( None ) <NEWLINE> <DEDENT> elif not isinstance ( a_slice , slice ) : <NEWLINE> <INDENT> raise ValueError ( <NEWLINE> <INDENT> <STRING> % str ( a_slice ) <NEWLINE> <DEDENT> ) <NEWLINE> <DEDENT> <DEDENT>
kpconf . set_backend ( backend ) <NEWLINE>
@ property <NEWLINE> <INDENT> def to_train ( self ) -> bool : <NEWLINE> <INDENT> if self . name == <STRING> : <NEWLINE> <INDENT> return True <NEWLINE> <DEDENT> return False <NEWLINE> <DEDENT> <DEDENT>
def main_Concern ( ) : <NEWLINE> <INDENT> parser = ArgumentParser ( ) <NEWLINE> parser . add_argument ( <STRING> , type = os . path . expanduser ) <NEWLINE> config , vimargs = parser . parse_known_args ( ) <NEWLINE> if config . chdir is not None : <NEWLINE> <INDENT> os . chdir ( config . chdir ) <NEWLINE> <DEDENT> configdir = Path . home ( ) / <STRING> <NEWLINE> configdir . mkdir ( parents = True , exist_ok = True ) <NEWLINE> with TemporaryDirectory ( dir = configdir ) as tempdir : <NEWLINE> <INDENT> tempdir = Path ( tempdir ) <NEWLINE> concernvimrc = tempdir / <STRING> <NEWLINE> sendblock = tempdir / <STRING> <NEWLINE> quit = tempdir / <STRING> <NEWLINE> screenrc = tempdir / <STRING> <NEWLINE> config = ConfigCtrl ( ) <NEWLINE> config . put ( <STRING> , <STRING> , function = toabswidth ) <NEWLINE> config . printf ( <STRING> , resource_filename ( __name__ , <STRING> ) ) <NEWLINE> try : <NEWLINE> <INDENT> config . loadsettings ( ) <NEWLINE> <DEDENT> except FileNotFoundError as e : <NEWLINE> <INDENT> log . info ( <STRING> , e ) <NEWLINE> <DEDENT> Concern = config . node . Concern <NEWLINE> uservimrc = Path . home ( ) / <STRING> <NEWLINE> if uservimrc . exists ( ) : <NEWLINE> <INDENT> ( - Concern ) . printf ( <STRING> , uservimrc ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> log . info ( <STRING> , uservimrc ) <NEWLINE> <DEDENT> ( - Concern ) . printf ( <STRING> , sys . executable ) <NEWLINE> ( - Concern ) . printf ( <STRING> , concernvimrc ) <NEWLINE> ( - Concern ) . printf ( <STRING> , sendblock ) <NEWLINE> ( - Concern ) . printf ( <STRING> , quit ) <NEWLINE> ( - Concern ) . printf ( <STRING> ) <NEWLINE> for arg in vimargs : <NEWLINE> <INDENT> ( - Concern ) . printf ( <STRING> , arg ) <NEWLINE> <DEDENT> import_module ( <STRING> , package = __package__ ) . configure ( Concern ) <NEWLINE> ( - Concern ) . processtemplate ( resource_filename ( templates . __name__ , <STRING> ) , concernvimrc ) <NEWLINE> ( - Concern ) . printf ( <STRING> ) <NEWLINE> ( - Concern ) . processtemplate ( resource_filename ( templates . __name__ , <STRING> ) , sendblock ) <NEWLINE> ( - Concern ) . processtemplate ( resource_filename ( templates . __name__ , <STRING> ) , quit ) <NEWLINE> ( - Concern ) . printf ( <STRING> ) <NEWLINE> ( - Concern ) . processtemplate ( resource_filename ( templates . __name__ , <STRING> ) , screenrc ) <NEWLINE> doublequotekey = Concern . doubleQuoteKey <NEWLINE> stuffablescreen ( doublequotekey ) . print ( <STRING> , Concern . sessionName , <STRING> , screenrc ) <NEWLINE> <DEDENT> <DEDENT>
<COMMENT> <NL> <INDENT> if sp . issparse ( X ) : <NEWLINE> <INDENT> centers [ c ] = X [ best_candidate ] . toarray ( ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> centers [ c ] = X [ best_candidate ] <NEWLINE> <DEDENT> centers_idx . append ( best_candidate ) <NEWLINE> current_pot = best_pot <NEWLINE> closest_dist_sq = best_dist_sq <NEWLINE> <DEDENT>
return target_dir <NEWLINE>
def _interdistance ( self , first : np . ndarray , second : np . ndarray ) -> np . ndarray : <NEWLINE> <INDENT> if first is not self . _last : <NEWLINE> <INDENT> self . _last = first <NEWLINE> self . _last_ranks = np . apply_along_axis ( st . rankdata , 0 , first ) <NEWLINE> <DEDENT> second_ranks = np . apply_along_axis ( st . rankdata , 0 , second ) <NEWLINE> return dist . cdist ( self . _last_ranks , second_ranks , metric = <STRING> ) <NEWLINE> <DEDENT>
@ contextlib . contextmanager <NEWLINE> <INDENT> def resume ( file_name ) : <NEWLINE> <INDENT> file_path = <STRING> . format ( env . HIDEOUT_BASEDIR , file_name ) <NEWLINE> target = None <NEWLINE> if os . path . exists ( file_path ) and not env . HIDEOUT_FORCE_CACHE : <NEWLINE> <INDENT> logger . error ( <STRING> . format ( file_path ) ) <NEWLINE> with open ( file_path , mode = <STRING> ) as f : <NEWLINE> <INDENT> target = pickle . load ( f ) <NEWLINE> <DEDENT> <DEDENT> yield target <NEWLINE> if target is not None : <NEWLINE> <INDENT> freeze ( target , file_name ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT>
def percent_of ( self , percent , whole ) : <NEWLINE> <INDENT> return ( percent * whole ) / 100 <NEWLINE> <DEDENT>
if batch : <NEWLINE> <INDENT> import batch_process <NEWLINE> batch_process . run ( indir ) <NEWLINE> else : <NEWLINE> metadata_dir = os . path . join ( indir , <STRING> ) <NEWLINE> if os . path . isdir ( metadata_dir ) : <NEWLINE> <INDENT> metadata_process . clean ( metadata_dir ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> raise IOError ( <STRING> ) <NEWLINE> <DEDENT> <DEDENT>
def __init__ ( self , operand , invert = False ) : <NEWLINE> <INDENT> super ( IsNullOperator , self ) . __init__ ( operand , <STRING> if invert else <STRING> ) <NEWLINE> self . invert = invert <NEWLINE> <DEDENT>
<COMMENT> <NL> <INDENT> ERROR_HANDLER . assert_true ( self . criteria_working_dir is not None , <STRING> , __file__ ) <NEWLINE> for criterion in self . tools_config_by_criterion_dict : <NEWLINE> <INDENT> ERROR_HANDLER . assert_true ( len ( self . tools_config_by_criterion_dict [ criterion ] ) != len ( set ( [ c . get_tool_config_alias ( ) for c in self . tools_config_by_criterion_dict [ criterion ] ] ) ) , <STRING> . format ( criterion ) , __file__ ) <NEWLINE> <DEDENT> <DEDENT>
<COMMENT> <NL> <INDENT> ERROR_HANDLER . assert_true ( self . tests_working_dir is not None , <STRING> , __file__ ) <NEWLINE> ERROR_HANDLER . assert_true ( len ( self . test_tool_config_list ) != len ( set ( [ c . get_tool_config_alias ( ) for c in self . test_tool_config_list ] ) ) , <STRING> , __file__ ) <NEWLINE> <DEDENT>
class CopyCallbackObject ( DefaultCallbackObject ) : <NEWLINE> <INDENT> def after_command ( self ) : <NEWLINE> <INDENT> file_src_dest_map = self . post_callback_args <NEWLINE> for src , dest in list ( file_src_dest_map . items ( ) ) : <NEWLINE> <INDENT> abs_src = os . path . join ( self . repository_rootdir , src ) <NEWLINE> if os . path . abspath ( abs_src ) != os . path . abspath ( dest ) : <NEWLINE> <INDENT> shutil . copy2 ( abs_src , dest ) <NEWLINE> <DEDENT> <DEDENT> return DefaultCallbackObject . after_command ( self ) <NEWLINE> <COMMENT> <NL> <COMMENT> <NL> <DEDENT> <DEDENT>
dup_list , invalid = KTestTestFormat . ktest_fdupes ( * folders , custom_replay_tool_binary_dir = self . custom_binary_dir ) <NEWLINE> <INDENT> if len ( invalid ) > 0 : <NEWLINE> <INDENT> logging . warning ( <STRING> . format ( len ( invalid ) , invalid ) ) <NEWLINE> for kt in invalid : <NEWLINE> <INDENT> if KTestTestFormat . get_dir ( kt , folders ) == self . tests_storage_dir : <NEWLINE> <INDENT> os . remove ( kt ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT> for dup_tuple in dup_list : <NEWLINE> <INDENT> key = os . path . relpath ( dup_tuple [ 0 ] , KTestTestFormat . get_dir ( dup_tuple [ 0 ] , folders ) ) <NEWLINE> kepttest2duptest_map [ key ] = [ os . path . relpath ( dp , KTestTestFormat . get_dir ( dp , folders ) ) for dp in dup_tuple [ 1 : ] ] <NEWLINE> for df in dup_tuple [ 1 : ] : <NEWLINE> <INDENT> if KTestTestFormat . get_dir ( df , folders ) == self . tests_storage_dir : <NEWLINE> <INDENT> os . remove ( df ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT> common_fs . dumpJSON ( kepttest2duptest_map , self . keptktest2dupktests ) <NEWLINE> <DEDENT>
parser_customexec = subparsers . add_parser ( <STRING> , help = <STRING> <NEWLINE> <INDENT> <STRING> ) <NEWLINE> parser_customexec . add_argument ( <STRING> , action = <STRING> , help = <STRING> ) <NEWLINE> <DEDENT>
def get_definitions_pairs ( defines_list ) : <NEWLINE> <INDENT> def_pairs = { } <NEWLINE> for define_statement_string in defines_list : <NEWLINE> <INDENT> elems = re . split ( <STRING> , define_statement_string ) <NEWLINE> if len ( elems ) != 3 : <COMMENT> <NEWLINE> <INDENT> continue <COMMENT> <NEWLINE> <DEDENT> name = elems [ 1 ] <NEWLINE> value = elems [ 2 ] <NEWLINE> def_pairs [ name ] = value <NEWLINE> <DEDENT> return def_pairs <NEWLINE> <DEDENT>
def update_required ( self ) -> bool : <NEWLINE> <INDENT> return self . _variables_manager . get_variables ( ) != self . _get_required_variables ( ) <NEWLINE> <DEDENT>
if log_entry . message is not <STRING> and log_entry . message is not None : <NEWLINE> <INDENT> dto [ <STRING> ] = log_entry . message <NEWLINE> <DEDENT>
deb_dependencies = self . extra_args . get ( <STRING> , { } ) . project . get ( <STRING> ) <NEWLINE> <INDENT> project = self . extra_args . get ( <STRING> , { } ) . project <NEWLINE> generated_builds = [ ] <NEWLINE> for deb in project . get ( <STRING> , [ ] ) : <NEWLINE> <INDENT> deb_name = deb . get ( <STRING> , self . project_name ) <NEWLINE> dpm = Dpm ( project_path = self . project_path , <NEWLINE> <INDENT> package_name = deb_name , <NEWLINE> package_version = self . new_version , <NEWLINE> install_path = deb . get ( <STRING> ) , <NEWLINE> dependencies = deb_dependencies , <NEWLINE> description = deb . get ( <STRING> ) , <NEWLINE> excludes = deb . get ( <STRING> , [ ] ) ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT>
dim = <STRING> if opts [ <STRING> ] else <STRING> ; <NEWLINE> <INDENT> if opts [ <STRING> ] : <NEWLINE> <INDENT> angle = float ( opts [ <STRING> ] ) ; <NEWLINE> angleopt = ( angle , dim ) ; <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> angleopt = None ; <NEWLINE> <DEDENT> KE , good = totalKE ( d , ecut , angleopt , return_bools = True ) ; <NEWLINE> LE = laserE ( E_0 , T , w , dim = dim ) ; <NEWLINE> totalq = d [ <STRING> ] [ good ] . sum ( ) * 1e12 ; <NEWLINE> print ( <STRING> . format ( totalq , <STRING> if opts [ <STRING> ] else <STRING> ) ) ; <NEWLINE> print ( <STRING> . format ( KE ) ) ; <NEWLINE> print ( <STRING> . format ( LE ) ) ; <NEWLINE> print ( <STRING> . format ( KE / LE ) ) ; <NEWLINE> <DEDENT>
headers = base_headers . copy ( ) <NEWLINE> <INDENT> headers [ <STRING> ] = index + 1 <NEWLINE> <DEDENT>
<COMMENT> <NL> <INDENT> enviar_email ( settings . DEFAULT_FROM_EMAIL , email , nome , <NEWLINE> <INDENT> assunto , template_email , mensagem ) <NEWLINE> <DEDENT> <DEDENT>
def mcall_stat_parse ( infile ) : <NEWLINE> <INDENT> with open ( infile ) as f : <NEWLINE> <INDENT> dstr = f . read ( ) <NEWLINE> <DEDENT> return float ( re . search ( <STRING> , dstr ) . groups ( ) [ 0 ] ) <NEWLINE> <DEDENT>
<COMMENT> <NL> <INDENT> x_value = np . sort ( data ) <NEWLINE> size_data = raw_data . size <NEWLINE> <COMMENT> <NL> y_value = [ ] <NEWLINE> <DEDENT>
@ staticmethod <NEWLINE> <INDENT> def retrieve_rows_csv ( request , job , ** kwargs ) : <NEWLINE> <INDENT> if request . method == <STRING> : <NEWLINE> <INDENT> print ( <STRING> , kwargs ) <NEWLINE> start_row = kwargs . get ( <STRING> ) <NEWLINE> num_rows = kwargs . get ( <STRING> ) <NEWLINE> input_format = kwargs . get ( <STRING> ) <NEWLINE> job_id = job . id <NEWLINE> <DEDENT> <DEDENT> <DEDENT>
<COMMENT> <NL> <INDENT> vcf_results = get_variants ( vcf_obj , raw_variants , vcfsamples , qual ) <NEWLINE> <DEDENT>
<COMMENT> <NL> <COMMENT> <NL> <COMMENT> <NL> <COMMENT> <NL> <INDENT> vcf_results = get_variants ( panel_filtered_results [ 0 ] , raw_variants , samples , qual ) <NEWLINE> <DEDENT>
if isinstance ( channels , list ) : <NEWLINE> <INDENT> for ch in channels : <NEWLINE> <INDENT> permissions [ int ( ch ) ] = ( read , write ) <NEWLINE> else : <NEWLINE> <DEDENT> permissions [ int ( channels ) ] = ( read , write ) <NEWLINE> <DEDENT>
def microlensing_parameters_limits_priors ( parameters , limits ) : <NEWLINE> <INDENT> for i in xrange ( len ( limits ) ) : <NEWLINE> <DEDENT>
if np . max ( ( caustic_points [ : , first_branch ] ) . real ) < np . max ( ( caustic_points [ : , second_branch ] ) . real ) : <NEWLINE>
<COMMENT> <NL> <COMMENT> <NL> <INDENT> if is_exception : <NEWLINE> <INDENT> ex_type , ex_value , ex_tb = response <NEWLINE> raise ex_type ( ex_value , ex_tb ) <NEWLINE> <DEDENT> return response <NEWLINE> <DEDENT>
slave = self . canvas_slave <NEWLINE> <COMMENT> <NL> <INDENT> frame_point_i = cv2 . perspectiveTransform ( np . array ( [ [ start_xy ] ] , dtype = float ) , <NEWLINE> <INDENT> slave . canvas_to_frame_map ) . ravel ( ) <NEWLINE> <COMMENT> <NL> <DEDENT> frame_corner_i = find_closest ( slave . df_frame_corners , frame_point_i ) <NEWLINE> <COMMENT> <NL> canvas_corner_i = find_closest ( slave . df_canvas_corners , start_xy ) <NEWLINE> <DEDENT>
enriched_transactions = enrich_transactions ( blocks , transactions , receipts ) <NEWLINE> <INDENT> if len ( enriched_transactions ) != len ( transactions ) : <NEWLINE> <INDENT> raise ValueError ( <STRING> + str ( enriched_transactions ) ) <NEWLINE> <DEDENT> enriched_logs = enrich_logs ( blocks , logs ) <NEWLINE> if len ( enriched_logs ) != len ( logs ) : <NEWLINE> <INDENT> raise ValueError ( <STRING> + str ( enriched_logs ) ) <NEWLINE> <DEDENT> enriched_token_transfers = enrich_token_transfers ( blocks , token_transfers ) <NEWLINE> if len ( enriched_token_transfers ) != len ( token_transfers ) : <NEWLINE> <INDENT> raise ValueError ( <STRING> + str ( enriched_token_transfers ) ) <NEWLINE> <DEDENT> <DEDENT>
class TestAccumulatingTraces ( unittest . TestCase ) : <NEWLINE> <INDENT> def setUp ( self ) : <NEWLINE> <INDENT> self . basis = FourierBasis ( space , 2 , 2 ) <NEWLINE> self . approximation = DiscreteLinearApproximation ( 0.1 , self . basis , actions = 3 ) <NEWLINE> self . env = Env ( ) <NEWLINE> self . traces = AccumulatingTraces ( self . approximation , self . env , 0.5 ) <NEWLINE> <DEDENT> <DEDENT>
def test_update ( self ) : <NEWLINE> <INDENT> basis = FourierBasis ( space , 2 , 2 ) <NEWLINE> approximation = LinearApproximation ( 0.1 , basis ) <NEWLINE> x = np . array ( [ 0.5 , 1 ] ) <NEWLINE> self . assertEqual ( approximation . call ( x ) , 0 ) <NEWLINE> approximation . update ( 1 , x ) <NEWLINE> self . assertAlmostEqual ( approximation . call ( x ) , 0.6 ) <NEWLINE> <DEDENT>
if minutes != 0 : <NEWLINE> <INDENT> if not first : res += <STRING> <NEWLINE> res += _ ( <STRING> ) % minutes ; <NEWLINE> first = False <NEWLINE> <DEDENT>
