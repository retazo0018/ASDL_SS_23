new = _css_import_re . sub ( <STRING> , new ) <NEWLINE>
def collect_diff_tag ( self , want , got ) : <NEWLINE> <INDENT> if not self . tag_compare ( want . tag , got . tag ) : <NEWLINE> <INDENT> tag = <STRING> % ( want . tag , got . tag ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> tag = got . tag <NEWLINE> <DEDENT> attrs = [ ] <NEWLINE> any = want . tag == <STRING> or <STRING> in want . attrib <NEWLINE> for name , value in sorted ( got . attrib . items ( ) ) : <NEWLINE> <INDENT> if name not in want . attrib and not any : <NEWLINE> <INDENT> attrs . append ( <STRING> % ( name , self . format_text ( value , False ) ) ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> if name in want . attrib : <NEWLINE> <INDENT> text = self . collect_diff_text ( want . attrib [ name ] , value , False ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> text = self . format_text ( value , False ) <NEWLINE> <DEDENT> attrs . append ( <STRING> % ( name , text ) ) <NEWLINE> <DEDENT> <DEDENT> if not any : <NEWLINE> <INDENT> for name , value in sorted ( want . attrib . items ( ) ) : <NEWLINE> <INDENT> if name in got . attrib : <NEWLINE> <INDENT> continue <NEWLINE> <DEDENT> attrs . append ( <STRING> % ( name , self . format_text ( value , False ) ) ) <NEWLINE> <DEDENT> <DEDENT> if attrs : <NEWLINE> <INDENT> tag = <STRING> % ( tag , <STRING> . join ( attrs ) ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> tag = <STRING> % tag <NEWLINE> <DEDENT> return tag <NEWLINE> <DEDENT>
SRC_ioncell_fws = SRCFireworks ( task_class = RelaxFWTask , task_input = ioncell_input , spec = spec , <NEWLINE> <INDENT> initialization_info = initialization_info , <NEWLINE> wf_task_index_prefix = <STRING> , <NEWLINE> deps = { SRC_ion_fws [ <STRING> ] . tasks [ 0 ] . task_type : <STRING> } ) <NEWLINE> fws . extend ( SRC_ioncell_fws [ <STRING> ] ) <NEWLINE> links_dict . update ( SRC_ioncell_fws [ <STRING> ] ) <NEWLINE> <DEDENT>
optconf , qadapter_spec , qtk_qadapter = self . run_autoparal ( self . abiinput , os . path . abspath ( <STRING> ) , self . ftm ) <NEWLINE> <INDENT> if self . use_SRC_scheme : <NEWLINE> <INDENT> return FWAction ( mod_spec = { <STRING> : { <STRING> : qadapter_spec , <STRING> : optconf [ <STRING> ] , <NEWLINE> <INDENT> <STRING> : optconf , <STRING> : qtk_qadapter . as_dict ( ) } } ) <NEWLINE> <DEDENT> <DEDENT> self . history . log_autoparal ( optconf ) <NEWLINE> self . abiinput . set_vars ( optconf . vars ) <NEWLINE> <DEDENT>
ec_nostress_clamped = myfw_nostress . tasks [ - 1 ] . get_elastic_tensor ( tensor_type = <STRING> ) <NEWLINE> <INDENT> ec_nostress_relaxed = myfw_nostress . tasks [ - 1 ] . get_elastic_tensor ( tensor_type = <STRING> ) <NEWLINE> ec_stress_relaxed = myfw_stress . tasks [ - 1 ] . get_elastic_tensor ( tensor_type = <STRING> ) <NEWLINE> <DEDENT>
def createSRCFireworks ( setup_task , run_task , handlers = None , validators = None , spec = None , initialization_info = None , <NEWLINE> <INDENT> task_index = None , deps = None ) : <NEWLINE> spec = copy . deepcopy ( spec ) <NEWLINE> if task_index is not None : <NEWLINE> src_task_index = SRCTaskIndex . from_any ( task_index ) <NEWLINE> else : <NEWLINE> src_task_index = SRCTaskIndex . from_task ( run_task ) <NEWLINE> setup_spec = copy . deepcopy ( spec ) <NEWLINE> setup_spec [ <STRING> ] = src_task_index <NEWLINE> pass <NEWLINE> <DEDENT>
links_dict = { setup_fw . fw_id : [ run_fw . fw_id ] , <NEWLINE> <INDENT> run_fw . fw_id : [ control_fw . fw_id ] } <NEWLINE> return { <STRING> : setup_fw , <STRING> : run_fw , <STRING> : control_fw , <STRING> : links_dict , <NEWLINE> <STRING> : [ setup_fw , run_fw , control_fw ] } <NEWLINE> <DEDENT>
<COMMENT> <NL> <INDENT> control_spec = copy . deepcopy ( spec ) <NEWLINE> control_spec = set_short_single_core_to_spec ( control_spec ) <NEWLINE> control_spec [ <STRING> ] = src_task_index <NEWLINE> control_fw = Firework ( control_task , spec = control_spec , name = src_task_index . control_str ) <NEWLINE> <DEDENT>
modified_objects = { } <NEWLINE> <INDENT> setup_spec_update = { } <NEWLINE> run_spec_update = { } <NEWLINE> for target , action in control_report . actions . items ( ) : <NEWLINE> <INDENT> target_object = initial_objects [ target ] <NEWLINE> action . apply ( target_object ) <NEWLINE> if target not in initial_objects_info : <NEWLINE> <INDENT> raise ValueError ( <STRING> . format ( target ) ) <NEWLINE> <DEDENT> if <STRING> not in initial_objects_info [ target ] : <NEWLINE> <INDENT> raise ValueError ( <STRING> . format ( target ) ) <NEWLINE> <DEDENT> for update in initial_objects_info [ target ] [ <STRING> ] : <NEWLINE> <INDENT> if update [ <STRING> ] == <STRING> : <NEWLINE> <INDENT> if <STRING> in update : <NEWLINE> <INDENT> mod = getattr ( target_object , update [ <STRING> ] ) ( ) <NEWLINE> new_spec [ update [ <STRING> ] ] = mod <NEWLINE> modified_objects [ update [ <STRING> ] ] = mod <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> new_spec [ update [ <STRING> ] ] = target_object <NEWLINE> modified_objects [ update [ <STRING> ] ] = target_object <NEWLINE> <DEDENT> <DEDENT> elif update [ <STRING> ] == <STRING> : <NEWLINE> <INDENT> if <STRING> in update : <NEWLINE> <INDENT> mod = getattr ( target_object , update [ <STRING> ] ) ( ) <NEWLINE> setup_spec_update [ update [ <STRING> ] ] = mod <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> setup_spec_update [ update [ <STRING> ] ] = target_object <NEWLINE> <DEDENT> <DEDENT> elif update [ <STRING> ] == <STRING> : <NEWLINE> <INDENT> if <STRING> in update : <NEWLINE> <INDENT> mod = getattr ( target_object , update [ <STRING> ] ) ( ) <NEWLINE> run_spec_update [ update [ <STRING> ] ] = mod <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> run_spec_update [ update [ <STRING> ] ] = target_object <NEWLINE> <DEDENT> <DEDENT> elif update [ <STRING> ] in [ <STRING> , <STRING> ] : <NEWLINE> <INDENT> task = setup_task if update [ <STRING> ] == <STRING> else run_task <NEWLINE> attr = getattr ( task , update [ <STRING> ] ) <NEWLINE> if <STRING> in update : <NEWLINE> <INDENT> mod = getattr ( target_object , update [ <STRING> ] ) ( ) <NEWLINE> attr = mod <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> attr = target_object <NEWLINE> <DEDENT> <DEDENT> else : <NEWLINE> <INDENT> raise ValueError ( <STRING> ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT> <DEDENT>
def simpleLoad ( request ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> loadform = SimpleLoadForm ( request . GET ) <NEWLINE> mpas = None <NEWLINE> if loadform . is_valid ( ) : <NEWLINE> <INDENT> user = loadform . cleaned_data [ <STRING> ] <NEWLINE> name = loadform . cleaned_data [ <STRING> ] <NEWLINE> mpas = Mpa . objects . filter ( user = user , name = name ) <NEWLINE> <DEDENT> return mpaLoad ( request , mpas , loadform ) <NEWLINE> <DEDENT>
<COMMENT> <NL> <COMMENT> <NL> <COMMENT> <NL> <INDENT> user = request . user <NEWLINE> from lingcod . sharing . utils import get_viewable_object_or_respond <NEWLINE> for pk in mpas : <NEWLINE> <COMMENT> <NL> <INDENT> try : <NEWLINE> <INDENT> obj = mpa_class . objects . get ( pk = pk ) <NEWLINE> <DEDENT> except : <NEWLINE> <INDENT> raise Http404 <NEWLINE> <DEDENT> <DEDENT> <DEDENT>
if not keyspace : <NEWLINE> <COMMENT> <NL> <INDENT> self . keyspaces = dict ( ( name , meta ) for name , meta in self . keyspaces . items ( ) <NEWLINE> <INDENT> if name in added_keyspaces ) <NEWLINE> else : <NEWLINE> <COMMENT> <NL> try : <NEWLINE> <DEDENT> keyspace_meta = self . keyspaces [ keyspace ] <NEWLINE> except KeyError : <NEWLINE> <COMMENT> <NL> <COMMENT> <NL> <COMMENT> <NL> pass <NEWLINE> if keyspace in cf_def_rows : <NEWLINE> for table_row in cf_def_rows [ keyspace ] : <NEWLINE> <INDENT> table_meta = self . _build_table_metadata ( <NEWLINE> <INDENT> keyspace_meta , table_row , col_def_rows [ keyspace ] ) <NEWLINE> <DEDENT> keyspace_meta . tables [ table_meta . name ] = table_meta <NEWLINE> <DEDENT> <DEDENT>
if not keyspace : <NEWLINE> <COMMENT> <NL> <INDENT> self . keyspaces = dict ( ( name , meta ) for name , meta in self . keyspaces . items ( ) <NEWLINE> <INDENT> if name in added_keyspaces ) <NEWLINE> else : <NEWLINE> <COMMENT> <NL> try : <NEWLINE> <DEDENT> keyspace_meta = self . keyspaces [ keyspace ] <NEWLINE> except KeyError : <NEWLINE> <COMMENT> <NL> <COMMENT> <NL> <COMMENT> <NL> pass <NEWLINE> if keyspace in cf_def_rows : <NEWLINE> for table_row in cf_def_rows [ keyspace ] : <NEWLINE> <INDENT> table_meta = self . _build_table_metadata ( <NEWLINE> <INDENT> keyspace_meta , table_row , col_def_rows [ keyspace ] ) <NEWLINE> <DEDENT> keyspace_meta . tables [ table_meta . name ] = table_meta <NEWLINE> <DEDENT> <DEDENT>
def populate ( self , cluster , hosts ) : <NEWLINE> <INDENT> self . _live_hosts = set ( hosts ) <NEWLINE> if len ( hosts ) <= 1 : <NEWLINE> <INDENT> self . _position = 0 <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> self . _position = randint ( 0 , len ( hosts ) - 1 ) <NEWLINE> <DEDENT> <DEDENT>
if not issubclass ( klass , cls ) : <NEWLINE> <INDENT> raise PolyMorphicModelException ( <NEWLINE> <INDENT> <STRING> . format ( klass . __name__ , poly_base . __name__ ) <NEWLINE> <DEDENT> ) <NEWLINE> <DEDENT>
if not issubclass ( klass , cls ) : <NEWLINE> <INDENT> raise PolyMorphicModelException ( <NEWLINE> <INDENT> <STRING> . format ( klass . __name__ , cls . __name__ ) <NEWLINE> <DEDENT> ) <NEWLINE> <DEDENT>
MultipleObjectsReturnedBase = MultipleObjectsReturnedBase or attrs . pop ( <STRING> , BaseModel . MultipleObjectsReturned ) <NEWLINE> <INDENT> attrs [ <STRING> ] = type ( <STRING> , ( MultipleObjectsReturnedBase , ) , { } ) <NEWLINE> <DEDENT>
def assume_role ( account , role ) : <NEWLINE> <INDENT> sts = boto3 . client ( <STRING> ) <NEWLINE> response = sts . assume_role ( RoleArn = <STRING> , <NEWLINE> <INDENT> RoleSessionName = <STRING> ) <NEWLINE> <DEDENT> if not response or not response [ <STRING> ] [ <STRING> ] == 200 : <NEWLINE> <INDENT> raise Exception ( <STRING> ) <NEWLINE> <DEDENT> return boto3 . Session ( <NEWLINE> <INDENT> aws_access_key_id = response [ <STRING> ] [ <STRING> ] , <NEWLINE> aws_secret_access_key = response [ <STRING> ] [ <STRING> ] , <NEWLINE> aws_session_token = response [ <STRING> ] [ <STRING> ] ) <NEWLINE> <DEDENT> <DEDENT>
def create_add_page ( site : Site , source : str , target : str , data = None , <NEWLINE> <INDENT> content = None ) : <NEWLINE> <STRING> <NEWLINE> init_content = <STRING> <NEWLINE> if content is None and not isinstance ( content , str ) : <NEWLINE> content = init_content <NEWLINE> <DEDENT>
<COMMENT> <NL> <INDENT> if <STRING> in prop . constraints ( ) and prop . getType ( ) == <STRING> : <NEWLINE> <INDENT> match = re . match ( prop . constraints ( ) [ <STRING> ] , claim . getTarget ( ) ) <NEWLINE> if not match or match . group ( 0 ) != claim . getTarget ( ) : <NEWLINE> <INDENT> return False , <STRING> <NEWLINE> <DEDENT> <DEDENT> if <STRING> in prop . constraints ( ) and prop . getType ( ) == <STRING> : <NEWLINE> <INDENT> if not claim . getTarget ( ) . getID ( ) in prop . constraints ( ) [ <STRING> ] : <NEWLINE> <INDENT> return False , <STRING> <NEWLINE> <DEDENT> <DEDENT> if <STRING> in prop . constraints ( ) : <NEWLINE> <INDENT> if claim . getID ( ) in item . claims : <NEWLINE> <INDENT> return False , <STRING> <NEWLINE> <DEDENT> <DEDENT> <DEDENT>
<COMMENT> <NL> <INDENT> for k , v in cli_args . iteritems ( ) : <NEWLINE> <INDENT> if k not in self . _data or v is not None : <NEWLINE> <INDENT> self . _data [ k ] = v <NEWLINE> <DEDENT> <DEDENT> <DEDENT>
<COMMENT> <NL> <INDENT> intermediates , trust_roots = [ ] , [ ] <NEWLINE> for store in self . stores : <NEWLINE> <INDENT> for cert in store : <NEWLINE> <INDENT> asn1cert = cert . to_asn1crypto <NEWLINE> ( trust_roots if store . trusted else intermediates ) . append ( asn1cert ) <NEWLINE> all_certs [ asn1cert ] = cert <NEWLINE> <DEDENT> <DEDENT> <DEDENT>
def prompt_hex ( item ) : <NEWLINE> <INDENT> if not isinstance ( item , JConfigHex ) : <NEWLINE> <INDENT> return <NEWLINE> <DEDENT> if not item . is_visible ( ) : <NEWLINE> <INDENT> return <NEWLINE> <DEDENT> print ( <STRING> . format ( item . get_name ( ) ) ) <NEWLINE> val = <STRING> <NEWLINE> while val == <STRING> or val == <STRING> : <NEWLINE> <INDENT> val = raw_input ( <STRING> . format ( item . get_prompt ( ) ) ) <NEWLINE> if val == <STRING> : <NEWLINE> <INDENT> print_help ( item ) <NEWLINE> <DEDENT> elif val == <STRING> : <NEWLINE> <INDENT> val = item . get_default_value ( ) <NEWLINE> if val is not <STRING> : <NEWLINE> <INDENT> item . set_user_value ( val ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> print ( <STRING> ) <NEWLINE> print_help ( item ) <NEWLINE> <DEDENT> <DEDENT> else : <NEWLINE> <INDENT> try : <NEWLINE> <INDENT> item . set_user_value ( val ) <NEWLINE> <DEDENT> except ValueError as ve : <NEWLINE> <INDENT> print ( ve ) <NEWLINE> val = <STRING> <NEWLINE> <DEDENT> <DEDENT> <DEDENT> <DEDENT>
return notification <NEWLINE>
if migration == <STRING> : <NEWLINE> <INDENT> continue <NEWLINE> <DEDENT>
for pattern in self . patterns [ <STRING> ] : <NEWLINE> <INDENT> file_pattern , method_pattern = pattern . split ( <STRING> , 1 ) <NEWLINE> if fnmatch . fnmatch ( method_file , file_pattern ) and fnmatch . fnmatch ( class_method_name , method_pattern ) : <NEWLINE> <INDENT> return False <NEWLINE> <DEDENT> <DEDENT>
if request_format == <STRING> : <NEWLINE> <INDENT> return render_template ( <STRING> , <NEWLINE> <INDENT> images = image_structs , <NEWLINE> album = album ) <NEWLINE> else : <NEWLINE> <DEDENT> return image_structs <NEWLINE> <DEDENT>
if request_format == <STRING> : <NEWLINE> <INDENT> return render_template ( <STRING> , <NEWLINE> <INDENT> images = image_structs , <NEWLINE> album = album ) <NEWLINE> else : <NEWLINE> <DEDENT> return image_structs <NEWLINE> <DEDENT>
<COMMENT> <NL> <INDENT> cwd = os . getcwd ( ) <NEWLINE> package_names = [ x for x in packages_to_create ] <NEWLINE> package_names . sort ( ) <NEWLINE> for package_name in package_names : <NEWLINE> <INDENT> package_version = packages_to_create [ package_name ] <NEWLINE> if normalize_package_name ( package_name ) in excluded_packages : <NEWLINE> <INDENT> print ( <STRING> % package_name ) <NEWLINE> continue <NEWLINE> <DEDENT> print ( <STRING> % package_name ) <NEWLINE> if dry : <NEWLINE> <INDENT> continue <NEWLINE> <DEDENT> temp_dir = mkdtemp ( suffix = <STRING> ) <NEWLINE> os . chdir ( temp_dir ) <NEWLINE> prepare_package ( package_name , package_version , deb_dest_dir , config_parser , allow_unsafe_download , verbose = verbose ) <NEWLINE> if not keep_temp : <NEWLINE> <INDENT> shutil . rmtree ( temp_dir ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> print ( <STRING> % ( package_name , package_version , temp_dir ) ) <NEWLINE> <DEDENT> <DEDENT> os . chdir ( cwd ) <NEWLINE> <DEDENT>
self . api . update ( { <STRING> : document . id } , update_instruction , upsert = upsert ) <NEWLINE>
if tag == VERSION : <NEWLINE> <INDENT> info = <STRING> . format ( <NEWLINE> <INDENT> tag , VERSION <NEWLINE> <DEDENT> ) <NEWLINE> sys . exit ( info ) <NEWLINE> <DEDENT>
@ isa ( <STRING> , RV32I , opcode = 0b1101111 ) <NEWLINE> <INDENT> class InstructionJAL ( InstructionJType ) : <NEWLINE> <INDENT> def execute ( self , model : Model ) : <NEWLINE> <INDENT> model . state . intreg [ self . rd ] = model . state . pc + 4 <NEWLINE> model . state . pc += self . imm <NEWLINE> <DEDENT> <DEDENT> <DEDENT>
to_find = name_list [ 0 ] <NEWLINE> <INDENT> found = None <NEWLINE> for key , value in data . items ( ) : <NEWLINE> <INDENT> if in_or_eq ( key , to_find ) : <NEWLINE> <INDENT> found = self . find ( name_list [ 1 : ] , strict , value , misses ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> found = self . find ( name_list , strict , value , misses - 1 ) <NEWLINE> <DEDENT> if found : <NEWLINE> <INDENT> return found <NEWLINE> <DEDENT> <DEDENT> <DEDENT>
data = read_csv ( input , sep = sep , rm_comment = True ) <NEWLINE> <INDENT> if header : <NEWLINE> <COMMENT> <NL> <INDENT> _ = data . pop ( 0 ) <NEWLINE> <DEDENT> <DEDENT>
try : <NEWLINE> <INDENT> test1 = datetime . strptime ( start , <STRING> ) <NEWLINE> test2 = datetime . strptime ( end , <STRING> ) <NEWLINE> except : <NEWLINE> raise ValueError ( <STRING> ) <NEWLINE> <DEDENT>
if ( entity != <STRING> or ( entity in [ <STRING> , <STRING> ] and field not in [ <STRING> , <STRING> ] ) ) : <NEWLINE> <INDENT> fieldDef = self . GetFields ( entity = entity , fields = [ field ] , cdoID = cdoID ) <NEWLINE> <DEDENT>
if not accesskey or not secretkey or not repopwd or not endpoint or not bucket or not targetdir : <NEWLINE> <INDENT> raise Exception ( <STRING> ) <NEWLINE> <DEDENT>
command = ( [ <STRING> , <STRING> , <STRING> , <NEWLINE> <INDENT> <STRING> , <STRING> % tmp , <NEWLINE> <STRING> % docker_tag , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <STRING> % weather_file . basename ( ) , <NEWLINE> <STRING> , prefix , <NEWLINE> <STRING> , <STRING> ] + <NEWLINE> ( [ <STRING> , <STRING> % idd_file . basename ( ) ] <NEWLINE> if idd_file is not None else [ ] ) + <NEWLINE> [ <STRING> , <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> % idf_file . basename ( ) ] ) <NEWLINE> return command <NEWLINE> else : <NEWLINE> command = ( [ <STRING> , <NEWLINE> <STRING> , tmp / weather_file . basename ( ) , <NEWLINE> <STRING> , prefix , <NEWLINE> <STRING> , tmp . abspath ( ) ] + <NEWLINE> ( [ <STRING> , tmp / idd_file . basename ( ) ] <NEWLINE> if idd_file is not None else [ ] ) + <NEWLINE> [ <STRING> , <STRING> , <NEWLINE> <STRING> , <NEWLINE> tmp / idf_file . basename ( ) ] ) <NEWLINE> return command <NEWLINE> <DEDENT>
self . ping_timeout_job = gevent . spawn_later ( self . ping_timeout , ping_timeout ) <NEWLINE>
all_event = [ ] <NEWLINE> <INDENT> nr_event = 0 <NEWLINE> with open ( filename , <STRING> ) as f : <NEWLINE> <INDENT> while True : <NEWLINE> <INDENT> nr_event += 1 <NEWLINE> if progress and nr_event % 10000 == 0 : <NEWLINE> <INDENT> print ( <STRING> , end = <STRING> ) <NEWLINE> <DEDENT> data = f . read ( 4 ) <NEWLINE> if data == <STRING> : <NEWLINE> <COMMENT> <NL> <INDENT> break <NEWLINE> <DEDENT> s = ( ( ( ( ( data [ 3 ] << 8 ) + data [ 2 ] ) << 8 ) + data [ 1 ] ) << 8 ) + data [ 0 ] <NEWLINE> finish_code = ( s & ( 1 << 31 ) ) >> 31 <NEWLINE> event_length = ( s & ( ( 1 << 14 ) - 1 ) << 17 ) >> 17 <NEWLINE> header_length = ( s & ( 0b11111 << 12 ) ) >> 12 <NEWLINE> crate_id = ( s & ( 0b1111 << 8 ) ) >> 8 <NEWLINE> slot_id = ( s & ( 0b1111 << 4 ) ) >> 4 <NEWLINE> channel_nr = s & 0b1111 <NEWLINE> data = f . read ( 4 ) <NEWLINE> eventtime_lo = ( ( ( ( ( data [ 3 ] << 8 ) + data [ 2 ] ) << 8 ) + data [ 1 ] ) << 8 ) + data [ 0 ] <NEWLINE> data = f . read ( 4 ) <NEWLINE> s = ( data [ 3 ] << 8 ) + data [ 2 ] <NEWLINE> cfd_trigger_bits = ( s & ( 0b111 << 13 ) ) >> 13 <NEWLINE> cfd_fractional = s & ( ( 1 << 13 ) - 1 ) <NEWLINE> eventtime_hi = ( data [ 1 ] << 8 ) + data [ 0 ] <NEWLINE> data = f . read ( 4 ) <NEWLINE> s = ( data [ 3 ] << 8 ) + data [ 2 ] <NEWLINE> trace_flag = ( s & ( 1 << 15 ) ) >> 15 <NEWLINE> trace_length = s & ( ( 1 << 16 ) - 1 ) <NEWLINE> event_energy = ( data [ 1 ] << 8 ) + data [ 0 ] <NEWLINE> for i in range ( header_length - 4 ) : <NEWLINE> <INDENT> data = f . read ( 4 ) <NEWLINE> <DEDENT> if event_length - header_length > 0 : <NEWLINE> <COMMENT> <NL> <COMMENT> <NL> <INDENT> trace = np . fromfile ( f , <STRING> . format ( event_length - header_length ) , count = 1 ) [ 0 , : , : ] <NEWLINE> <COMMENT> <NL> if keep_trace : <NEWLINE> <INDENT> trace [ : , 0 ] , trace [ : , 1 ] = trace [ : , 1 ] , trace [ : , 0 ] . copy ( ) <NEWLINE> trace = trace . flatten ( ) <NEWLINE> <DEDENT> <DEDENT> else : <NEWLINE> <INDENT> trace = [ ] <NEWLINE> <DEDENT> if not keep_trace : <NEWLINE> <INDENT> trace = [ ] <NEWLINE> <DEDENT> TS = 2 ** 32 * mpmath . mpf ( eventtime_hi ) + mpmath . mpf ( eventtime_lo ) <NEWLINE> TS *= 10e-9 <NEWLINE> CFD_error = False <NEWLINE> if cfd_trigger_bits == 7 : <NEWLINE> <INDENT> CFD_error = True <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> TS += mpmath . mpf ( cfd_trigger_bits - 1 + cfd_fractional / 8192 ) * 2e-9 <NEWLINE> <DEDENT> yield Event ( channel_nr , crate_id , slot_id , TS , event_energy , trace , CFD_error ) <NEWLINE> <DEDENT> <DEDENT> return <NEWLINE> <DEDENT>
return CFD , cfdtrigger , errors <NEWLINE>
def to_namedtuple ( name , d ) : <NEWLINE> <INDENT> keys = list ( d . keys ( ) ) <NEWLINE> namedtuple = collections . namedtuple ( name , keys ) <NEWLINE> return namedtuple ( ** d ) <NEWLINE> <DEDENT>
def test_smoothline ( ) : <NEWLINE> <INDENT> canvas = pyagg . Canvas ( 1000 , 500 ) <NEWLINE> canvas . percent_space ( ) <NEWLINE> for x1 , x2 in zip ( range ( - 50 , 100 , 10 ) , range ( 0 , 150 , 10 ) ) : <NEWLINE> <INDENT> canvas . draw_line ( [ x2 , 0 , x1 , 100 ] ) <NEWLINE> <DEDENT> canvas . draw_line ( [ 10 , 10 , 50 , 90 , 90 , 10 ] , <NEWLINE> <INDENT> smooth = True , <NEWLINE> fillcolor = ( 222 , 0 , 0 ) , <NEWLINE> fillsize = 2 ) <NEWLINE> <DEDENT> canvas . draw_text ( <STRING> , ( 50 , 50 ) , textfont = <STRING> , textsize = 55 ) <NEWLINE> return canvas <NEWLINE> <DEDENT>
if not self . has_duplicates ( ) : <NEWLINE> <INDENT> return super ( ) . contains_element ( element ) <NEWLINE> <DEDENT>
if intersection . area == box_list [ 0 ] . area : <NEWLINE> <INDENT> if intersection . area <= PyAlgorithm . unionRects ( rect_list ) . area : <NEWLINE> <INDENT> return intersection <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> return box ( 0 , 0 , 0 , 0 ) <NEWLINE> else : <NEWLINE> <DEDENT> return intersection <NEWLINE> <DEDENT>
<COMMENT> <NL> <COMMENT> <NL> <INDENT> for representative_sample , family in families . items ( ) : <NEWLINE> <INDENT> if len ( family ) == 1 : <NEWLINE> <INDENT> logger . info ( <STRING> , representative_sample ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> logger . info ( <STRING> , <STRING> . join ( family ) ) <NEWLINE> <DEDENT> max_coverage_per_sample = max ( 1 , max_coverage // len ( family ) ) <NEWLINE> logger . info ( <STRING> , max_coverage_per_sample ) <NEWLINE> trios = family_trios [ representative_sample ] <NEWLINE> <DEDENT> <DEDENT>
def eval_overlap ( n1 , n2 ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> hang1 = n2 [ <STRING> ] - n1 [ <STRING> ] <NEWLINE> overlap = zip ( n1 [ <STRING> ] [ hang1 : ] , n2 [ <STRING> ] ) <NEWLINE> match , mismatch = ( 0 , 0 ) <NEWLINE> for ( c1 , c2 ) in overlap : <NEWLINE> <INDENT> if c1 in [ <STRING> , <STRING> , <STRING> , <STRING> ] and c2 in [ <STRING> , <STRING> , <STRING> , <STRING> ] : <NEWLINE> <INDENT> if c1 == c2 : <NEWLINE> <INDENT> match += 1 <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> mismatch += 1 <NEWLINE> <DEDENT> <DEDENT> <DEDENT> return ( match , mismatch ) <NEWLINE> <DEDENT>
if given_args_length < command_args_length : <NEWLINE> <INDENT> arg_index = command_args_length - given_args_length <NEWLINE> if arg_index >= len ( comm [ <STRING> ] ) : <NEWLINE> <INDENT> arg_index = 0 <NEWLINE> <DEDENT> error = colorize ( comm [ <STRING> ] [ given_args_length ] , <STRING> ) + <STRING> <NEWLINE> elif given_args_length > max_args_length : <NEWLINE> error = <STRING> . format ( <NEWLINE> <INDENT> command_args_length , given_args_length ) <NEWLINE> else : <NEWLINE> <COMMENT> <NL> <COMMENT> <NL> <DEDENT> error = comm [ <STRING> ] ( * args ) <NEWLINE> <DEDENT>
logger . debug ( <STRING> , zone_id , data ) <NEWLINE> <INDENT> response = self . _send_request ( <STRING> , <STRING> . format ( zone_id ) , data ) <NEWLINE> <DEDENT>
def _parse_filename ( f_arg , d_arg , name_contains ) : <NEWLINE> <INDENT> if f_arg is not None : <NEWLINE> <INDENT> for file in os . listdir ( os . path . join ( os . path . dirname ( __file__ ) , d_arg ) ) : <NEWLINE> <INDENT> if file . endswith ( <STRING> ) : <NEWLINE> <INDENT> if name_contains in file : <NEWLINE> <INDENT> return file <NEWLINE> <DEDENT> <DEDENT> <DEDENT> <DEDENT> return None <NEWLINE> <DEDENT>
def handle_batch_place ( self , frame ) : <NEWLINE> <INDENT> for x in frame [ <STRING> ] : <NEWLINE> <INDENT> self . handle_place ( x ) <NEWLINE> <DEDENT> <DEDENT>
for member in pyson . evaluate ( term . args [ 1 ] , intention . scope ) : <NEWLINE> <INDENT> intention . stack . append ( choicepoint ) <NEWLINE> <DEDENT>
def _request ( self , name , namespace , devId = None , payload = { } ) : <NEWLINE> <INDENT> headers = { <NEWLINE> <INDENT> <STRING> : <STRING> <NEWLINE> <DEDENT> } <NEWLINE> header = { <NEWLINE> <INDENT> <STRING> : name , <NEWLINE> <STRING> : namespace , <NEWLINE> <STRING> : 1 , <NEWLINE> <DEDENT> } <NEWLINE> payload [ <STRING> ] = SESSION . accessToken <NEWLINE> if namespace != <STRING> : <NEWLINE> <INDENT> payload [ <STRING> ] = devId <NEWLINE> <DEDENT> data = { <NEWLINE> <INDENT> <STRING> : header , <NEWLINE> <STRING> : payload <NEWLINE> <DEDENT> } <NEWLINE> response = requests . post ( <NEWLINE> <INDENT> ( TUYACLOUDURL + <STRING> ) . format ( SESSION . region ) , <NEWLINE> json = data <NEWLINE> <DEDENT> ) <NEWLINE> if not response . ok : <NEWLINE> <INDENT> _LOGGER . warning ( <STRING> , response . status_code , devId ) <NEWLINE> return <NEWLINE> <DEDENT> response_json = response . json ( ) <NEWLINE> if response_json [ <STRING> ] [ <STRING> ] != <STRING> : <NEWLINE> <INDENT> _LOGGER . debug ( <STRING> + <NEWLINE> <INDENT> response_json [ <STRING> ] [ <STRING> ] ) <NEWLINE> <DEDENT> <DEDENT> return response_json <NEWLINE> <DEDENT>
<COMMENT> <NL> <INDENT> dimu_pt , dimu_phi , dimu_para , dimu_perp = create_metres ( <NEWLINE> <INDENT> event . METnoX , event . MuonSelection , <NEWLINE> <DEDENT> ) <NEWLINE> event . DiMuon_pt = dimu_pt <NEWLINE> event . DiMuon_phi = dimu_phi <NEWLINE> event . METnoX_diMuonParaProjPt = dimu_para <NEWLINE> event . METnoX_diMuonPerpProjPt = dimu_perp <NEWLINE> event . METnoX_diMuonParaProjPt_Minus_DiMuon_pt = dimu_para - dimu_pt <NEWLINE> event . METnoX_diMuonPerpProjPt_Plus_DiMuon_pt = dimu_perp + dimu_pt <NEWLINE> event . METnoX_diMuonParaProjPt_Div_DiMuon_pt = dimu_para / dimu_pt <NEWLINE> event . METnoX_diMuonPerpProjPt_Plus_DiMuon_pt_Div_DiMuon_pt = ( dimu_perp + dimu_pt ) / dimu_pt <NEWLINE> <DEDENT>
<COMMENT> <NL> <INDENT> libdata = fastq2insert_size ( sys . stderr , fastq , fasta , mapq , threads , limit / 100 , verbose ) <NEWLINE> <COMMENT> <NL> <COMMENT> <NL> libraries = [ ] <NEWLINE> <COMMENT> <NL> for fq1 , fq2 , ismedian , ismean , isstd , pairs in sorted ( libdata , key = lambda x : x [ 3 ] ) : <NEWLINE> <COMMENT> <NL> <INDENT> if not libraries or ismean > 1.5 * libraries [ - 1 ] [ 4 ] [ 0 ] : <NEWLINE> <COMMENT> <NL> <INDENT> libraries . append ( [ [ ] , [ ] , [ ] , [ ] , [ ] , [ ] ] ) <NEWLINE> i = 1 <NEWLINE> <COMMENT> <NL> <DEDENT> libraries [ - 1 ] [ 0 ] . append ( <STRING> % i ) <NEWLINE> libraries [ - 1 ] [ 1 ] . append ( open ( fq1 ) ) <NEWLINE> libraries [ - 1 ] [ 2 ] . append ( open ( fq2 ) ) <NEWLINE> <COMMENT> <NL> orientation = get_orientation ( pairs , fq1 , fq2 ) <NEWLINE> libraries [ - 1 ] [ 3 ] . append ( orientation ) <NEWLINE> <COMMENT> <NL> libraries [ - 1 ] [ 4 ] . append ( int ( ismean ) ) <NEWLINE> stdfrac = isstd / ismean <NEWLINE> <COMMENT> <NL> if stdfrac > 0.66 : <NEWLINE> <INDENT> sys . stderr . write ( <STRING> % ( ismean , isstd , fq1 , fq2 ) ) <NEWLINE> <COMMENT> <NL> <DEDENT> if stdfrac > 1 : <NEWLINE> <INDENT> stdfrac = 1.0 <NEWLINE> <DEDENT> libraries [ - 1 ] [ 5 ] . append ( stdfrac ) <NEWLINE> <COMMENT> <NL> i += 1 <NEWLINE> <DEDENT> return libraries <NEWLINE> <DEDENT>
return Mutation ( <NEWLINE> <INDENT> seq = str ( seq_region ) , <NEWLINE> start = start_pos , <NEWLINE> stop = end_pos , <NEWLINE> mutation_start = mutation_start_pos_in_region , <NEWLINE> n_removed = n_aa_deleted , <NEWLINE> n_inserted = n_aa_inserted , <NEWLINE> annot = annot ) <NEWLINE> <DEDENT>
def __init__ ( self , text : str ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> self . text = text <NEWLINE> self . items = set ( ) <NEWLINE> count : Counter = Counter ( ) <NEWLINE> for key , val in self . parse ( text ) : <NEWLINE> <INDENT> self . items . add ( val ) <NEWLINE> count [ key ] += 1 <NEWLINE> if key == <STRING> : <NEWLINE> <INDENT> self . el = val <NEWLINE> <DEDENT> <DEDENT> <DEDENT>
from pprint import pprint <NEWLINE> <INDENT> with open ( filename , <STRING> ) as script : <NEWLINE> <INDENT> script_content = script . readlines ( ) <NEWLINE> <DEDENT> pprint ( script_content ) <NEWLINE> pprint ( script_content [ 0 ] . rstrip ( ) ) <NEWLINE> pprint ( script_content [ 0 ] . strip ( ) ) <NEWLINE> if ( script_content [ 0 ] . rstrip ( ) != OP_BASH_HEADER ) and ( script_content [ 0 ] . rstrip ( ) != OP_SH_HEADER ) : <NEWLINE> <INDENT> script_content . insert ( 0 , OP_SH_HEADER + <STRING> ) <NEWLINE> <DEDENT> usr_exec_file = os . path . basename ( new_sh_file ) <NEWLINE> pprint ( script_content ) <NEWLINE> pprint ( <STRING> + P_USR_LOCAL_BIN_DIR + usr_exec_file ) <NEWLINE> if os . path . exists ( P_USR_LOCAL_BIN_DIR + usr_exec_file ) : <NEWLINE> <INDENT> return False <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> with open ( P_USR_LOCAL_BIN_DIR + usr_exec_file , <STRING> ) as sh_file : <NEWLINE> <INDENT> for script_line in script_content : <NEWLINE> <INDENT> sh_file . write ( script_line ) <NEWLINE> <DEDENT> <DEDENT> os . chmod ( P_USR_LOCAL_BIN_DIR + usr_exec_file , 0o755 ) <NEWLINE> return True <NEWLINE> <DEDENT> <DEDENT>
<COMMENT> <NL> <INDENT> if np . issubdtype ( dtype , np . integer ) : <NEWLINE> <INDENT> if out_min is None : <NEWLINE> <INDENT> out_min = np . iinfo ( dtype ) . min <NEWLINE> <DEDENT> if out_max is None : <NEWLINE> <INDENT> out_max = np . iinfo ( dtype ) . max <NEWLINE> <COMMENT> <NL> <DEDENT> <DEDENT> else : <NEWLINE> <INDENT> if out_min is None : <NEWLINE> <INDENT> out_min = 0. <NEWLINE> <DEDENT> if in_max is None : <NEWLINE> <INDENT> out_max = 1. <NEWLINE> <COMMENT> <NL> <DEDENT> <DEDENT> scaled = ( img - in_min ) * ( out_max - out_min ) / ( in_max - in_min ) + out_min <NEWLINE> return saturate_cast ( scaled , dtype ) <NEWLINE> <DEDENT>
def clean ( self , value ) : <NEWLINE> <INDENT> cleaned_data = [ ] <NEWLINE> errors = [ ] <NEWLINE> value = filter ( None , value ) <NEWLINE> for index , item in enumerate ( value ) : <NEWLINE> <INDENT> try : <NEWLINE> <INDENT> cleaned_data . append ( self . base_field . clean ( item ) ) <NEWLINE> <DEDENT> except forms . ValidationError as error : <NEWLINE> <INDENT> errors . append ( <NEWLINE> <INDENT> prefix_validation_error ( <NEWLINE> <INDENT> error , self . error_messages [ <STRING> ] , code = <STRING> , params = { <STRING> : index } <NEWLINE> <DEDENT> ) <NEWLINE> <DEDENT> ) <NEWLINE> <DEDENT> <DEDENT> if errors : <NEWLINE> <INDENT> raise forms . ValidationError ( list ( chain . from_iterable ( errors ) ) ) <NEWLINE> <DEDENT> if not cleaned_data and self . required : <NEWLINE> <INDENT> raise forms . ValidationError ( self . error_messages [ <STRING> ] ) <NEWLINE> <DEDENT> return cleaned_data <NEWLINE> <DEDENT>
widget . world . setToIdentity ( ) <NEWLINE> <INDENT> if event . buttons ( ) == Qt . LeftButton : <NEWLINE> <INDENT> self . set_x_rotation ( widget , widget . xWorldRot + dy ) <NEWLINE> self . set_z_rotation ( widget , widget . zWorldRot + dx ) <NEWLINE> <DEDENT> elif event . buttons ( ) == Qt . RightButton : <NEWLINE> <INDENT> self . set_x_rotation ( widget , widget . xWorldRot + dy ) <NEWLINE> self . set_y_rotation ( widget , widget . yWorldRot + dx ) <NEWLINE> <DEDENT> elif event . buttons ( ) == Qt . MiddleButton : <NEWLINE> <COMMENT> <NL> <INDENT> distance_x = 200 * abs ( widget . zCameraPos + widget . centroid [ 2 ] ) / widget . width ( ) <NEWLINE> distance_y = 200 * abs ( widget . zCameraPos + widget . centroid [ 2 ] ) / widget . height ( ) <NEWLINE> self . set_x_movement ( widget , widget . xCameraPos + ( distance_x * dx / 200.0 ) ) <NEWLINE> self . set_y_movement ( widget , widget . yCameraPos - ( distance_y * dy / 200.0 ) ) <NEWLINE> <DEDENT> <DEDENT>
<COMMENT> <NL> <INDENT> self . fill_buffer ( _POSITION , 3 , vertices , GLfloat , GL_FLOAT , self . vbos [ _POSITION ] ) <NEWLINE> self . fill_buffer ( _COLOR , 4 , colors , GLfloat , GL_FLOAT , self . vbos [ _COLOR ] ) <NEWLINE> <DEDENT>
e_transport_config = engine_transport_config <NEWLINE> <INDENT> if engine_transport_config in ( ENGINE_TRANSPORT_CONFIG , ENGINE_TRANSPORT_BRIDGE_CONFIG ) : <NEWLINE> <INDENT> e_transport_config = None <NEWLINE> <DEDENT> <DEDENT>
def submit_xml ( self , xml ) : <NEWLINE> <INDENT> data = { <STRING> : ET . tostring ( xml ) , <NEWLINE> <INDENT> <STRING> : self . API } <NEWLINE> <DEDENT> response = urllib2 . urlopen ( self . url , utf8urlencode ( data ) ) <NEWLINE> root = ET . parse ( response ) . getroot ( ) <NEWLINE> if root . tag == <STRING> : <NEWLINE> <INDENT> raise USPSXMLError ( root ) <NEWLINE> <DEDENT> error = root . find ( <STRING> ) <NEWLINE> if error is not None : <NEWLINE> <INDENT> raise USPSXMLError ( error ) <NEWLINE> <DEDENT> return root <NEWLINE> <DEDENT>
def is_virtualenv ( ) : <NEWLINE> <INDENT> return hasattr ( sys , <STRING> ) or ( sys . prefix != sys . base_prefix ) <NEWLINE> <DEDENT>
if ( options . kaichu_jira_host <NEWLINE> <INDENT> and options . pocket_change_username <NEWLINE> and ( options . pocket_change_password or options . pocket_change_token ) <NEWLINE> and options . kaichu_jira_app_key <NEWLINE> and options . kaichu_jira_project_key ) : <NEWLINE> try : <NEWLINE> <INDENT> KaichuManager . jira = JiraClient ( options . pocket_change_host , <NEWLINE> <INDENT> options . kaichu_jira_host , <NEWLINE> options . kaichu_jira_app_key , <NEWLINE> options . pocket_change_username , <NEWLINE> options . pocket_change_password , <NEWLINE> options . pocket_change_token ) <NEWLINE> <DEDENT> <DEDENT> except ValueError : <NEWLINE> <INDENT> return False <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> return True <NEWLINE> else : <NEWLINE> <DEDENT> return False <NEWLINE> <DEDENT>
def check_authkey ( f ) : <NEWLINE> <INDENT> def wrapper ( * args , ** kwargs ) : <NEWLINE> <INDENT> if not args [ 0 ] . authkey or not args [ 0 ] . uid == args [ 1 ] : <NEWLINE> <INDENT> args [ 0 ] . authorize ( args [ 1 ] ) <NEWLINE> <DEDENT> return f ( * args , ** kwargs ) <NEWLINE> <DEDENT> return wrapper <NEWLINE> <DEDENT>
<COMMENT> <NL> <COMMENT> <NL> <INDENT> attribute_resolver = KeyResolver ( lambda k , v : getattr ( v , k ) , ( AttributeError , TypeError ) ) <NEWLINE> <DEDENT>
def launch_task ( self , task_obj , * args , ** kwargs ) : <NEWLINE> <INDENT> tid_obj = self . register_task ( task_obj ) <NEWLINE> task_obj . run ( * args , ** kwargs ) <NEWLINE> return task_obj <NEWLINE> <DEDENT>
<COMMENT> <NL> <INDENT> if float ( self . elements [ ix ] . length ) == 0 : <NEWLINE> <INDENT> return y [ ix ] <NEWLINE> <DEDENT> <DEDENT>
conditions = self . get ( key ) <NEWLINE> <INDENT> if not conditions : <NEWLINE> <COMMENT> <NL> <INDENT> return True <NEWLINE> <DEDENT> <DEDENT>
admin . site . register ( Switch , SwitchAdmin ) <NEWLINE>
def _resolved ( self , path , kwargs ) : <NEWLINE> <INDENT> if not path : <NEWLINE> <INDENT> return self <NEWLINE> <DEDENT> c = self <NEWLINE> for name in path [ : - 1 ] : <NEWLINE> <INDENT> that = self . resolvables . get ( name ) <NEWLINE> c = Context ( c ) if that is None else that . resolve ( c ) <NEWLINE> <DEDENT> <DEDENT>
def process_response ( self , request , response ) : <NEWLINE> <INDENT> if ( not getattr ( request , <STRING> , False ) ) or not request . clienttrack_first_visit : <NEWLINE> <COMMENT> <NL> <INDENT> if not request . clienttrack_first_visit : <NEWLINE> <INDENT> request . clienttrack_first_visit = time . time ( ) <NEWLINE> <DEDENT> max_age = 3 * 365 * 24 * 60 * 60 <COMMENT> <NEWLINE> expires_time = time . time ( ) + max_age <NEWLINE> expires = cookie_date ( expires_time ) <NEWLINE> response . set_cookie ( <STRING> , <STRING> % ( request . clienttrack_first_visit , request . clienttrack_uid , time . time ( ) ) , <NEWLINE> <INDENT> max_age = max_age , expires = expires ) <NEWLINE> <DEDENT> <DEDENT> return response <NEWLINE> <DEDENT>
svm = sns . catplot ( x = x_axis_name , y = <STRING> , hue = hue , data = data_table , <NEWLINE> <INDENT> hue_order = None , <NEWLINE> kind = kind , orient = None , color = fig_facecolor , palette = palette , ax = ax1 ) <NEWLINE> <DEDENT>
def verify_result ( self , expected ) : <NEWLINE> <INDENT> self . assertEqual ( expected , self . result ) <NEWLINE> <DEDENT>
nx . write_graphml ( graph_out , path ) <NEWLINE>
<COMMENT> <NL> <INDENT> desired_key = model . Key . from_raw ( joined ) <NEWLINE> root = ( ancestor for ancestor in desired_key . ancestry ) . next ( ) <NEWLINE> tail = ( <NEWLINE> <INDENT> desired_key . flatten ( True ) [ 0 ] . replace ( root . flatten ( True ) [ 0 ] , <STRING> ) or ( <NEWLINE> <INDENT> <STRING> ) ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT>
else : <NEWLINE> <INDENT> logger . debug ( <STRING> ) <NEWLINE> rmtree ( directory_name ) <NEWLINE> return True <NEWLINE> <DEDENT>
if next_img . shape != img_shape : <NEWLINE> <INDENT> raise ValueError ( <STRING> % <NEWLINE> <INDENT> ( img_shape , next_img . shape ) ) <NEWLINE> img_out += next_img <NEWLINE> <COMMENT> <NL> overlap_idxs = ( img_out != 0 ) & ( next_img != 0 ) <NEWLINE> img_out [ overlap_idxs ] = next_img [ overlap_idxs ] <NEWLINE> <DEDENT> <DEDENT>
def get_arti_berhub ( self , soup = None ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> if soup is None : <NEWLINE> <INDENT> soup = self . soup <NEWLINE> <DEDENT> <DEDENT>
@ extension_class ( list ) <NEWLINE> <INDENT> def Sort ( self : Flow , by ) : <NEWLINE> <INDENT> if is_to_destruct ( by ) : <NEWLINE> <INDENT> by = destruct_func ( by ) <NEWLINE> <DEDENT> self . stream . sort ( key = by ) <NEWLINE> return self <NEWLINE> <DEDENT> <DEDENT>
while ( len ( targets ) > 1 ) and ( len ( dests ) > 1 ) and ( targets [ 0 ] == dests [ 0 ] ) : <NEWLINE> <INDENT> targets = targets [ 1 : ] <NEWLINE> dests = dests [ 1 : ] <NEWLINE> <DEDENT>
if self . balloon is None : <NEWLINE> <INDENT> if ( self . balloontop > 0 ) or ( self . balloonbottom > 0 ) : <NEWLINE> <INDENT> self . output = self . output . split ( <STRING> ) <NEWLINE> self . output = self . output [ self . balloontop : ~ ( self . balloonbottom ) ] <NEWLINE> self . output = <STRING> . join ( self . output ) <NEWLINE> <DEDENT> <DEDENT>
<COMMENT> <NL> <INDENT> if self . restriction is not None : <NEWLINE> <INDENT> logic = Metadata . makeRestrictionLogic ( self . restriction ) <NEWLINE> ponies = { } <NEWLINE> for ponydir in ponydirs : <NEWLINE> <INDENT> for pony in Metadata . restrictedPonies ( ponydir , logic ) : <NEWLINE> <INDENT> if ( pony in oldponies ) and not ( pony in ponies ) : <COMMENT> <NEWLINE> <INDENT> ponies [ pony ] = ponydir + pony + <STRING> <NEWLINE> <DEDENT> <DEDENT> <DEDENT> if len ( ponies ) > 0 : <NEWLINE> <INDENT> oldponies = ponies <NEWLINE> <DEDENT> <DEDENT> <DEDENT>
if coord_ts is None : <NEWLINE> <INDENT> if cur_corr > file_data [ i - 1 ] [ CORR_KEY ] and cur_corr > file_data [ i + 1 ] [ CORR_KEY ] : <NEWLINE> <INDENT> logger . info ( <STRING> , cur_corr , cur_coord ) <NEWLINE> return - math . log10 ( inv_C_0 / sum_for_pka ) , cur_corr , cur_coord <NEWLINE> else : <NEWLINE> <DEDENT> if cur_coord >= coord_ts : <NEWLINE> <INDENT> logger . info ( <STRING> , cur_coord , cur_corr ) <NEWLINE> return - math . log10 ( inv_C_0 / sum_for_pka ) , cur_corr , cur_coord <NEWLINE> <DEDENT> <DEDENT>
copy_field ( <STRING> , True ) <NEWLINE> <INDENT> copy_field ( <STRING> ) <NEWLINE> copy_field ( <STRING> ) <NEWLINE> if access_token is not None : <NEWLINE> <INDENT> user . access_token = access_token <NEWLINE> <DEDENT> <DEDENT>
try : <NEWLINE> <INDENT> best_token = token_manager . get_access_token ( user_id ) <NEWLINE> except UserToken . DoesNotExist : <NEWLINE> pass <NEWLINE> else : <NEWLINE> if best_token . id not in processed_user_tokens : <NEWLINE> <INDENT> logger . info ( <STRING> ) <NEWLINE> debug_all_tokens_for_user . retry ( args = [ user_id ] , <NEWLINE> <INDENT> countdown = 45 ) <NEWLINE> <DEDENT> <DEDENT> else : <NEWLINE> <INDENT> logger . info ( <STRING> ) <NEWLINE> tokens_to_delete = sorted ( processed_user_tokens ) <NEWLINE> tokens_to_delete . remove ( best_token . id ) <NEWLINE> for token_id in tokens_to_delete : <NEWLINE> <INDENT> UserToken . objects . filter ( id = token_id ) . update ( deleted = True ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT>
qname = dns . name . from_text ( theZone ) <NEWLINE> <INDENT> request = dns . message . make_query ( qname , rdtype = dns . rdatatype . SOA , rdclass = dns . rdataclass . ANY ) <NEWLINE> request . use_edns ( r . edns , r . ednsflags , r . payload ) <NEWLINE> request . want_dnssec ( True ) <NEWLINE> response = None <NEWLINE> nameservers = misc . authNS ( theZone ) <NEWLINE> for nameserver in nameservers [ : ] : <NEWLINE> <INDENT> try : <NEWLINE> <INDENT> l . logDebug ( <STRING> . format ( nameserver , theZone ) ) <NEWLINE> response = dns . query . tcp ( request , nameserver , 10 ) <NEWLINE> rcode = response . rcode ( ) <NEWLINE> if rcode == 0 : continue <NEWLINE> <DEDENT> except ( socket . error , dns . exception . Timeout , dns . query . UnexpectedSource , <NEWLINE> <INDENT> dns . exception . FormError , EOFError , dns . resolver . NoAnswer , <NEWLINE> dns . resolver . NXDOMAIN ) : <NEWLINE> pass <NEWLINE> <DEDENT> l . logError ( <STRING> . format ( <NEWLINE> <INDENT> nameserver , theZone ) ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT>
if png_icon_name in files : <NEWLINE> <INDENT> new_path = os . path . join ( root , png_icon_name ) <NEWLINE> new_size = self . _extract_icon_size_from_path ( new_path ) <NEWLINE> <DEDENT>
content = [ ] <NEWLINE> <INDENT> if isinstance ( file , list ) : <NEWLINE> <INDENT> files = [ ] <NEWLINE> for filePattern in file : <NEWLINE> <INDENT> files += matchPattern ( filePattern ) <NEWLINE> <DEDENT> <DEDENT> elif isinstance ( file , str ) : <NEWLINE> <INDENT> files = matchPattern ( file ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> raise RuntimeError ( <STRING> + <NEWLINE> <INDENT> <STRING> ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT>
if version is None : <NEWLINE> <INDENT> message = ( <STRING> <NEWLINE> <INDENT> . format ( v = target , id = resource . id , vers = <STRING> . join ( options ) ) ) <NEWLINE> <DEDENT> <DEDENT>
restorer = capnp . Restorer ( capability . TestSturdyRefObjectId , _restore ) <NEWLINE> <INDENT> server = capnp . RpcServer ( loop , write_stream , restorer ) <NEWLINE> client = capnp . RpcClient ( loop , read_stream ) <NEWLINE> <DEDENT>
if not rebuild : <NEWLINE> <INDENT> if not hasattr ( stack . top , <STRING> ) : <NEWLINE> <INDENT> stack . top . sass_cache = { } <NEWLINE> <DEDENT> cache = stack . top . sass_cache <NEWLINE> <DEDENT>
return { <NEWLINE> <INDENT> <STRING> : encoded , <NEWLINE> <STRING> : signature_b64 , <NEWLINE> <STRING> : key , <NEWLINE> <STRING> : access_key , <NEWLINE> <STRING> : bucket_url , <NEWLINE> <STRING> : <STRING> , <NEWLINE> <STRING> : <STRING> , <NEWLINE> <STRING> : content_type <NEWLINE> } <NEWLINE> <DEDENT>
for kInfo in kernelInfo : <NEWLINE> <INDENT> if isInPlace and numKernelsOdd and not inPlaceDone and kInfo . in_place_possible : <NEWLINE> <INDENT> currWrite = currRead <NEWLINE> inPlaceDone = True <NEWLINE> <DEDENT> <DEDENT>
flag_dict = { <STRING> : <STRING> , <STRING> : <STRING> , <STRING> : <STRING> } <NEWLINE> <INDENT> def cancel ( ) : <NEWLINE> <INDENT> c_input = input ( <STRING> ) <NEWLINE> sub . Popen ( <STRING> , shell = True ) <NEWLINE> <DEDENT> def get_method ( ) : <NEWLINE> <INDENT> flag = <STRING> <NEWLINE> get_method = input ( <STRING> ) <NEWLINE> if get_method == <STRING> : <NEWLINE> <INDENT> flag = <STRING> <NEWLINE> <DEDENT> elif get_method == <STRING> : <NEWLINE> <INDENT> flag = <STRING> <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> flag = <STRING> <NEWLINE> <DEDENT> return flag <NEWLINE> <DEDENT> def print_time ( sleep_list , method ) : <NEWLINE> <INDENT> print ( <STRING> , flag_dict [ method ] , <STRING> , str ( sleep_list [ 0 ] ) , <STRING> , str ( sleep_list [ 1 ] ) , <STRING> ) <NEWLINE> <DEDENT> def duration ( ) : <NEWLINE> <INDENT> try : <NEWLINE> <INDENT> get_hour = int ( input ( <STRING> ) ) <NEWLINE> <DEDENT> except ValueError : <NEWLINE> <INDENT> get_hour = 0 <NEWLINE> <DEDENT> try : <NEWLINE> <INDENT> get_minute = int ( input ( <STRING> ) ) <NEWLINE> <DEDENT> except ValueError : <NEWLINE> <INDENT> get_minute = 0 <NEWLINE> <DEDENT> sleep_time = get_hour * 3600 + get_minute * 60 <NEWLINE> flag = get_method ( ) <NEWLINE> print_time ( [ get_hour , get_minute ] , flag ) <NEWLINE> sub . Popen ( <STRING> + flag + <STRING> + str ( sleep_time ) , shell = True ) <NEWLINE> cancel ( ) <NEWLINE> <DEDENT> <DEDENT>
e_transport_config = engine_transport_config <NEWLINE> <INDENT> if engine_transport_config in ( ENGINE_TRANSPORT_CONFIG , ENGINE_TRANSPORT_BRIDGE_CONFIG ) : <NEWLINE> <INDENT> e_transport_config = None <NEWLINE> <DEDENT> <DEDENT>
def query_ncbi_species ( species_entry ) : <NEWLINE> <INDENT> if species_entry is None : <NEWLINE> <INDENT> return None <NEWLINE> <DEDENT> try : <NEWLINE> <INDENT> species_entry = re . compile ( species_entry ) <NEWLINE> with get_connection ( ) as connection : <NEWLINE> <INDENT> db = connection . get_database ( ) <COMMENT> <NEWLINE> species_db = db . species <COMMENT> <NEWLINE> result = species_db . find_one ( { <STRING> : species_entry } , { <STRING> : 1 , <STRING> : 0 } ) <NEWLINE> group_result = species_db . find_one ( { <STRING> : species_entry } , { <STRING> : 1 , <STRING> : 0 } ) <NEWLINE> if result is not None : <NEWLINE> <INDENT> return result [ <STRING> ] <NEWLINE> <DEDENT> elif group_result is not None : <NEWLINE> <INDENT> return group_result [ <STRING> ] <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> return None <NEWLINE> <DEDENT> <DEDENT> <DEDENT> except Exception as e : <NEWLINE> <INDENT> print ( traceback . format_exc ( ) ) <NEWLINE> return None <NEWLINE> <DEDENT> <DEDENT>
@ app . callback ( <NEWLINE> <INDENT> Output ( <STRING> , <STRING> ) , <NEWLINE> [ Input ( <STRING> , <STRING> ) ] <NEWLINE> ) <NEWLINE> def update_rerun_form ( run_name ) : <NEWLINE> run_name = run_name . split ( <STRING> ) [ 0 ] <NEWLINE> if run_name == <STRING> or not hasattr ( keys , <STRING> ) : <NEWLINE> <INDENT> return None <NEWLINE> <DEDENT> <DEDENT>
def test_describe_then_description ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> network = <STRING> <NEWLINE> description_str = <STRING> <NEWLINE> self . address_space . describe ( <NEWLINE> <INDENT> description = description_str , <NEWLINE> ip_parameter = network , <NEWLINE> <DEDENT> ) <NEWLINE> self . assertEqual ( <NEWLINE> <INDENT> self . address_space . description ( <NEWLINE> <INDENT> network , <NEWLINE> <DEDENT> ) , <NEWLINE> description_str , <NEWLINE> <DEDENT> ) <NEWLINE> ipv6_address = <STRING> <NEWLINE> description_str = <STRING> <NEWLINE> self . address_space . describe ( <NEWLINE> <INDENT> ip_parameter = ipv6_address , <NEWLINE> description = description_str , <NEWLINE> <DEDENT> ) <NEWLINE> self . assertEqual ( <NEWLINE> <INDENT> self . address_space . description ( <NEWLINE> <INDENT> ipv6_address , <NEWLINE> <DEDENT> ) , <NEWLINE> description_str , <NEWLINE> <DEDENT> ) <NEWLINE> zero_ipv4 = <STRING> <NEWLINE> description_str = <STRING> <NEWLINE> self . address_space . describe ( <NEWLINE> <INDENT> description = description_str , <NEWLINE> ip_parameter = zero_ipv4 , <NEWLINE> <DEDENT> ) <NEWLINE> self . assertEqual ( <NEWLINE> <INDENT> self . address_space . description ( <NEWLINE> <INDENT> zero_ipv4 , <NEWLINE> <DEDENT> ) , <NEWLINE> description_str , <NEWLINE> <DEDENT> ) <NEWLINE> <DEDENT>
self . __parent_supernet [ as_address ] = supernet <NEWLINE> <INDENT> children_of_as_network = ( <NEWLINE> <INDENT> self . __children_ip_object . setdefault ( as_network , set ( ) ) <NEWLINE> <DEDENT> ) <NEWLINE> children_of_supernet = ( <NEWLINE> <INDENT> self . __children_ip_object . setdefault ( supernet , set ( ) ) <NEWLINE> <DEDENT> ) <NEWLINE> <COMMENT> <NL> version = as_network . version <NEWLINE> to_arrange = set ( ) <NEWLINE> for tentative_child in children_of_supernet : <NEWLINE> <INDENT> if ( isinstance ( tentative_child , IPAddressTuple ) <NEWLINE> <INDENT> and tentative_child . version == version <NEWLINE> and tentative_child in as_network ) : <NEWLINE> to_arrange . add ( tentative_child ) <NEWLINE> <DEDENT> elif ( isinstance ( tentative_child , IPNetworkTuple ) <NEWLINE> <INDENT> and tentative_child . version == version <NEWLINE> and tentative_child . subnet_of ( as_network ) ) : <NEWLINE> to_arrange . add ( tentative_child ) <NEWLINE> <DEDENT> <DEDENT> for child in to_arrange : <NEWLINE> <INDENT> self . __parent_supernet [ child ] = as_network <NEWLINE> children_of_as_network . add ( child ) <NEWLINE> children_of_supernet . remove ( child ) <NEWLINE> <DEDENT> children_of_supernet . add ( as_network ) <NEWLINE> else : <NEWLINE> raise TypeError ( <STRING> ) <NEWLINE> <DEDENT>
self . __parent_supernet [ as_network ] = supernet <NEWLINE> <INDENT> children_of_as_network = ( <NEWLINE> <INDENT> self . __children_ip_object . setdefault ( as_network , set ( ) ) <NEWLINE> <DEDENT> ) <NEWLINE> children_of_supernet = ( <NEWLINE> <INDENT> self . __children_ip_object . setdefault ( supernet , set ( ) ) <NEWLINE> <DEDENT> ) <NEWLINE> <COMMENT> <NL> version = as_network . version <NEWLINE> to_arrange = set ( ) <NEWLINE> for tentative_child in children_of_supernet : <NEWLINE> <INDENT> if ( isinstance ( tentative_child , IPAddressTuple ) <NEWLINE> <INDENT> and tentative_child . version == version <NEWLINE> and tentative_child in as_network ) : <NEWLINE> to_arrange . add ( tentative_child ) <NEWLINE> <DEDENT> elif ( isinstance ( tentative_child , IPNetworkTuple ) <NEWLINE> <INDENT> and tentative_child . version == version <NEWLINE> and tentative_child . subnet_of ( as_network ) ) : <NEWLINE> to_arrange . add ( tentative_child ) <NEWLINE> <DEDENT> <DEDENT> for child in to_arrange : <NEWLINE> <INDENT> self . __parent_supernet [ child ] = as_network <NEWLINE> children_of_as_network . add ( child ) <NEWLINE> children_of_supernet . remove ( child ) <NEWLINE> <DEDENT> children_of_supernet . add ( as_network ) <NEWLINE> else : <NEWLINE> raise TypeError ( <STRING> ) <NEWLINE> <DEDENT>
def _convert_table ( self , ** kwargs ) : <NEWLINE> <INDENT> self . _table_elements = { <NEWLINE> <INDENT> <STRING> : list ( ) , <NEWLINE> <STRING> : list ( ) , <NEWLINE> <STRING> : list ( ) , <NEWLINE> <STRING> : 0 , <NEWLINE> <DEDENT> } <NEWLINE> <COMMENT> <NL> if isinstance ( self . _html_content , dict ) : <NEWLINE> <INDENT> self . _table_elements . update ( self . _html_content ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> obj = self . _html_content <NEWLINE> if isinstance ( self . _html_content , ( basestring , unicode ) ) : <NEWLINE> <INDENT> from bs4 import BeautifulSoup <NEWLINE> obj = BeautifulSoup ( self . _html_content ) <NEWLINE> <DEDENT> html_head = getattr ( obj , <STRING> ) <NEWLINE> if html_head : <NEWLINE> <INDENT> for a_col in html_head . find_all ( <STRING> ) : <NEWLINE> <INDENT> tmp_col_head = { <NEWLINE> <INDENT> <STRING> : a_col . get_text ( strip = True ) , <NEWLINE> <DEDENT> } <NEWLINE> self . _table_elements [ <STRING> ] . append ( tmp_col_head ) <NEWLINE> <DEDENT> <DEDENT> html_body = getattr ( obj , <STRING> ) <NEWLINE> if html_body : <NEWLINE> <INDENT> for a_row in html_body . find_all ( <STRING> ) : <NEWLINE> <INDENT> new_row = list ( ) <NEWLINE> for a_cell in a_row . find_all ( <STRING> ) : <NEWLINE> <INDENT> tmp_cell = { <NEWLINE> <INDENT> <STRING> : a_cell . get_text ( strip = True ) , <NEWLINE> <DEDENT> } <NEWLINE> new_row . append ( tmp_cell ) <NEWLINE> <DEDENT> self . _table_elements [ <STRING> ] . append ( new_row ) <NEWLINE> <DEDENT> <DEDENT> html_foot = getattr ( obj , <STRING> ) <NEWLINE> if html_foot : <NEWLINE> <INDENT> for a_foot in html_foot . find_all ( <STRING> ) : <NEWLINE> <INDENT> foot_cell = { <NEWLINE> <INDENT> <STRING> : a_foot . get_text ( strip = True ) , <NEWLINE> <DEDENT> } <NEWLINE> <DEDENT> self . _table_elements [ <STRING> ] . append ( foot_cell ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT>
def addDeterminants ( self , text , deter_rule , matches , match_begin , match_end , current_position ) : <NEWLINE> <INDENT> deter_rule = deter_rule [ FastCNER . END ] <NEWLINE> end = current_position if match_end == 0 else match_end <NEWLINE> current_span = Span ( match_begin + self . offset , end + self . offset , <NEWLINE> <INDENT> text [ match_begin : end ] ) <NEWLINE> <DEDENT> current_spans_list = [ ] <NEWLINE> overlap_checkers = self . overlap_checkers <NEWLINE> for key in deter_rule . keys ( ) : <NEWLINE> <INDENT> rule_id = deter_rule [ key ] <NEWLINE> if self . logger is not None : <NEWLINE> <INDENT> self . logger . debug ( <NEWLINE> <INDENT> <STRING> . format ( match_begin , match_end , str ( self . rule_store [ rule_id ] ) ) ) <NEWLINE> <DEDENT> <DEDENT> current_span . rule_id = rule_id <NEWLINE> if key in overlap_checkers : <NEWLINE> <INDENT> current_spans_list = matches [ key ] <NEWLINE> overlap_checker = overlap_checkers [ key ] <NEWLINE> overlapped_pos = overlap_checker . search ( current_span . begin , current_span . end ) <NEWLINE> if len ( overlapped_pos ) > 0 : <NEWLINE> <INDENT> pos = overlapped_pos . pop ( ) . data <NEWLINE> overlapped_span = current_spans_list [ pos ] <NEWLINE> if not self . compareSpan ( current_span , overlapped_span ) : <NEWLINE> <INDENT> continue <NEWLINE> <DEDENT> current_spans_list [ pos ] = current_span <NEWLINE> overlap_checker . remove ( Interval ( current_span . begin , current_span . end ) ) <NEWLINE> overlap_checker . add ( current_span . begin , current_span . end , pos ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> overlap_checker . add ( current_span . begin , current_span . end , len ( current_spans_list ) ) <NEWLINE> current_spans_list . append ( current_span ) <NEWLINE> <DEDENT> <DEDENT> else : <NEWLINE> <INDENT> matches [ key ] = current_spans_list <NEWLINE> overlap_checker = IntervalTree ( ) <NEWLINE> <COMMENT> <NL> overlap_checker . add ( current_span . begin , current_span . end - 1 , len ( current_spans_list ) ) <NEWLINE> current_spans_list . append ( current_span ) <NEWLINE> overlap_checkers [ key ] = overlap_checker <NEWLINE> <DEDENT> <DEDENT> <DEDENT>
def isCreate ( self ) : <NEWLINE> <INDENT> data_id = self . featureServerProxy . getID ( ) <NEWLINE> return data_id is None and self . request . body != <STRING> and self . request . method == <STRING> <NEWLINE> <DEDENT>
if this_base_url not in scrape_whitelist : <NEWLINE> <INDENT> return <STRING> <NEWLINE> <DEDENT>
def get_selected_station ( self ) : <NEWLINE> <INDENT> bits = self . spi . read_pin ( self . station_bits ) <NEWLINE> result = 0 <NEWLINE> for index , value in enumerate ( bits ) : <NEWLINE> <INDENT> result += value * 2 ** index <NEWLINE> <DEDENT> <DEDENT>
proc_session = subject . experiments [ <NEWLINE>
for dataset in session . datasets : <NEWLINE>
def __init__ ( self , study_name , datasets , fields ) : <NEWLINE> <INDENT> super ( BaseArchiveSink , self ) . __init__ ( study_name , datasets , <NEWLINE> <INDENT> fields ) <NEWLINE> <COMMENT> <NL> <DEDENT> for dataset in datasets : <NEWLINE> <INDENT> assert isinstance ( dataset , DatasetSpec ) <NEWLINE> self . _add_trait ( self . inputs , dataset . name + PATH_SUFFIX , <NEWLINE> <INDENT> PATH_TRAIT ) <NEWLINE> <COMMENT> <NL> <DEDENT> <DEDENT> for field in fields : <NEWLINE> <INDENT> assert isinstance ( field , FieldSpec ) <NEWLINE> self . _add_trait ( self . inputs , field . name + FIELD_SUFFIX , <NEWLINE> <INDENT> field . dtype ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT>
if FIELDS_FNAME in dnames : <NEWLINE>
if ( rx is not None ) : <NEWLINE> <INDENT> ptid_md = pd . DataFrame ( data = rowmeta_dict , <NEWLINE> <INDENT> columns = rowmeta_dict . keys ( ) ) <NEWLINE> <DEDENT> ptid_md = ptid_md . drop_duplicates ( ) <NEWLINE> else : <NEWLINE> ptid_md = _generatePtidMetadata ( wideform_df , id_list , rx ) <NEWLINE> <DEDENT>
def callimpl ( self ) : <NEWLINE> <COMMENT> <NL> <COMMENT> <NL> <COMMENT> <NL> <COMMENT> <NL> <COMMENT> <NL> <INDENT> noiseflag = self . noiseflagreg . value <NEWLINE> if not self . toneflagreg . value : <NEWLINE> <INDENT> self . blockbuf . copybuf ( self . tone ( self . block ) ) <NEWLINE> if not noiseflag : <NEWLINE> <INDENT> self . blockbuf . orbuf ( self . noise ( self . block ) ) <NEWLINE> <DEDENT> <DEDENT> elif not noiseflag : <NEWLINE> <INDENT> self . blockbuf . copybuf ( self . noise ( self . block ) ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> self . blockbuf . fill ( 0 ) <NEWLINE> <DEDENT> <DEDENT>
command = <STRING> % ( executable or <STRING> ) <NEWLINE> <INDENT> if bare : <NEWLINE> <INDENT> command = <STRING> . join ( ( command , <STRING> ) ) <NEWLINE> <DEDENT> <DEDENT>
if nominas : <NEWLINE> <INDENT> xml . complemento . nominas = nominas <NEWLINE> xml . complemento . nomina = nominas [ 0 ] <NEWLINE> else : <NEWLINE> xml . complemento . nominas = [ ] <NEWLINE> xml . complemento . nomina = None <NEWLINE> <DEDENT>
used_file = dockerfile_content . split ( <STRING> ) [ 1 ] <NEWLINE> <INDENT> used_file = used_file . split ( <STRING> ) [ 0 ] <NEWLINE> <DEDENT>
interfaces_lag = self . specific_parser . get_interfaces_lag ( interfaces ) <NEWLINE> <INDENT> for ifname , lag in interfaces_lag . items ( ) : <NEWLINE> <INDENT> try : <NEWLINE> <INDENT> real_lag_name = ( <NEWLINE> <INDENT> self . _search_key_case_insensitive ( interfaces , lag ) <NEWLINE> <DEDENT> ) <NEWLINE> <DEDENT> except KeyError : <NEWLINE> <INDENT> logger . error ( <STRING> , lag ) <NEWLINE> continue <NEWLINE> <DEDENT> <DEDENT> <DEDENT>
class ProcessInlineFormsetView ( ProcessFormView ) : <NEWLINE> <INDENT> def post ( self , request , * args , ** kwargs ) : <NEWLINE> <INDENT> form = self . get_form ( ) <NEWLINE> inline_formset = None <NEWLINE> if form . is_valid ( ) : <NEWLINE> <INDENT> obj = form . save ( commit = False ) <NEWLINE> inline_formset = self . get_inline_formset ( ) <NEWLINE> if inline_formset . is_valid ( ) : <NEWLINE> <INDENT> obj . save ( ) <NEWLINE> inline_formset . save ( ) <NEWLINE> return self . form_valid ( form , inline_formset ) <NEWLINE> <DEDENT> <DEDENT> return self . form_invalid ( form = form , inline_formset = inline_formset ) <NEWLINE> <DEDENT> <DEDENT>
if smart : <NEWLINE> <INDENT> mmesh = deepcopy ( lmesh ) <NEWLINE> <COMMENT> <NL> if quality_assessor is None or quality_assessor == <STRING> : <NEWLINE> <INDENT> if edim == 3 : <NEWLINE> <INDENT> quality_func = lambda mesh : mesh . Volumes ( ) <NEWLINE> <DEDENT> elif edim == 2 : <NEWLINE> <INDENT> quality_func = lambda mesh : mesh . Areas ( ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> quality_func = lambda mesh : mesh . Lengths ( ) <NEWLINE> <DEDENT> <DEDENT> elif quality_assessor == <STRING> : <NEWLINE> <INDENT> quality_func = lambda mesh : mesh . AspectRatios ( ) <NEWLINE> <DEDENT> elif quality_assessor == <STRING> : <NEWLINE> <INDENT> quality_func = lambda mesh : mesh . Angles ( ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> raise ValueError ( <STRING> ) <NEWLINE> <DEDENT> <DEDENT>
self . _set_epochs ( epochs = max_epoch ) <NEWLINE> <INDENT> if not refit_on_all : <NEWLINE> <INDENT> simple_logger . info ( <STRING> % max_epoch ) <NEWLINE> self . model , self . model_checkpoint = self . model_checkpoint , None <NEWLINE> <DEDENT> else : <NEWLINE> <COMMENT> <NL> <INDENT> simple_logger . info ( <STRING> % max_epoch ) <NEWLINE> self . fit ( train_obs ) <NEWLINE> <DEDENT> <DEDENT>
if not os . path . exists ( path ) : <COMMENT> <NEWLINE> <INDENT> os . mkdir ( path ) <NEWLINE> <DEDENT>
@ classmethod <NEWLINE> <INDENT> def construct ( cls , gas , rh , t_min , t_max , t_delta , exegete : Exegete ) : <NEWLINE> <INDENT> cells = [ ExegeteRenderingTRhCell ( t , exegete . error ( gas , rh , t ) ) <NEWLINE> <INDENT> for t in range ( t_min , t_max + 1 , t_delta ) ] <NEWLINE> <DEDENT> <DEDENT> <DEDENT>
for rh in range ( 10 , 91 , 5 ) : <NEWLINE> <INDENT> for t in range ( 0 , 46 , 5 ) : <NEWLINE> <INDENT> interpretation = exegete . interpretation ( <STRING> , text , rh , t ) <NEWLINE> print ( <STRING> % ( rh , t , text , interpretation ) ) <NEWLINE> <DEDENT> <DEDENT>
return response <NEWLINE>
@ classmethod <NEWLINE> <INDENT> def persistence_location ( cls , host ) : <NEWLINE> <INDENT> return cls . aws_dir ( ) , cls . __FILENAME <NEWLINE> <DEDENT> <DEDENT>
return elapsed_minutes < self . __config . unresponsive_minutes_allowed <NEWLINE>
<COMMENT> <NL> <INDENT> if not os . path . exists ( <STRING> ) or is_older_than ( <STRING> , <STRING> ) : <NEWLINE> <INDENT> os . system ( <STRING> ) <NEWLINE> <DEDENT> with open ( <STRING> ) as file : <NEWLINE> <INDENT> long_description = file . read ( ) <NEWLINE> <DEDENT> <DEDENT>
def get_tracks ( self , paths ) : <NEWLINE> <INDENT> iterators = [ ] <NEWLINE> for path in paths : <NEWLINE> <INDENT> try : <NEWLINE> <INDENT> iterators . append ( IterableTrackPaths ( path , self . script . configuration ) ) <NEWLINE> <DEDENT> except LibraryError as e : <NEWLINE> <INDENT> self . error ( e ) <NEWLINE> <DEDENT> <DEDENT> return iterators <NEWLINE> <DEDENT>
skip = False <NEWLINE> <INDENT> for i , ( value , docstring ) in enumerate ( zip ( args , docstring_arguments ) ) : <NEWLINE> <INDENT> if skip : <NEWLINE> <INDENT> skip = False <NEWLINE> continue <NEWLINE> <DEDENT> if not <STRING> in docstring . split ( ) and <STRING> in docstring : <NEWLINE> <COMMENT> <NL> <COMMENT> <NL> <INDENT> if docstring . startswith ( <STRING> ) and <STRING> in docstring . split ( ) : <NEWLINE> <INDENT> if value . value is None : <NEWLINE> <INDENT> return_value . append ( None ) <NEWLINE> <DEDENT> elif any ( map ( value . value . startswith , [ <STRING> , <STRING> ] ) ) : <NEWLINE> <INDENT> try : <NEWLINE> <INDENT> return_value . append ( json . loads ( value . value ) ) <NEWLINE> <DEDENT> except json . decoder . JSONDecodeError : <NEWLINE> <INDENT> return_value . append ( value . value ) <NEWLINE> <DEDENT> <DEDENT> else : <NEWLINE> <INDENT> return_value . append ( value . value ) <NEWLINE> <DEDENT> <DEDENT> elif <STRING> in docstring . split ( ) : <NEWLINE> <INDENT> if ( i + 1 ) < len ( docstring_arguments ) : <NEWLINE> <INDENT> next_docstring = docstring_arguments [ i + 1 ] <NEWLINE> next_docstring = next_docstring . split ( ) <NEWLINE> if ( <NEWLINE> <INDENT> <STRING> in next_docstring <NEWLINE> and <STRING> in next_docstring <NEWLINE> and <STRING> in docstring . split ( ) <NEWLINE> <DEDENT> ) : <NEWLINE> <INDENT> return_value . append ( <NEWLINE> <INDENT> to_bytearray ( args [ i + 1 ] . value , value . value ) <NEWLINE> <DEDENT> ) <NEWLINE> skip = True <NEWLINE> continue <NEWLINE> <DEDENT> <DEDENT> return_value . append ( value . value ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> return_value . append ( value ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT> <DEDENT>
<COMMENT> <NL> <INDENT> newxlim = ( ax_left . get_xlim ( ) [ 0 ] , xposPlusViolin + 0.25 ) <NEWLINE> ax_left . set_xlim ( newxlim ) <NEWLINE> <DEDENT>
for i in range ( 0 , len ( bslist ) ) : <NEWLINE> <INDENT> bsi = bslist [ i ] <NEWLINE> <COMMENT> <NL> array = bsi [ <STRING> ] <NEWLINE> ylims . append ( array ) <NEWLINE> <DEDENT>
self . rotate_songs ( ) <NEWLINE> <INDENT> self . current_song = { } <NEWLINE> self . current_song_json = <STRING> <NEWLINE> self . current_song_json_updated = str ( time ( ) ) <NEWLINE> else : <NEWLINE> song = r . json ( ) <NEWLINE> item = song [ <STRING> ] <NEWLINE> <COMMENT> <NL> if <STRING> in self . current_song and item [ <STRING> ] == self . current_song [ <STRING> ] : <NEWLINE> <INDENT> self . current_song_checks += 1 <NEWLINE> <COMMENT> <NL> if song [ <STRING> ] < self . current_song [ <STRING> ] or song [ <STRING> ] - 10000 > self . current_song [ <STRING> ] : <NEWLINE> <INDENT> self . current_song_json_updated = str ( time ( ) ) <NEWLINE> LISTEN_ALONG_API . set_current_playing_song ( song_uri = item [ <STRING> ] , position_ms = song [ <STRING> ] ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT>
users_json += <STRING> <NEWLINE> <INDENT> return PlainTextResponse ( content = users_json , media_type = <STRING> ) <NEWLINE> <DEDENT>
@ staticmethod <NEWLINE> <INDENT> def _set_song ( user : ListenAlongUser , song_json : str ) -> None : <NEWLINE> <INDENT> if user . tokens : <NEWLINE> <INDENT> status = SpotifyWebAPI . set_current_playing_song ( user . tokens . access , song_json ) <NEWLINE> if user . public . status != status : <NEWLINE> <INDENT> user . public . status = status <NEWLINE> user . public_json = json . dumps ( asdict ( user . public ) ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT> <DEDENT>
class post_install ( install ) : <NEWLINE> <INDENT> def run ( self ) : <NEWLINE> <INDENT> install . run ( self ) <NEWLINE> print ( <STRING> ) <NEWLINE> <COMMENT> <NL> if <STRING> not in open ( <STRING> ) . read ( ) : <NEWLINE> <INDENT> os . system ( <STRING> ) <NEWLINE> os . system ( <STRING> ) <NEWLINE> <COMMENT> <NL> <DEDENT> os . system ( <STRING> ) <NEWLINE> os . system ( <STRING> ) <NEWLINE> os . system ( <STRING> ) <NEWLINE> <COMMENT> <NL> os . system ( <STRING> ) <NEWLINE> os . system ( <STRING> ) <NEWLINE> os . system ( <STRING> ) <NEWLINE> <DEDENT> <DEDENT>
def echo_copyright ( ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> cur_year = str ( datetime . now ( ) . year ) <NEWLINE> year_range = <STRING> <NEWLINE> if cur_year != year_range : <NEWLINE> <INDENT> year_range = <STRING> . format ( cur_year ) <NEWLINE> <DEDENT> gpl3_notice_2018 = [ <NEWLINE> <INDENT> <STRING> . format ( <NEWLINE> <INDENT> app_name = __BigName__ , <NEWLINE> version = dob_version , <NEWLINE> <DEDENT> ) , <NEWLINE> <STRING> , <NEWLINE> <STRING> . format ( <NEWLINE> <INDENT> years = year_range , <NEWLINE> author = __author__ , <NEWLINE> email = __author_email__ , <NEWLINE> <DEDENT> ) , <NEWLINE> <COMMENT> <NL> <COMMENT> <NL> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> _ ( <STRING> ) , <NEWLINE> _ ( <STRING> ) , <NEWLINE> _ ( <STRING> ) , <NEWLINE> _ ( <STRING> ) . format ( __arg0name__ ) , <NEWLINE> <DEDENT> ] <NEWLINE> notice = gpl3_notice_2018 <NEWLINE> for line in notice : <NEWLINE> <INDENT> click_echo ( line ) <NEWLINE> <DEDENT> <DEDENT>
if len ( line . split ( ) ) > 1 : <NEWLINE> <INDENT> if <STRING> in line . split ( ) [ 0 ] : <NEWLINE> <INDENT> flag = 1 <NEWLINE> <DEDENT> <DEDENT>
<COMMENT> <NL> <INDENT> def parse ( self , row ) : <NEWLINE> <INDENT> output = [ ] <NEWLINE> for i , value in enumerate ( row ) : <NEWLINE> <INDENT> parsed = getattr ( self , <STRING> . format ( i ) , noop ) ( value ) <NEWLINE> if isinstance ( parsed , ( list , tuple ) ) : <NEWLINE> <INDENT> output . extend ( parsed ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> output . append ( parsed ) <NEWLINE> <DEDENT> <DEDENT> return output <NEWLINE> <DEDENT> <DEDENT>
def safe_apply ( <NEWLINE> <INDENT> self , apply_on : str , func : Callable , apply_to : str = None <NEWLINE> ) -> pd . Series : <NEWLINE> try : <NEWLINE> <INDENT> apply_to = apply_to or apply_on <NEWLINE> self . df [ apply_to ] = self . df [ apply_on ] . apply ( func ) <NEWLINE> <DEDENT> except KeyError as ke : <NEWLINE> <INDENT> logger . debug ( <NEWLINE> <INDENT> MSG_PARSER_CHECK . format ( op_name = self . operator . name , col_name = apply_on ) <NEWLINE> <DEDENT> ) <NEWLINE> <DEDENT> except Exception as e : <NEWLINE> <INDENT> logger . debug ( <NEWLINE> <INDENT> MSG_PARSER_ERROR . format ( op_name = self . operator . name , e = e ) , exc_info = e <NEWLINE> <DEDENT> ) <NEWLINE> <DEDENT> return self <NEWLINE> <DEDENT>
for PATH in PATHS : <NEWLINE> <INDENT> if not os . path . isfile ( PATH ) : <NEWLINE> <INDENT> print ( <STRING> ) <NEWLINE> continue <NEWLINE> <DEDENT> <DEDENT>
GPIO . setmode ( pin_mode ) <NEWLINE> <INDENT> if pin_rst is not None : <NEWLINE> <INDENT> GPIO . setup ( pin_rst , GPIO . OUT ) <NEWLINE> GPIO . output ( pin_rst , 1 ) <NEWLINE> <DEDENT> GPIO . setup ( pin_irq , GPIO . IN , pull_up_down = GPIO . PUD_UP ) <NEWLINE> GPIO . add_event_detect ( pin_irq , GPIO . FALLING , <NEWLINE> <INDENT> callback = self . irq_callback ) <NEWLINE> <DEDENT> if pin_ce != 0 : <NEWLINE> <INDENT> GPIO . setup ( pin_ce , GPIO . OUT ) <NEWLINE> GPIO . output ( pin_ce , 1 ) <NEWLINE> <DEDENT> self . init ( ) <NEWLINE> <DEDENT>
if ( with_forecast ) : <NEWLINE> <INDENT> forecast_url = forecast_urls [ provider ] <NEWLINE> r = requests . get ( <NEWLINE> <INDENT> forecast_url . format ( loc_parsed , units , api_key ) ) <NEWLINE> <DEDENT> f = json . loads ( r . text ) <NEWLINE> if ( c [ <STRING> ] [ <STRING> ] [ <STRING> ] != 1 ) : <NEWLINE> <INDENT> return { <STRING> : <STRING> } <NEWLINE> else : <NEWLINE> <DEDENT> f = None <NEWLINE> except requests . exceptions . ConnectionError as e : <NEWLINE> return { <STRING> : <STRING> } <NEWLINE> return { <STRING> : c , <STRING> : f } <NEWLINE> else : <NEWLINE> return { <STRING> : <STRING> } <NEWLINE> <DEDENT>
logger2 . info ( step . name ) <NEWLINE> <INDENT> args = step . args . replace ( <NEWLINE> <INDENT> <STRING> , tmpdir + patientname ) . replace ( <STRING> , ref ) . replace ( <STRING> , patientname ) <NEWLINE> <DEDENT> cmdver = step . version . replace ( <STRING> , <STRING> ) <NEWLINE> javacmds = [ <STRING> , <STRING> , <STRING> , <STRING> ] <NEWLINE> if any ( javacmd in step . command for javacmd in javacmds ) : <NEWLINE> <INDENT> cmd = <STRING> % tmpdir + cfg . binPath + step . command + <STRING> + step . command + <STRING> + cmdver + <STRING> + step . subcommand <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> cmd = cfg . binPath + step . command + <STRING> + step . command + <STRING> + cmdver + <STRING> + step . subcommand <NEWLINE> <DEDENT> if <STRING> in cmd : <NEWLINE> <INDENT> cmdstr = cmd + <STRING> + args + <STRING> + <STRING> + inputfile + <STRING> + outputfile <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> cmdstr = cmd + <STRING> + args + <STRING> + <STRING> + inputfile + <STRING> + outputfile <NEWLINE> print ( cmd ) <NEWLINE> <DEDENT> cmd = shlex . split ( cmdstr ) <NEWLINE> <DEDENT>
return dict_out <NEWLINE>
<COMMENT> <NL> <INDENT> if with_sem : <NEWLINE> <INDENT> df_sem = ( df [ column ] <NEWLINE> <INDENT> . groupby ( <STRING> ) <NEWLINE> . mean ( ) <NEWLINE> . resample ( groupby ) <NEWLINE> . apply ( sem ) <NEWLINE> if groupby != <STRING> and groupby != <STRING> else <NEWLINE> df [ column ] . groupby ( <STRING> ) . apply ( sem ) ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT>
def _request ( self , method , endpoint , params = None , ** kwargs ) : <NEWLINE> <INDENT> _params = { <STRING> : self . access_token } <NEWLINE> if params : <NEWLINE> <INDENT> _params . update ( params ) <NEWLINE> <DEDENT> response = requests . request ( method , self . BASE_URL + endpoint , params = _params , ** kwargs ) <NEWLINE> return self . _parse ( response ) <NEWLINE> <DEDENT>
linelist = [ element for element in line if element not in illegal ] <NEWLINE> <INDENT> line = _np . array ( linelist ) <NEWLINE> return line <NEWLINE> <DEDENT>
def _splice_volumes ( self , vollist ) : <NEWLINE> <INDENT> namespace = self . get_user_namespace ( ) <NEWLINE> already_vols = [ ] <NEWLINE> if self . volumes : <NEWLINE> <INDENT> already_vols = [ x [ <STRING> ] for x in self . volumes ] <NEWLINE> self . log . debug ( <STRING> % already_vols ) <NEWLINE> <DEDENT> for vol in vollist : <NEWLINE> <INDENT> volname = self . _get_volume_name_for_mountpoint ( vol [ <STRING> ] ) <NEWLINE> shortname = vol [ <STRING> ] [ 1 : ] . replace ( <STRING> , <STRING> ) <NEWLINE> if shortname in already_vols : <NEWLINE> <INDENT> self . log . info ( <NEWLINE> <INDENT> <STRING> . format ( volname ) ) <NEWLINE> <DEDENT> continue <NEWLINE> <DEDENT> k8s_vol = vol [ <STRING> ] <NEWLINE> if k8s_vol : <NEWLINE> <COMMENT> <NL> <INDENT> kvol = self . _get_nfs_volume ( k8s_vol ) <NEWLINE> ns_vol = self . _replicate_nfs_pv_with_suffix ( <NEWLINE> <INDENT> kvol , namespace ) <NEWLINE> <DEDENT> self . _create_pvc_for_pv ( ns_vol ) <NEWLINE> <DEDENT> mode = <STRING> <NEWLINE> vmro = True <NEWLINE> if vol [ <STRING> ] == <STRING> : <NEWLINE> <INDENT> mode = <STRING> <NEWLINE> vmro = False <NEWLINE> <DEDENT> vvol = { <NEWLINE> <INDENT> <STRING> : shortname , <NEWLINE> <DEDENT> } <NEWLINE> if k8s_vol : <NEWLINE> <INDENT> pvcvs = V1PersistentVolumeClaimVolumeSource ( <NEWLINE> <INDENT> claim_name = ns_vol . metadata . name , <NEWLINE> read_only = vmro <NEWLINE> <DEDENT> ) <NEWLINE> vvol [ <STRING> ] = pvcvs <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> vvol [ <STRING> ] = { <NEWLINE> <INDENT> <STRING> : vol [ <STRING> ] , <NEWLINE> <STRING> : vol [ <STRING> ] , <NEWLINE> <STRING> : [ mode ] <NEWLINE> <DEDENT> } <NEWLINE> <DEDENT> <DEDENT> <DEDENT>
class Task ( TaskModel ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> def __init__ ( self , job , frame , parent_task = None , state = None , <NEWLINE> <INDENT> priority = None , attempts = None , agent = None ) : <NEWLINE> <COMMENT> <NL> if modelfor ( job , TABLE_JOB ) : <NEWLINE> jobid = job . jobid <NEWLINE> if jobid is None : <NEWLINE> raise ValueError ( <STRING> ) <NEWLINE> elif isinstance ( job , int ) : <NEWLINE> jobid = job <NEWLINE> else : <NEWLINE> raise ValueError ( <STRING> ) <NEWLINE> <DEDENT> <DEDENT>
if attempts is not None : <NEWLINE> <INDENT> self . attempts = attempts <NEWLINE> <DEDENT>
m = re . match ( self . inputs [ f ] , os . path . basename ( filename ) ) <NEWLINE> <INDENT> if m is not None : <NEWLINE> <COMMENT> <NL> <INDENT> if os . path . exists ( filename ) : <NEWLINE> <INDENT> self . local_in [ f ] = filename <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> self . remote_in [ f ] = filename <NEWLINE> <DEDENT> <DEDENT> <DEDENT>
for name in self . const : <NEWLINE> <INDENT> args = self . const [ name ] <NEWLINE> names = [ codegen . getName ( ) for _ in args ] <NEWLINE> codegen . inFunction ( ) <NEWLINE> if len ( names ) > 0 : <NEWLINE> <INDENT> codegen . append ( <STRING> + self . package + <STRING> + name + <STRING> ) <NEWLINE> codegen . append ( <STRING> . join ( names ) ) <NEWLINE> codegen . append ( <STRING> + str ( count ) + <STRING> + <STRING> . join ( names ) + <STRING> ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> codegen . append ( <STRING> + self . package + <STRING> + name + <STRING> + str ( count ) + <STRING> + <STRING> . join ( names ) + <STRING> ) <NEWLINE> <DEDENT> <DEDENT>
filters_list . append ( query . c . key == tag . lower ( ) ) <NEWLINE>
values = list ( pushes . value ) <NEWLINE> <INDENT> title = <STRING> . join ( <NEWLINE> <INDENT> map ( <NEWLINE> <INDENT> str , <NEWLINE> [ <NEWLINE> <INDENT> sig . framework , <NEWLINE> sig . suite , <NEWLINE> sig . test , <NEWLINE> sig . platform , <NEWLINE> sig . repository , <NEWLINE> about_deviant . overall_dev_status , <NEWLINE> <DEDENT> ] , <NEWLINE> <DEDENT> ) <NEWLINE> <DEDENT> ) <NEWLINE> <COMMENT> <NL> url = <STRING> + value2url_param ( { <NEWLINE> <INDENT> <STRING> : 1 , <NEWLINE> <STRING> : [ sig . repository , sig . id , 1 , coalesce ( sig . framework_id , sig . framework ) ] , <NEWLINE> <STRING> : 31536000 , <NEWLINE> <DEDENT> } ) <NEWLINE> <DEDENT>
datasetPath = os . path . join ( self . Path , self . DatasetName , self . Name ) <NEWLINE> <COMMENT> <NL> <INDENT> if not arcpy . Exists ( datasetPath ) : <NEWLINE> <INDENT> raise Exception ( datasetPath + <STRING> ) <NEWLINE> <COMMENT> <NL> <DEDENT> trys = 0 <NEWLINE> while arcpy . TestSchemaLock ( datasetPath ) or trys < 6 : <NEWLINE> <INDENT> time . sleep ( 10 ) <NEWLINE> trys += 1 <NEWLINE> <COMMENT> <NL> <DEDENT> <DEDENT>
def is_prefixed ( value , prefix ) : <NEWLINE> <INDENT> return value . startswith ( <NEWLINE> <INDENT> force_bytes ( prefix ) if is_bytes ( value ) else force_text ( prefix ) <NEWLINE> <DEDENT> ) <NEWLINE> <DEDENT>
if is_array ( block . get ( <STRING> ) ) : <NEWLINE> <INDENT> for item in block [ <STRING> ] : <NEWLINE> <INDENT> if not is_string ( item ) : <NEWLINE> <INDENT> item = outputTransactionFormatter ( item ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT>
def login ( request ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> manipulator = AuthenticationForm ( request ) <NEWLINE> redirect_to = request . REQUEST . get ( REDIRECT_FIELD_NAME , <STRING> ) <NEWLINE> if request . POST : <NEWLINE> <INDENT> errors = manipulator . get_validation_errors ( request . POST ) <NEWLINE> if not errors : <NEWLINE> <COMMENT> <NL> <INDENT> if not redirect_to or <STRING> in redirect_to or <STRING> in redirect_to : <NEWLINE> <INDENT> redirect_to = <STRING> <NEWLINE> <DEDENT> request . session [ users . SESSION_KEY ] = manipulator . get_user_id ( ) <NEWLINE> return HttpResponseRedirect ( redirect_to ) <NEWLINE> <DEDENT> <DEDENT> else : <NEWLINE> <INDENT> errors = { } <NEWLINE> <DEDENT> response = HttpResponse ( ) <NEWLINE> request . session . set_test_cookie ( ) <NEWLINE> t = template_loader . get_template ( <STRING> ) <NEWLINE> c = Context ( request , { <NEWLINE> <INDENT> <STRING> : formfields . FormWrapper ( manipulator , request . POST , errors ) , <NEWLINE> REDIRECT_FIELD_NAME : redirect_to , <NEWLINE> <STRING> : sites . get_current ( ) . name , <NEWLINE> <DEDENT> } ) <NEWLINE> response . write ( t . render ( c ) ) <NEWLINE> return response <NEWLINE> <DEDENT>
def W ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> <COMMENT> <NL> week_number = None <NEWLINE> jan1_weekday = self . data . replace ( month = 1 , day = 1 ) . weekday ( ) + 1 <NEWLINE> weekday = self . data . weekday ( ) + 1 <NEWLINE> day_of_year = self . z ( ) <NEWLINE> if day_of_year <= ( 8 - jan1_weekday ) and jan1_weekday > 4 : <NEWLINE> <INDENT> if jan1_weekday == 5 or ( jan1_weekday == 6 and isleap ( self . data . year - 1 ) ) : <NEWLINE> <INDENT> week_number = 53 <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> week_number = 52 <NEWLINE> <DEDENT> <DEDENT> else : <NEWLINE> <INDENT> if isleap ( self . data . year ) : <NEWLINE> <INDENT> i = 366 <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> i = 365 <NEWLINE> <DEDENT> if ( i - day_of_year ) < ( 4 - weekday ) : <NEWLINE> <INDENT> week_number = 1 <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> j = day_of_year + ( 7 - weekday ) + ( jan1_weekday - 1 ) <NEWLINE> week_number = j // 7 <NEWLINE> if jan1_weekday > 4 : <NEWLINE> <INDENT> week_number -= 1 <NEWLINE> <DEDENT> <DEDENT> <DEDENT> return week_number <NEWLINE> <DEDENT>
def test_cache_page_old_style ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> def my_view ( request ) : <NEWLINE> <INDENT> return <STRING> <NEWLINE> <DEDENT> my_view_cached = cache_page ( my_view , 123 ) <NEWLINE> self . assertEqual ( my_view_cached ( HttpRequest ( ) ) , <STRING> ) <NEWLINE> <DEDENT>
def _get_key ( self , full_path ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> full_path_checksum = hashlib . sha1 ( full_path ) . digest ( ) <NEWLINE> return full_path_checksum <NEWLINE> <DEDENT>
for m_instance , name in SWIFT_STATS . iteritems ( ) : <NEWLINE> <INDENT> if m_instance in stats : <NEWLINE> <INDENT> metric = collectd . Values ( ) <NEWLINE> metric . plugin = <STRING> <NEWLINE> metric . interval = INTERVAL <NEWLINE> metric . type = <STRING> <NEWLINE> metric . type_instance = name <NEWLINE> metric . values = [ stats [ m_instance ] ] <NEWLINE> metric . dispatch ( ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> collectd . error ( <STRING> . format ( m_instance ) ) <NEWLINE> <DEDENT> <DEDENT>
<COMMENT> <NL> <INDENT> samtools_index_command = ( <NEWLINE> <INDENT> settings [ <STRING> ] , <STRING> , <NEWLINE> strand_split_bam <NEWLINE> ) <NEWLINE> <DEDENT> <DEDENT>
featureCounts_command = ( <NEWLINE> <INDENT> settings [ <STRING> ] , <NEWLINE> <COMMENT> <NL> <COMMENT> <NL> <STRING> , <STRING> , <STRING> , <STRING> , <NEWLINE> <STRING> , str ( settings [ <STRING> ] ) , <NEWLINE> <STRING> , str ( settings [ <STRING> ] ) , <NEWLINE> <COMMENT> <NL> <COMMENT> <NL> <STRING> , input_SAF , <NEWLINE> <STRING> , output_SAF , <NEWLINE> input_bam <NEWLINE> <COMMENT> <NL> ) <NEWLINE> with open ( input_SAF ) as f_out : <NEWLINE> for line in f_out : <NEWLINE> print ( line ) <NEWLINE> <DEDENT>
elif pos == consensus_seq [ j ] : <NEWLINE>
pshow = sp . add_parser ( <STRING> , help = <STRING> ) <NEWLINE> <INDENT> m = pshow . add_mutually_exclusive_group ( ) <NEWLINE> m . add_argument ( <STRING> , <STRING> , <NEWLINE> <INDENT> help = <STRING> ) <NEWLINE> <DEDENT> m . add_argument ( <STRING> , <STRING> , type = PathType ( exists = True ) , default = os . path . expanduser ( <STRING> ) , <NEWLINE> <INDENT> help = <STRING> ) <NEWLINE> <DEDENT> pshow . add_argument ( <STRING> , <STRING> , action = <STRING> ) <NEWLINE> pshow . set_defaults ( func = show ) <NEWLINE> <DEDENT>
if callbacks : <NEWLINE> <INDENT> callbacks . remove ( callback ) <NEWLINE> if len ( callbacks ) == 0 : <NEWLINE> <INDENT> del self . _subscribers [ ( channel , pattern ) ] <NEWLINE> <DEDENT> <DEDENT>
@ property <NEWLINE> <INDENT> def ip_addrs ( self ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> self . _logger . info ( <STRING> ) <NEWLINE> out = self . cmd ( <STRING> . join ( [ <NEWLINE> <INDENT> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , <NEWLINE> <STRING> , ] ) ) <NEWLINE> <DEDENT> ips = out . split ( <STRING> ) <NEWLINE> if out and not out . startswith ( <STRING> ) : <NEWLINE> <INDENT> self . _logger . debug ( <STRING> + str ( ips ) ) <NEWLINE> return out . split ( <STRING> ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> raise NoIPException ( <STRING> . format ( <NEWLINE> <INDENT> ips ) ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT> <DEDENT>
def set_page_and_response_if_appropriate ( self ) : <NEWLINE> <INDENT> if not isinstance ( request . routing_exception , NotFound ) and current_page : <NEWLINE> <INDENT> return self . page_view ( ) <NEWLINE> <DEDENT> <DEDENT>
def _get_missing_params_from_robot_variables ( self , param_dict ) : <NEWLINE> <INDENT> for testlink_param , robot_variable in robot_report_params . items ( ) : <NEWLINE> <INDENT> setdefault_if_not_none ( param_dict , testlink_param , self . _get_param_from_robot ( robot_variable ) ) <NEWLINE> <DEDENT> <DEDENT>
def maybe_swap_spatial_dims ( ds , namex = <STRING> , namey = <STRING> ) : <NEWLINE> <INDENT> swaps = { } <NEWLINE> lx , rx = ds . indexes [ namex ] [ [ 0 , - 1 ] ] <NEWLINE> uy , ly = ds . indexes [ namey ] [ [ 0 , - 1 ] ] <NEWLINE> <DEDENT>
@ staticmethod <NEWLINE> <INDENT> def write_output ( content , basename ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> <COMMENT> <NL> compressor = JsCompressor ( ) <NEWLINE> filtered = compressor . filter ( content , method = <STRING> , kind = <STRING> ) <NEWLINE> output = compressor . filter_output ( filtered ) <NEWLINE> path = compressor . get_filepath ( output , basename = basename ) <NEWLINE> <COMMENT> <NL> compressor . storage . save ( path , ContentFile ( output . encode ( compressor . charset ) ) ) <NEWLINE> return mark_safe ( compressor . storage . url ( path ) ) <NEWLINE> <DEDENT> <DEDENT>
with ExitStack ( ) as stack : <NEWLINE> <INDENT> files = [ stack . enter_context ( open ( fname , <STRING> ) ) for fname in self . file_list ] <NEWLINE> ii = 0 <NEWLINE> while True : <NEWLINE> <INDENT> try : <NEWLINE> <INDENT> timestamps , channel_data = self . _reader . read_block ( file = files [ ii ] , block_size = block_size ) <NEWLINE> if 0 < len ( timestamps ) < block_size : <NEWLINE> <COMMENT> <NL> <INDENT> ii += 1 <NEWLINE> timestamps_ , channel_data_ = self . _reader . read_block ( file = files [ ii ] , block_size = block_size - len ( timestamps ) ) <NEWLINE> if not isinstance ( timestamps , list ) : <NEWLINE> <INDENT> raise TypeError ( <STRING> ) <NEWLINE> <DEDENT> timestamps = timestamps + timestamps_ <COMMENT> <NEWLINE> channel_data = np . hstack ( ( channel_data , channel_data_ ) ) <NEWLINE> <DEDENT> if timestamps : <NEWLINE> <INDENT> yield timestamps , channel_data <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> ii += 1 <NEWLINE> <DEDENT> <DEDENT> except IndexError : <NEWLINE> <INDENT> return <NEWLINE> <DEDENT> <DEDENT> <DEDENT>
super ( ) . __setitem__ ( key , ( len ( value ) , value ) ) <NEWLINE>
argString = str ( self . __convertDictItemsToStr ( args ) ) <NEWLINE> <INDENT> argStringb64 = b64encode ( bytes ( argString , <STRING> ) ) . decode ( <STRING> ) <NEWLINE> signature = hmac . new ( <NEWLINE> <INDENT> bytes ( self . __private , <STRING> ) , <NEWLINE> bytes ( argStringb64 , <STRING> ) , <NEWLINE> sha384 ) <NEWLINE> <DEDENT> headerPayload = { <NEWLINE> <INDENT> <STRING> : self . __public , <NEWLINE> <STRING> : argStringb64 , <NEWLINE> <STRING> : signature . hexdigest ( ) <NEWLINE> <DEDENT> } <NEWLINE> <DEDENT>
def _notify_thread_subscribers ( self , thread , notification_text , comment = None ) : <NEWLINE> <INDENT> forum = thread . getForum ( ) <NEWLINE> di = self . _thread_info ( thread ) <NEWLINE> if comment is not None : <NEWLINE> <INDENT> di [ <STRING> ] = comment . absolute_url ( ) <NEWLINE> di [ <STRING> ] = safe_unicode ( comment . getText ( ) ) <NEWLINE> <DEDENT> subscriptions = getUtility ( ISubscriptions ) <NEWLINE> subscribers = set ( subscriptions . subscribers_for ( thread ) ) | set ( subscriptions . subscribers_for ( forum ) ) <NEWLINE> mdtool = getToolByName ( thread , <STRING> ) <NEWLINE> keys = mdtool . propertyIds ( ) <NEWLINE> for mdata in subscribers : <NEWLINE> <INDENT> if ( comment is not None ) and ( mdata . getId ( ) == comment . Creator ( ) ) : <NEWLINE> <INDENT> continue <NEWLINE> <DEDENT> di . update ( [ ( k , str ( mdata . getProperty ( k ) ) . decode ( self . _encoding ( ) ) ) for k in keys ] ) <NEWLINE> di [ <STRING> ] = self . _salutation_for_member ( di ) <NEWLINE> self . _notify ( di , notification_text % di ) <NEWLINE> log . info ( <STRING> . format ( subscriber = di . get ( <STRING> ) ) ) <NEWLINE> <DEDENT> <DEDENT>
def validate_request ( schema ) : <NEWLINE> <INDENT> def decorator ( view_func ) : <NEWLINE> <INDENT> @ wraps ( view_func ) <NEWLINE> def _wrapped_view ( view , * args , ** kwargs ) : <NEWLINE> <INDENT> request = view . request <NEWLINE> context = DrfUtils . get_request_parameters ( request ) <NEWLINE> context = SchemaValidator . validate ( context , schema ) <NEWLINE> kwargs [ <STRING> ] = context <NEWLINE> return view_func ( view , * args , ** kwargs ) <NEWLINE> <DEDENT> <DEDENT> <DEDENT>
def __init__ ( self , code , db = os . getenv ( <STRING> ) + <STRING> , <NEWLINE> <INDENT> local = False ) : <NEWLINE> if code in inmet . sites . index . values : <NEWLINE> self . code = code <NEWLINE> self . cod_OMM = inmet . sites . loc [ code ] . cod_OMM <NEWLINE> self . inicio_operacao = inmet . sites . loc [ code ] . inicio_operacao <NEWLINE> self . lat = inmet . sites . loc [ code ] . lat <NEWLINE> self . lon = inmet . sites . loc [ code ] . lon <NEWLINE> self . alt = inmet . sites . loc [ code ] . alt <NEWLINE> self . dados = get_from_ldb ( code , local , db ) <NEWLINE> <DEDENT>
def trajectories ( ret , trajs , ** kw ) : <NEWLINE> <INDENT> getkw = mk_getkw ( kw , trajdefaults ) ; <NEWLINE> x , y = getkw ( <STRING> ) ; <NEWLINE> if not test ( kw , <STRING> ) : <NEWLINE> <INDENT> xlim , ylim = ret [ <STRING> ] . get_xlim ( ) , ret [ <STRING> ] . get_ylim ( ) ; <NEWLINE> <DEDENT> if not test ( kw , <STRING> ) : <NEWLINE> <INDENT> plotit = lambda itr : ret [ <STRING> ] . plot ( <NEWLINE> <INDENT> itr [ x ] , itr [ y ] , <NEWLINE> lw = 0.1 , <NEWLINE> c = getkw ( <STRING> ) , alpha = getkw ( <STRING> ) ) ; <NEWLINE> <DEDENT> pass ; <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> cf = getkw ( <STRING> ) ; <NEWLINE> if type ( cf ) == str : <NEWLINE> <INDENT> cf = lambda itr : itr [ cf ] ; <NEWLINE> <DEDENT> plotit = lambda itr : ret [ <STRING> ] . scatter ( <NEWLINE> <INDENT> itr [ x ] , itr [ y ] , <NEWLINE> c = cf ( itr ) , <NEWLINE> lw = getkw ( <STRING> ) , <NEWLINE> s = getkw ( <STRING> ) , <NEWLINE> cmap = getkw ( <STRING> ) ) ; <NEWLINE> <DEDENT> <DEDENT> for itr in np . rollaxis ( trajs , 1 ) : <NEWLINE> <INDENT> plotit ( itr ) ; <NEWLINE> <DEDENT> if not test ( kw , <STRING> ) : <NEWLINE> <INDENT> ret [ <STRING> ] . set_xlim ( xlim ) ; <NEWLINE> ret [ <STRING> ] . set_ylim ( ylim ) ; <NEWLINE> <DEDENT> <DEDENT>
class xnd ( _xnd ) : <NEWLINE> <INDENT> def __new__ ( cls , value = None , type = None , levels = None ) : <NEWLINE> <INDENT> if type is None : <NEWLINE> <INDENT> if levels is not None : <NEWLINE> <INDENT> args = <STRING> . join ( <STRING> % l if l is not None else <STRING> for l in levels ) <NEWLINE> t = <STRING> % ( len ( value ) , args ) <NEWLINE> type = ndt ( t ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> type = typeof ( value ) <NEWLINE> <DEDENT> <DEDENT> else : <NEWLINE> <INDENT> if levels is not None : <NEWLINE> <INDENT> raise TypeError ( <NEWLINE> <INDENT> <STRING> ) <NEWLINE> <DEDENT> <DEDENT> elif isinstance ( type , str ) : <NEWLINE> <INDENT> type = ndt ( type ) <NEWLINE> <DEDENT> <DEDENT> return _xnd ( type , value ) <NEWLINE> <DEDENT> <DEDENT>
if pack_transfer . is_dest_location_to_confirm ( move , scanned_location ) : <NEWLINE> <INDENT> if confirmation : <NEWLINE> <COMMENT> <NL> <COMMENT> <NL> <INDENT> move . location_dest_id = scanned_location . id <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> return self . _response_for_location_need_confirm ( ) <NEWLINE> <DEDENT> <DEDENT>
def is_dest_location_to_confirm ( self , move , scanned_location ) : <NEWLINE> <INDENT> <STRING> <NEWLINE> move_dest_location = move . move_line_ids [ 0 ] . location_dest_id <NEWLINE> zone_locations = self . env [ <STRING> ] . search ( <NEWLINE> <INDENT> [ ( <STRING> , <STRING> , move_dest_location . id ) ] <NEWLINE> <DEDENT> ) <NEWLINE> return scanned_location not in zone_locations <NEWLINE> <DEDENT>
if pack_transfer . is_dest_location_to_confirm ( move , scanned_location ) : <NEWLINE> <INDENT> if confirmation : <NEWLINE> <COMMENT> <NL> <COMMENT> <NL> <INDENT> move . location_dest_id = scanned_location . id <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> return self . _response_for_location_need_confirm ( ) <NEWLINE> <DEDENT> <DEDENT>
class SelectDestPackageMixin : <NEWLINE> <INDENT> def _assert_response_select_dest_package ( <NEWLINE> <INDENT> self , response , picking , selected_lines , packages , message = None <NEWLINE> <DEDENT> ) : <NEWLINE> <INDENT> self . assert_response ( <NEWLINE> <INDENT> response , <NEWLINE> next_state = <STRING> , <NEWLINE> data = { <NEWLINE> <INDENT> <STRING> : { <NEWLINE> <INDENT> <STRING> : picking . id , <NEWLINE> <STRING> : picking . name , <NEWLINE> <STRING> : <STRING> , <NEWLINE> <STRING> : <STRING> , <NEWLINE> <STRING> : len ( picking . move_line_ids ) , <NEWLINE> <STRING> : { <STRING> : self . customer . id , <STRING> : self . customer . name } , <NEWLINE> <DEDENT> } , <NEWLINE> <STRING> : [ <NEWLINE> <INDENT> self . _package_data ( package , picking ) for package in packages <NEWLINE> <DEDENT> ] , <NEWLINE> <STRING> : [ <NEWLINE> <INDENT> self . _move_line_data ( ml ) for ml in selected_lines . sorted ( ) <NEWLINE> <DEDENT> ] , <NEWLINE> <DEDENT> } , <NEWLINE> message = message , <NEWLINE> <DEDENT> ) <NEWLINE> <DEDENT> <DEDENT>
new_moves = self . browse ( chain . from_iterable ( new_move_per_location . values ( ) ) ) <NEWLINE> <INDENT> return self | new_moves <NEWLINE> <DEDENT>
for attr_name in loss_like_attr_names : <NEWLINE> <INDENT> tag_name = <STRING> . format ( <NEWLINE> <INDENT> base_name = self . base_name , attr_name = attr_name <NEWLINE> <DEDENT> ) <NEWLINE> attr = getattr ( dc_value , attr_name ) <NEWLINE> if isinstance ( attr , Tensor ) : <NEWLINE> <INDENT> value = attr . item ( ) <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> value = attr <NEWLINE> <DEDENT> self . writer . add_scalar ( tag_name , scalar_value = value , global_step = step ) <NEWLINE> self . values [ attr_name ] . append ( value ) <NEWLINE> <DEDENT>
for config_data_point in self . _config [ <STRING> ] : <NEWLINE> <INDENT> dp = DataPoint ( config_data_point , _config_methods , self . _mqtt_client , self . _logger , <NEWLINE> <INDENT> self . _no_data_behavior ) <NEWLINE> <DEDENT> self . _purges . append ( dp . purge_old_values ) <NEWLINE> for method in dp . methods : <NEWLINE> <INDENT> process = method . process <NEWLINE> cost = method . execution_points_estimation ( ) <NEWLINE> self . _logger . info ( <STRING> . <NEWLINE> <INDENT> format ( process . __name__ , cost ) ) <NEWLINE> <DEDENT> self . _processes . append ( ( process , cost ) ) <NEWLINE> <DEDENT> self . _data_points . append ( dp ) <NEWLINE> <DEDENT>
for domain , data in domains . items ( ) : <NEWLINE> <INDENT> service_name = data . get ( <STRING> ) <NEWLINE> if not service_name : <NEWLINE> <INDENT> continue <NEWLINE> <DEDENT> strowger . set_http_route ( domain , service_name ) <NEWLINE> <DEDENT>
def connectMongo ( ) : <NEWLINE> <INDENT> client = pymongo . MongoClient ( aa . mongouri ) <NEWLINE> shouts = client . aaserver . shouts . find ( { } ) <NEWLINE> shouts_ = [ shout for shout in shouts ] <NEWLINE> return shouts_ <NEWLINE> <DEDENT>
def output ( self , out_prefix ) : <NEWLINE> <INDENT> if ( not out_prefix ) : <NEWLINE> <INDENT> tax_filepath = default_taxonomy_file <NEWLINE> tag_filepath = default_tagging_file <NEWLINE> exp_filepath = default_expansion_file <NEWLINE> <DEDENT> else : <NEWLINE> <INDENT> tax_filepath = out_prefix + <STRING> <NEWLINE> tag_filepath = out_prefix + <STRING> <NEWLINE> exp_filepath = out_prefix + <STRING> <NEWLINE> <DEDENT> taxonomy . to_file ( tax_filepath ) <NEWLINE> log . info ( <STRING> % ( <NEWLINE> <INDENT> len ( taxonomy ) , tax_filepath ) ) <NEWLINE> <DEDENT> tagging . expand_all_destinations ( ) <NEWLINE> tagging . to_file ( tag_filepath ) <NEWLINE> log . info ( <STRING> % ( <NEWLINE> <INDENT> len ( tagging ) , tag_filepath ) ) <NEWLINE> <DEDENT> expansion . to_file ( exp_filepath ) <NEWLINE> log . info ( <STRING> % ( <NEWLINE> <INDENT> len ( expansion ) , exp_filepath ) ) <NEWLINE> <DEDENT> <DEDENT>
evolution = evolve . run_evolution ( vertices , terminals , 5 , n = 16 , n1 = 2 , n2 = 8 ) <NEWLINE> <INDENT> genes = evolve . get_best_individual ( evolution ) <NEWLINE> tst = evolve . get_best_terminal_steiner_tree ( vertices , terminals , evolution ) <NEWLINE> w1 = tst [ <STRING> ] . sum ( ) <NEWLINE> w2 = evolution . at [ len ( evolution ) - 1 , <STRING> ] <NEWLINE> <DEDENT>
reflections = reflections . select ( reflections [ <STRING> ] == 1701 ) <NEWLINE>
if ntr : <NEWLINE> <INDENT> intgr . integrater_reset_reindex_operator ( ) <NEWLINE> need_to_return = True <NEWLINE> <DEDENT>
